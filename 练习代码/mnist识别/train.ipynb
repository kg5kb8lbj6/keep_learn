{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./train_output', exist_ok=True) # 创建文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = r'D:\\learn\\MNIST_Dataset\\train_images'\n",
    "txt = './train_output/total_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(image_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(image_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(os.path.join(image_root, '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 0, filename = 0\n",
      "label = 1, filename = 1\n",
      "label = 2, filename = 2\n",
      "label = 3, filename = 3\n",
      "label = 4, filename = 4\n",
      "label = 5, filename = 5\n",
      "label = 6, filename = 6\n",
      "label = 7, filename = 7\n",
      "label = 8, filename = 8\n",
      "label = 9, filename = 9\n"
     ]
    }
   ],
   "source": [
    "# 照片的名字以及对应的数字 写入一个txt文件中\n",
    "def image_list(imageRoot, txt):\n",
    "    f = open(txt, 'wt')\n",
    "    for (label, filename) in enumerate(sorted(os.listdir(image_root), reverse = False)):\n",
    "        print('label = {}, filename = {}'.format(label, filename))\n",
    "        if os.path.isdir(os.path.join(image_root, filename)):\n",
    "            for imagename in os.listdir(os.path.join(image_root, filename)):\n",
    "                name, ext = os.path.splitext(imagename)\n",
    "                ext = ext[1:]\n",
    "                if ext == 'jpg' or ext == 'png' or ext == 'bmp':\n",
    "                    f.write('%s %d\\n' % (os.path.join(imageRoot, filename, imagename), label))\n",
    "    f.close()\n",
    "image_list(imageRoot = image_root, txt = txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFile = r'D:\\learn\\下载git的代码\\mnist\\train_output\\train.txt'\n",
    "valFile = r'D:\\learn\\下载git的代码\\mnist\\train_output\\val.txt'\n",
    "def shuffle_split(listFile, trainFile, valFile):\n",
    "    with open(listFile, 'r') as f:\n",
    "        records = f.readlines()\n",
    "    random.shuffle(records)\n",
    "    num = len(records)\n",
    "    trainNum = int(num * 0.8) # 训练集占80%\n",
    "    with open(trainFile, 'w') as f:\n",
    "        f.writelines(records[:trainNum])\n",
    "    with open(valFile, 'w') as f1:\n",
    "        f1.writelines(records[trainNum:])\n",
    "shuffle_split(listFile = txt, trainFile = trainFile, valFile = valFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "fh = open(trainFile, 'r')\n",
    "for line in fh:\n",
    "    #print(line)\n",
    "    # strip : 移除字符串头尾指定的字符（默认为空格或换行符）或字符序列\n",
    "    line = line.strip('\\n') # ['D:\\\\learn\\\\MNIST_Dataset\\\\train_images\\\\4\\\\4_04811.jpg 4', '']\n",
    "    #print(line)\n",
    "    line = line.rstrip() # # 删除 string 字符串末尾的指定字符，默认为空白符，包括空格、换行符、回车符、制表符。\n",
    "    words = line.split()\n",
    "    test.append((words[0], int(words[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, transform = None, target_transform = None):\n",
    "        fh = open(txt, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:  # line为每一行\n",
    "            line = line.strip('\\n')\n",
    "            line = line.rstrip() # 删除 string 字符串末尾的指定字符，默认为空白符，包括空格、换行符、回车符、制表符。\n",
    "            words = line.split()\n",
    "            imgs.append((words[0], int(words[1])))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn ,label = self.imgs[index]\n",
    "        img = cv2.imread(fn, cv2.IMREAD_COLOR)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(txt = trainFile, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = MyDataset(txt = valFile, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(dataset = val_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, stride = 1, padding = 1), # 32 * 28 *28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # 32 * 14 * 14\n",
    "        )\n",
    "        self. conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1), # 64 * 14 *14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # 64 x 7 x 7\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # 64 x 3 x3\n",
    "        )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(64 * 3 * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv2_out = self.conv2(conv1_out)\n",
    "        conv3_out = self.conv3(conv2_out)\n",
    "        res = conv3_out.reshape(conv3_out.size(0), -1)\n",
    "        out = self.dense(res)\n",
    "        return out\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             896\n",
      "              ReLU-2           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 64, 14, 14]          18,496\n",
      "              ReLU-5           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-6             [-1, 64, 7, 7]               0\n",
      "            Conv2d-7             [-1, 64, 7, 7]          36,928\n",
      "              ReLU-8             [-1, 64, 7, 7]               0\n",
      "         MaxPool2d-9             [-1, 64, 3, 3]               0\n",
      "           Linear-10                  [-1, 128]          73,856\n",
      "             ReLU-11                  [-1, 128]               0\n",
      "           Linear-12                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 131,466\n",
      "Trainable params: 131,466\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.70\n",
      "Params size (MB): 0.50\n",
      "Estimated Total Size (MB): 1.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01, weight_decay = 1e-3)\n",
    "# 在第10轮的时候lr * 0.1， 在第20轮后 (lr * 0.1) * 0.1\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [10, 20], 0.1)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.MultiStepLR at 0x1f1129fc070>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1/30 batch   0/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  1/30 batch   1/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  1/30 batch   2/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  1/30 batch   3/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  1/30 batch   4/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  1/30 batch   5/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  1/30 batch   6/375  Train Loss: 0.093, Acc: 0.969\n",
      "epoch:  1/30 batch   7/375  Train Loss: 0.085, Acc: 0.984\n",
      "epoch:  1/30 batch   8/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch:  1/30 batch   9/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  1/30 batch  10/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  1/30 batch  11/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  1/30 batch  12/375  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  1/30 batch  13/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch:  1/30 batch  14/375  Train Loss: 0.130, Acc: 0.961\n",
      "epoch:  1/30 batch  15/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  1/30 batch  16/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  1/30 batch  17/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  1/30 batch  18/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  1/30 batch  19/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch:  1/30 batch  20/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  1/30 batch  21/375  Train Loss: 0.109, Acc: 0.961\n",
      "epoch:  1/30 batch  22/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  1/30 batch  23/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  1/30 batch  24/375  Train Loss: 0.115, Acc: 0.969\n",
      "epoch:  1/30 batch  25/375  Train Loss: 0.141, Acc: 0.953\n",
      "epoch:  1/30 batch  26/375  Train Loss: 0.146, Acc: 0.938\n",
      "epoch:  1/30 batch  27/375  Train Loss: 0.083, Acc: 0.961\n",
      "epoch:  1/30 batch  28/375  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  1/30 batch  29/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  1/30 batch  30/375  Train Loss: 0.123, Acc: 0.945\n",
      "epoch:  1/30 batch  31/375  Train Loss: 0.102, Acc: 0.984\n",
      "epoch:  1/30 batch  32/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  1/30 batch  33/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  1/30 batch  34/375  Train Loss: 0.144, Acc: 0.945\n",
      "epoch:  1/30 batch  35/375  Train Loss: 0.089, Acc: 0.961\n",
      "epoch:  1/30 batch  36/375  Train Loss: 0.169, Acc: 0.953\n",
      "epoch:  1/30 batch  37/375  Train Loss: 0.154, Acc: 0.945\n",
      "epoch:  1/30 batch  38/375  Train Loss: 0.118, Acc: 0.977\n",
      "epoch:  1/30 batch  39/375  Train Loss: 0.084, Acc: 0.969\n",
      "epoch:  1/30 batch  40/375  Train Loss: 0.133, Acc: 0.969\n",
      "epoch:  1/30 batch  41/375  Train Loss: 0.128, Acc: 0.945\n",
      "epoch:  1/30 batch  42/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  1/30 batch  43/375  Train Loss: 0.208, Acc: 0.945\n",
      "epoch:  1/30 batch  44/375  Train Loss: 0.077, Acc: 0.984\n",
      "epoch:  1/30 batch  45/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  1/30 batch  46/375  Train Loss: 0.106, Acc: 0.953\n",
      "epoch:  1/30 batch  47/375  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  1/30 batch  48/375  Train Loss: 0.123, Acc: 0.922\n",
      "epoch:  1/30 batch  49/375  Train Loss: 0.179, Acc: 0.953\n",
      "epoch:  1/30 batch  50/375  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  1/30 batch  51/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  1/30 batch  52/375  Train Loss: 0.187, Acc: 0.945\n",
      "epoch:  1/30 batch  53/375  Train Loss: 0.118, Acc: 0.977\n",
      "epoch:  1/30 batch  54/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch:  1/30 batch  55/375  Train Loss: 0.131, Acc: 0.953\n",
      "epoch:  1/30 batch  56/375  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  1/30 batch  57/375  Train Loss: 0.163, Acc: 0.930\n",
      "epoch:  1/30 batch  58/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  1/30 batch  59/375  Train Loss: 0.128, Acc: 0.969\n",
      "epoch:  1/30 batch  60/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  1/30 batch  61/375  Train Loss: 0.203, Acc: 0.945\n",
      "epoch:  1/30 batch  62/375  Train Loss: 0.069, Acc: 0.961\n",
      "epoch:  1/30 batch  63/375  Train Loss: 0.132, Acc: 0.953\n",
      "epoch:  1/30 batch  64/375  Train Loss: 0.106, Acc: 0.977\n",
      "epoch:  1/30 batch  65/375  Train Loss: 0.104, Acc: 0.961\n",
      "epoch:  1/30 batch  66/375  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  1/30 batch  67/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  1/30 batch  68/375  Train Loss: 0.083, Acc: 0.961\n",
      "epoch:  1/30 batch  69/375  Train Loss: 0.134, Acc: 0.953\n",
      "epoch:  1/30 batch  70/375  Train Loss: 0.170, Acc: 0.961\n",
      "epoch:  1/30 batch  71/375  Train Loss: 0.105, Acc: 0.977\n",
      "epoch:  1/30 batch  72/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  1/30 batch  73/375  Train Loss: 0.177, Acc: 0.961\n",
      "epoch:  1/30 batch  74/375  Train Loss: 0.112, Acc: 0.961\n",
      "epoch:  1/30 batch  75/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  1/30 batch  76/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  1/30 batch  77/375  Train Loss: 0.204, Acc: 0.914\n",
      "epoch:  1/30 batch  78/375  Train Loss: 0.087, Acc: 0.953\n",
      "epoch:  1/30 batch  79/375  Train Loss: 0.141, Acc: 0.969\n",
      "epoch:  1/30 batch  80/375  Train Loss: 0.099, Acc: 0.977\n",
      "epoch:  1/30 batch  81/375  Train Loss: 0.142, Acc: 0.938\n",
      "epoch:  1/30 batch  82/375  Train Loss: 0.164, Acc: 0.938\n",
      "epoch:  1/30 batch  83/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  1/30 batch  84/375  Train Loss: 0.091, Acc: 0.984\n",
      "epoch:  1/30 batch  85/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  1/30 batch  86/375  Train Loss: 0.150, Acc: 0.953\n",
      "epoch:  1/30 batch  87/375  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  1/30 batch  88/375  Train Loss: 0.175, Acc: 0.953\n",
      "epoch:  1/30 batch  89/375  Train Loss: 0.128, Acc: 0.969\n",
      "epoch:  1/30 batch  90/375  Train Loss: 0.066, Acc: 0.961\n",
      "epoch:  1/30 batch  91/375  Train Loss: 0.087, Acc: 0.984\n",
      "epoch:  1/30 batch  92/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  1/30 batch  93/375  Train Loss: 0.143, Acc: 0.961\n",
      "epoch:  1/30 batch  94/375  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  1/30 batch  95/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  1/30 batch  96/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  1/30 batch  97/375  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  1/30 batch  98/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  1/30 batch  99/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  1/30 batch 100/375  Train Loss: 0.133, Acc: 0.977\n",
      "epoch:  1/30 batch 101/375  Train Loss: 0.091, Acc: 0.953\n",
      "epoch:  1/30 batch 102/375  Train Loss: 0.132, Acc: 0.961\n",
      "epoch:  1/30 batch 103/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  1/30 batch 104/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  1/30 batch 105/375  Train Loss: 0.059, Acc: 0.992\n",
      "epoch:  1/30 batch 106/375  Train Loss: 0.102, Acc: 0.945\n",
      "epoch:  1/30 batch 107/375  Train Loss: 0.105, Acc: 0.961\n",
      "epoch:  1/30 batch 108/375  Train Loss: 0.131, Acc: 0.953\n",
      "epoch:  1/30 batch 109/375  Train Loss: 0.091, Acc: 0.953\n",
      "epoch:  1/30 batch 110/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch:  1/30 batch 111/375  Train Loss: 0.101, Acc: 0.977\n",
      "epoch:  1/30 batch 112/375  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  1/30 batch 113/375  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  1/30 batch 114/375  Train Loss: 0.097, Acc: 0.984\n",
      "epoch:  1/30 batch 115/375  Train Loss: 0.131, Acc: 0.961\n",
      "epoch:  1/30 batch 116/375  Train Loss: 0.148, Acc: 0.953\n",
      "epoch:  1/30 batch 117/375  Train Loss: 0.194, Acc: 0.953\n",
      "epoch:  1/30 batch 118/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  1/30 batch 119/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch:  1/30 batch 120/375  Train Loss: 0.210, Acc: 0.961\n",
      "epoch:  1/30 batch 121/375  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  1/30 batch 122/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  1/30 batch 123/375  Train Loss: 0.077, Acc: 0.961\n",
      "epoch:  1/30 batch 124/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  1/30 batch 125/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  1/30 batch 126/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  1/30 batch 127/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  1/30 batch 128/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  1/30 batch 129/375  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  1/30 batch 130/375  Train Loss: 0.125, Acc: 0.961\n",
      "epoch:  1/30 batch 131/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  1/30 batch 132/375  Train Loss: 0.110, Acc: 0.977\n",
      "epoch:  1/30 batch 133/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  1/30 batch 134/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch:  1/30 batch 135/375  Train Loss: 0.090, Acc: 0.984\n",
      "epoch:  1/30 batch 136/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  1/30 batch 137/375  Train Loss: 0.057, Acc: 0.992\n",
      "epoch:  1/30 batch 138/375  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  1/30 batch 139/375  Train Loss: 0.072, Acc: 0.969\n",
      "epoch:  1/30 batch 140/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  1/30 batch 141/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  1/30 batch 142/375  Train Loss: 0.097, Acc: 0.961\n",
      "epoch:  1/30 batch 143/375  Train Loss: 0.147, Acc: 0.953\n",
      "epoch:  1/30 batch 144/375  Train Loss: 0.124, Acc: 0.945\n",
      "epoch:  1/30 batch 145/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  1/30 batch 146/375  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  1/30 batch 147/375  Train Loss: 0.130, Acc: 0.938\n",
      "epoch:  1/30 batch 148/375  Train Loss: 0.142, Acc: 0.953\n",
      "epoch:  1/30 batch 149/375  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  1/30 batch 150/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  1/30 batch 151/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  1/30 batch 152/375  Train Loss: 0.060, Acc: 0.992\n",
      "epoch:  1/30 batch 153/375  Train Loss: 0.134, Acc: 0.977\n",
      "epoch:  1/30 batch 154/375  Train Loss: 0.113, Acc: 0.953\n",
      "epoch:  1/30 batch 155/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  1/30 batch 156/375  Train Loss: 0.194, Acc: 0.938\n",
      "epoch:  1/30 batch 157/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch:  1/30 batch 158/375  Train Loss: 0.104, Acc: 0.961\n",
      "epoch:  1/30 batch 159/375  Train Loss: 0.110, Acc: 0.969\n",
      "epoch:  1/30 batch 160/375  Train Loss: 0.167, Acc: 0.930\n",
      "epoch:  1/30 batch 161/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  1/30 batch 162/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  1/30 batch 163/375  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  1/30 batch 164/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  1/30 batch 165/375  Train Loss: 0.170, Acc: 0.953\n",
      "epoch:  1/30 batch 166/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  1/30 batch 167/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  1/30 batch 168/375  Train Loss: 0.138, Acc: 0.938\n",
      "epoch:  1/30 batch 169/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  1/30 batch 170/375  Train Loss: 0.104, Acc: 0.969\n",
      "epoch:  1/30 batch 171/375  Train Loss: 0.117, Acc: 0.961\n",
      "epoch:  1/30 batch 172/375  Train Loss: 0.092, Acc: 0.961\n",
      "epoch:  1/30 batch 173/375  Train Loss: 0.165, Acc: 0.914\n",
      "epoch:  1/30 batch 174/375  Train Loss: 0.098, Acc: 0.938\n",
      "epoch:  1/30 batch 175/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  1/30 batch 176/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  1/30 batch 177/375  Train Loss: 0.063, Acc: 0.992\n",
      "epoch:  1/30 batch 178/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  1/30 batch 179/375  Train Loss: 0.130, Acc: 0.961\n",
      "epoch:  1/30 batch 180/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  1/30 batch 181/375  Train Loss: 0.056, Acc: 0.969\n",
      "epoch:  1/30 batch 182/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  1/30 batch 183/375  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  1/30 batch 184/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  1/30 batch 185/375  Train Loss: 0.106, Acc: 0.984\n",
      "epoch:  1/30 batch 186/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch:  1/30 batch 187/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  1/30 batch 188/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  1/30 batch 189/375  Train Loss: 0.175, Acc: 0.953\n",
      "epoch:  1/30 batch 190/375  Train Loss: 0.131, Acc: 0.969\n",
      "epoch:  1/30 batch 191/375  Train Loss: 0.063, Acc: 0.992\n",
      "epoch:  1/30 batch 192/375  Train Loss: 0.177, Acc: 0.961\n",
      "epoch:  1/30 batch 193/375  Train Loss: 0.201, Acc: 0.961\n",
      "epoch:  1/30 batch 194/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  1/30 batch 195/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  1/30 batch 196/375  Train Loss: 0.272, Acc: 0.930\n",
      "epoch:  1/30 batch 197/375  Train Loss: 0.086, Acc: 0.961\n",
      "epoch:  1/30 batch 198/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  1/30 batch 199/375  Train Loss: 0.148, Acc: 0.930\n",
      "epoch:  1/30 batch 200/375  Train Loss: 0.114, Acc: 0.953\n",
      "epoch:  1/30 batch 201/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  1/30 batch 202/375  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  1/30 batch 203/375  Train Loss: 0.095, Acc: 0.969\n",
      "epoch:  1/30 batch 204/375  Train Loss: 0.159, Acc: 0.961\n",
      "epoch:  1/30 batch 205/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  1/30 batch 206/375  Train Loss: 0.107, Acc: 0.961\n",
      "epoch:  1/30 batch 207/375  Train Loss: 0.108, Acc: 0.961\n",
      "epoch:  1/30 batch 208/375  Train Loss: 0.184, Acc: 0.938\n",
      "epoch:  1/30 batch 209/375  Train Loss: 0.131, Acc: 0.961\n",
      "epoch:  1/30 batch 210/375  Train Loss: 0.166, Acc: 0.969\n",
      "epoch:  1/30 batch 211/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  1/30 batch 212/375  Train Loss: 0.067, Acc: 0.992\n",
      "epoch:  1/30 batch 213/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  1/30 batch 214/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  1/30 batch 215/375  Train Loss: 0.135, Acc: 0.961\n",
      "epoch:  1/30 batch 216/375  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  1/30 batch 217/375  Train Loss: 0.142, Acc: 0.953\n",
      "epoch:  1/30 batch 218/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  1/30 batch 219/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  1/30 batch 220/375  Train Loss: 0.068, Acc: 0.969\n",
      "epoch:  1/30 batch 221/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  1/30 batch 222/375  Train Loss: 0.160, Acc: 0.961\n",
      "epoch:  1/30 batch 223/375  Train Loss: 0.071, Acc: 0.969\n",
      "epoch:  1/30 batch 224/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  1/30 batch 225/375  Train Loss: 0.059, Acc: 0.969\n",
      "epoch:  1/30 batch 226/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  1/30 batch 227/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  1/30 batch 228/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  1/30 batch 229/375  Train Loss: 0.118, Acc: 0.969\n",
      "epoch:  1/30 batch 230/375  Train Loss: 0.065, Acc: 0.961\n",
      "epoch:  1/30 batch 231/375  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  1/30 batch 232/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  1/30 batch 233/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  1/30 batch 234/375  Train Loss: 0.103, Acc: 0.977\n",
      "epoch:  1/30 batch 235/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  1/30 batch 236/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch:  1/30 batch 237/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  1/30 batch 238/375  Train Loss: 0.113, Acc: 0.969\n",
      "epoch:  1/30 batch 239/375  Train Loss: 0.130, Acc: 0.969\n",
      "epoch:  1/30 batch 240/375  Train Loss: 0.168, Acc: 0.969\n",
      "epoch:  1/30 batch 241/375  Train Loss: 0.058, Acc: 0.992\n",
      "epoch:  1/30 batch 242/375  Train Loss: 0.179, Acc: 0.938\n",
      "epoch:  1/30 batch 243/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  1/30 batch 244/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  1/30 batch 245/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch:  1/30 batch 246/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  1/30 batch 247/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  1/30 batch 248/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch:  1/30 batch 249/375  Train Loss: 0.056, Acc: 0.992\n",
      "epoch:  1/30 batch 250/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  1/30 batch 251/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  1/30 batch 252/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  1/30 batch 253/375  Train Loss: 0.115, Acc: 0.969\n",
      "epoch:  1/30 batch 254/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  1/30 batch 255/375  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  1/30 batch 256/375  Train Loss: 0.057, Acc: 0.992\n",
      "epoch:  1/30 batch 257/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  1/30 batch 258/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch:  1/30 batch 259/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  1/30 batch 260/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  1/30 batch 261/375  Train Loss: 0.171, Acc: 0.945\n",
      "epoch:  1/30 batch 262/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  1/30 batch 263/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  1/30 batch 264/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  1/30 batch 265/375  Train Loss: 0.119, Acc: 0.961\n",
      "epoch:  1/30 batch 266/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  1/30 batch 267/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  1/30 batch 268/375  Train Loss: 0.171, Acc: 0.969\n",
      "epoch:  1/30 batch 269/375  Train Loss: 0.077, Acc: 0.961\n",
      "epoch:  1/30 batch 270/375  Train Loss: 0.132, Acc: 0.945\n",
      "epoch:  1/30 batch 271/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  1/30 batch 272/375  Train Loss: 0.146, Acc: 0.945\n",
      "epoch:  1/30 batch 273/375  Train Loss: 0.194, Acc: 0.930\n",
      "epoch:  1/30 batch 274/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  1/30 batch 275/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  1/30 batch 276/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  1/30 batch 277/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  1/30 batch 278/375  Train Loss: 0.162, Acc: 0.938\n",
      "epoch:  1/30 batch 279/375  Train Loss: 0.149, Acc: 0.945\n",
      "epoch:  1/30 batch 280/375  Train Loss: 0.133, Acc: 0.961\n",
      "epoch:  1/30 batch 281/375  Train Loss: 0.134, Acc: 0.953\n",
      "epoch:  1/30 batch 282/375  Train Loss: 0.169, Acc: 0.953\n",
      "epoch:  1/30 batch 283/375  Train Loss: 0.235, Acc: 0.930\n",
      "epoch:  1/30 batch 284/375  Train Loss: 0.225, Acc: 0.922\n",
      "epoch:  1/30 batch 285/375  Train Loss: 0.101, Acc: 0.977\n",
      "epoch:  1/30 batch 286/375  Train Loss: 0.106, Acc: 0.977\n",
      "epoch:  1/30 batch 287/375  Train Loss: 0.135, Acc: 0.953\n",
      "epoch:  1/30 batch 288/375  Train Loss: 0.148, Acc: 0.961\n",
      "epoch:  1/30 batch 289/375  Train Loss: 0.161, Acc: 0.922\n",
      "epoch:  1/30 batch 290/375  Train Loss: 0.120, Acc: 0.961\n",
      "epoch:  1/30 batch 291/375  Train Loss: 0.086, Acc: 0.953\n",
      "epoch:  1/30 batch 292/375  Train Loss: 0.116, Acc: 0.969\n",
      "epoch:  1/30 batch 293/375  Train Loss: 0.214, Acc: 0.945\n",
      "epoch:  1/30 batch 294/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  1/30 batch 295/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  1/30 batch 296/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  1/30 batch 297/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  1/30 batch 298/375  Train Loss: 0.073, Acc: 0.984\n",
      "epoch:  1/30 batch 299/375  Train Loss: 0.055, Acc: 0.969\n",
      "epoch:  1/30 batch 300/375  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  1/30 batch 301/375  Train Loss: 0.116, Acc: 0.961\n",
      "epoch:  1/30 batch 302/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  1/30 batch 303/375  Train Loss: 0.053, Acc: 0.969\n",
      "epoch:  1/30 batch 304/375  Train Loss: 0.108, Acc: 0.953\n",
      "epoch:  1/30 batch 305/375  Train Loss: 0.219, Acc: 0.961\n",
      "epoch:  1/30 batch 306/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  1/30 batch 307/375  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  1/30 batch 308/375  Train Loss: 0.103, Acc: 0.961\n",
      "epoch:  1/30 batch 309/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  1/30 batch 310/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  1/30 batch 311/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  1/30 batch 312/375  Train Loss: 0.103, Acc: 0.977\n",
      "epoch:  1/30 batch 313/375  Train Loss: 0.102, Acc: 0.977\n",
      "epoch:  1/30 batch 314/375  Train Loss: 0.104, Acc: 0.977\n",
      "epoch:  1/30 batch 315/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  1/30 batch 316/375  Train Loss: 0.082, Acc: 0.961\n",
      "epoch:  1/30 batch 317/375  Train Loss: 0.127, Acc: 0.969\n",
      "epoch:  1/30 batch 318/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  1/30 batch 319/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  1/30 batch 320/375  Train Loss: 0.126, Acc: 0.969\n",
      "epoch:  1/30 batch 321/375  Train Loss: 0.157, Acc: 0.961\n",
      "epoch:  1/30 batch 322/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  1/30 batch 323/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  1/30 batch 324/375  Train Loss: 0.035, Acc: 1.000\n",
      "epoch:  1/30 batch 325/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  1/30 batch 326/375  Train Loss: 0.161, Acc: 0.945\n",
      "epoch:  1/30 batch 327/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch:  1/30 batch 328/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  1/30 batch 329/375  Train Loss: 0.196, Acc: 0.938\n",
      "epoch:  1/30 batch 330/375  Train Loss: 0.122, Acc: 0.953\n",
      "epoch:  1/30 batch 331/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  1/30 batch 332/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  1/30 batch 333/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  1/30 batch 334/375  Train Loss: 0.119, Acc: 0.961\n",
      "epoch:  1/30 batch 335/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  1/30 batch 336/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch:  1/30 batch 337/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  1/30 batch 338/375  Train Loss: 0.132, Acc: 0.969\n",
      "epoch:  1/30 batch 339/375  Train Loss: 0.246, Acc: 0.922\n",
      "epoch:  1/30 batch 340/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  1/30 batch 341/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  1/30 batch 342/375  Train Loss: 0.127, Acc: 0.953\n",
      "epoch:  1/30 batch 343/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  1/30 batch 344/375  Train Loss: 0.139, Acc: 0.953\n",
      "epoch:  1/30 batch 345/375  Train Loss: 0.129, Acc: 0.953\n",
      "epoch:  1/30 batch 346/375  Train Loss: 0.065, Acc: 0.969\n",
      "epoch:  1/30 batch 347/375  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  1/30 batch 348/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  1/30 batch 349/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  1/30 batch 350/375  Train Loss: 0.108, Acc: 0.977\n",
      "epoch:  1/30 batch 351/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  1/30 batch 352/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  1/30 batch 353/375  Train Loss: 0.193, Acc: 0.930\n",
      "epoch:  1/30 batch 354/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  1/30 batch 355/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  1/30 batch 356/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  1/30 batch 357/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  1/30 batch 358/375  Train Loss: 0.114, Acc: 0.969\n",
      "epoch:  1/30 batch 359/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  1/30 batch 360/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  1/30 batch 361/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch:  1/30 batch 362/375  Train Loss: 0.127, Acc: 0.969\n",
      "epoch:  1/30 batch 363/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  1/30 batch 364/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  1/30 batch 365/375  Train Loss: 0.093, Acc: 0.984\n",
      "epoch:  1/30 batch 366/375  Train Loss: 0.154, Acc: 0.969\n",
      "epoch:  1/30 batch 367/375  Train Loss: 0.101, Acc: 0.961\n",
      "epoch:  1/30 batch 368/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  1/30 batch 369/375  Train Loss: 0.155, Acc: 0.961\n",
      "epoch:  1/30 batch 370/375  Train Loss: 0.154, Acc: 0.961\n",
      "epoch:  1/30 batch 371/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  1/30 batch 372/375  Train Loss: 0.116, Acc: 0.961\n",
      "epoch:  1/30 batch 373/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  1/30 batch 374/375  Train Loss: 0.105, Acc: 0.977\n",
      "Train Loss: 0.094871, Acc: 0.970\n",
      "Val Loss: 0.062642, Acc: 0.981\n",
      "epoch:  2/30 batch   0/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  2/30 batch   1/375  Train Loss: 0.086, Acc: 0.961\n",
      "epoch:  2/30 batch   2/375  Train Loss: 0.095, Acc: 0.969\n",
      "epoch:  2/30 batch   3/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  2/30 batch   4/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  2/30 batch   5/375  Train Loss: 0.066, Acc: 0.969\n",
      "epoch:  2/30 batch   6/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  2/30 batch   7/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  2/30 batch   8/375  Train Loss: 0.109, Acc: 0.961\n",
      "epoch:  2/30 batch   9/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  2/30 batch  10/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  2/30 batch  11/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  2/30 batch  12/375  Train Loss: 0.083, Acc: 0.969\n",
      "epoch:  2/30 batch  13/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  2/30 batch  14/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  2/30 batch  15/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  2/30 batch  16/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  2/30 batch  17/375  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  2/30 batch  18/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch:  2/30 batch  19/375  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  2/30 batch  20/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  2/30 batch  21/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  2/30 batch  22/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  2/30 batch  23/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  2/30 batch  24/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch:  2/30 batch  25/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  2/30 batch  26/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch:  2/30 batch  27/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch:  2/30 batch  28/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  2/30 batch  29/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  2/30 batch  30/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch:  2/30 batch  31/375  Train Loss: 0.091, Acc: 0.953\n",
      "epoch:  2/30 batch  32/375  Train Loss: 0.108, Acc: 0.969\n",
      "epoch:  2/30 batch  33/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch:  2/30 batch  34/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  2/30 batch  35/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch:  2/30 batch  36/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch:  2/30 batch  37/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  2/30 batch  38/375  Train Loss: 0.096, Acc: 0.953\n",
      "epoch:  2/30 batch  39/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  2/30 batch  40/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch:  2/30 batch  41/375  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  2/30 batch  42/375  Train Loss: 0.083, Acc: 0.984\n",
      "epoch:  2/30 batch  43/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  2/30 batch  44/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  2/30 batch  45/375  Train Loss: 0.053, Acc: 0.969\n",
      "epoch:  2/30 batch  46/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  2/30 batch  47/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  2/30 batch  48/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  2/30 batch  49/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch:  2/30 batch  50/375  Train Loss: 0.160, Acc: 0.953\n",
      "epoch:  2/30 batch  51/375  Train Loss: 0.161, Acc: 0.953\n",
      "epoch:  2/30 batch  52/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  2/30 batch  53/375  Train Loss: 0.170, Acc: 0.930\n",
      "epoch:  2/30 batch  54/375  Train Loss: 0.186, Acc: 0.945\n",
      "epoch:  2/30 batch  55/375  Train Loss: 0.073, Acc: 0.984\n",
      "epoch:  2/30 batch  56/375  Train Loss: 0.027, Acc: 1.000\n",
      "epoch:  2/30 batch  57/375  Train Loss: 0.136, Acc: 0.945\n",
      "epoch:  2/30 batch  58/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  2/30 batch  59/375  Train Loss: 0.106, Acc: 0.945\n",
      "epoch:  2/30 batch  60/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  2/30 batch  61/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  2/30 batch  62/375  Train Loss: 0.076, Acc: 0.961\n",
      "epoch:  2/30 batch  63/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  2/30 batch  64/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  2/30 batch  65/375  Train Loss: 0.144, Acc: 0.969\n",
      "epoch:  2/30 batch  66/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  2/30 batch  67/375  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  2/30 batch  68/375  Train Loss: 0.115, Acc: 0.969\n",
      "epoch:  2/30 batch  69/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  2/30 batch  70/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  2/30 batch  71/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  2/30 batch  72/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  2/30 batch  73/375  Train Loss: 0.095, Acc: 0.984\n",
      "epoch:  2/30 batch  74/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  2/30 batch  75/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  2/30 batch  76/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  2/30 batch  77/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  2/30 batch  78/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  2/30 batch  79/375  Train Loss: 0.108, Acc: 0.969\n",
      "epoch:  2/30 batch  80/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  2/30 batch  81/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  2/30 batch  82/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  2/30 batch  83/375  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  2/30 batch  84/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch:  2/30 batch  85/375  Train Loss: 0.051, Acc: 0.969\n",
      "epoch:  2/30 batch  86/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  2/30 batch  87/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  2/30 batch  88/375  Train Loss: 0.112, Acc: 0.977\n",
      "epoch:  2/30 batch  89/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  2/30 batch  90/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  2/30 batch  91/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  2/30 batch  92/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  2/30 batch  93/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  2/30 batch  94/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  2/30 batch  95/375  Train Loss: 0.164, Acc: 0.953\n",
      "epoch:  2/30 batch  96/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  2/30 batch  97/375  Train Loss: 0.029, Acc: 1.000\n",
      "epoch:  2/30 batch  98/375  Train Loss: 0.105, Acc: 0.961\n",
      "epoch:  2/30 batch  99/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  2/30 batch 100/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  2/30 batch 101/375  Train Loss: 0.083, Acc: 0.984\n",
      "epoch:  2/30 batch 102/375  Train Loss: 0.105, Acc: 0.953\n",
      "epoch:  2/30 batch 103/375  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  2/30 batch 104/375  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  2/30 batch 105/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  2/30 batch 106/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  2/30 batch 107/375  Train Loss: 0.125, Acc: 0.953\n",
      "epoch:  2/30 batch 108/375  Train Loss: 0.154, Acc: 0.969\n",
      "epoch:  2/30 batch 109/375  Train Loss: 0.151, Acc: 0.945\n",
      "epoch:  2/30 batch 110/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch:  2/30 batch 111/375  Train Loss: 0.111, Acc: 0.961\n",
      "epoch:  2/30 batch 112/375  Train Loss: 0.110, Acc: 0.953\n",
      "epoch:  2/30 batch 113/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch:  2/30 batch 114/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  2/30 batch 115/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  2/30 batch 116/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  2/30 batch 117/375  Train Loss: 0.095, Acc: 0.977\n",
      "epoch:  2/30 batch 118/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  2/30 batch 119/375  Train Loss: 0.147, Acc: 0.961\n",
      "epoch:  2/30 batch 120/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  2/30 batch 121/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch:  2/30 batch 122/375  Train Loss: 0.095, Acc: 0.953\n",
      "epoch:  2/30 batch 123/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  2/30 batch 124/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  2/30 batch 125/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  2/30 batch 126/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  2/30 batch 127/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  2/30 batch 128/375  Train Loss: 0.197, Acc: 0.945\n",
      "epoch:  2/30 batch 129/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch:  2/30 batch 130/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch:  2/30 batch 131/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  2/30 batch 132/375  Train Loss: 0.062, Acc: 0.969\n",
      "epoch:  2/30 batch 133/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch:  2/30 batch 134/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  2/30 batch 135/375  Train Loss: 0.154, Acc: 0.953\n",
      "epoch:  2/30 batch 136/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  2/30 batch 137/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  2/30 batch 138/375  Train Loss: 0.111, Acc: 0.953\n",
      "epoch:  2/30 batch 139/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  2/30 batch 140/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  2/30 batch 141/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  2/30 batch 142/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  2/30 batch 143/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  2/30 batch 144/375  Train Loss: 0.225, Acc: 0.961\n",
      "epoch:  2/30 batch 145/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  2/30 batch 146/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  2/30 batch 147/375  Train Loss: 0.113, Acc: 0.977\n",
      "epoch:  2/30 batch 148/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  2/30 batch 149/375  Train Loss: 0.141, Acc: 0.969\n",
      "epoch:  2/30 batch 150/375  Train Loss: 0.164, Acc: 0.938\n",
      "epoch:  2/30 batch 151/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  2/30 batch 152/375  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  2/30 batch 153/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  2/30 batch 154/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  2/30 batch 155/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  2/30 batch 156/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  2/30 batch 157/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  2/30 batch 158/375  Train Loss: 0.147, Acc: 0.961\n",
      "epoch:  2/30 batch 159/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  2/30 batch 160/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  2/30 batch 161/375  Train Loss: 0.126, Acc: 0.969\n",
      "epoch:  2/30 batch 162/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  2/30 batch 163/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  2/30 batch 164/375  Train Loss: 0.091, Acc: 0.961\n",
      "epoch:  2/30 batch 165/375  Train Loss: 0.101, Acc: 0.953\n",
      "epoch:  2/30 batch 166/375  Train Loss: 0.214, Acc: 0.945\n",
      "epoch:  2/30 batch 167/375  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  2/30 batch 168/375  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  2/30 batch 169/375  Train Loss: 0.196, Acc: 0.945\n",
      "epoch:  2/30 batch 170/375  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  2/30 batch 171/375  Train Loss: 0.100, Acc: 0.969\n",
      "epoch:  2/30 batch 172/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  2/30 batch 173/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  2/30 batch 174/375  Train Loss: 0.150, Acc: 0.961\n",
      "epoch:  2/30 batch 175/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  2/30 batch 176/375  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  2/30 batch 177/375  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  2/30 batch 178/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  2/30 batch 179/375  Train Loss: 0.120, Acc: 0.969\n",
      "epoch:  2/30 batch 180/375  Train Loss: 0.063, Acc: 0.992\n",
      "epoch:  2/30 batch 181/375  Train Loss: 0.093, Acc: 0.969\n",
      "epoch:  2/30 batch 182/375  Train Loss: 0.103, Acc: 0.977\n",
      "epoch:  2/30 batch 183/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch:  2/30 batch 184/375  Train Loss: 0.075, Acc: 0.984\n",
      "epoch:  2/30 batch 185/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  2/30 batch 186/375  Train Loss: 0.090, Acc: 0.961\n",
      "epoch:  2/30 batch 187/375  Train Loss: 0.149, Acc: 0.953\n",
      "epoch:  2/30 batch 188/375  Train Loss: 0.151, Acc: 0.961\n",
      "epoch:  2/30 batch 189/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  2/30 batch 190/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  2/30 batch 191/375  Train Loss: 0.214, Acc: 0.961\n",
      "epoch:  2/30 batch 192/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  2/30 batch 193/375  Train Loss: 0.208, Acc: 0.961\n",
      "epoch:  2/30 batch 194/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  2/30 batch 195/375  Train Loss: 0.140, Acc: 0.938\n",
      "epoch:  2/30 batch 196/375  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  2/30 batch 197/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  2/30 batch 198/375  Train Loss: 0.139, Acc: 0.953\n",
      "epoch:  2/30 batch 199/375  Train Loss: 0.114, Acc: 0.945\n",
      "epoch:  2/30 batch 200/375  Train Loss: 0.078, Acc: 0.961\n",
      "epoch:  2/30 batch 201/375  Train Loss: 0.203, Acc: 0.945\n",
      "epoch:  2/30 batch 202/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  2/30 batch 203/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  2/30 batch 204/375  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  2/30 batch 205/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  2/30 batch 206/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  2/30 batch 207/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  2/30 batch 208/375  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  2/30 batch 209/375  Train Loss: 0.111, Acc: 0.961\n",
      "epoch:  2/30 batch 210/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  2/30 batch 211/375  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  2/30 batch 212/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch:  2/30 batch 213/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  2/30 batch 214/375  Train Loss: 0.148, Acc: 0.961\n",
      "epoch:  2/30 batch 215/375  Train Loss: 0.084, Acc: 0.961\n",
      "epoch:  2/30 batch 216/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  2/30 batch 217/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  2/30 batch 218/375  Train Loss: 0.085, Acc: 0.961\n",
      "epoch:  2/30 batch 219/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  2/30 batch 220/375  Train Loss: 0.111, Acc: 0.984\n",
      "epoch:  2/30 batch 221/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  2/30 batch 222/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  2/30 batch 223/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  2/30 batch 224/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch:  2/30 batch 225/375  Train Loss: 0.127, Acc: 0.969\n",
      "epoch:  2/30 batch 226/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  2/30 batch 227/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  2/30 batch 228/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  2/30 batch 229/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  2/30 batch 230/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  2/30 batch 231/375  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  2/30 batch 232/375  Train Loss: 0.032, Acc: 1.000\n",
      "epoch:  2/30 batch 233/375  Train Loss: 0.120, Acc: 0.953\n",
      "epoch:  2/30 batch 234/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch:  2/30 batch 235/375  Train Loss: 0.093, Acc: 0.984\n",
      "epoch:  2/30 batch 236/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  2/30 batch 237/375  Train Loss: 0.095, Acc: 0.953\n",
      "epoch:  2/30 batch 238/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch:  2/30 batch 239/375  Train Loss: 0.087, Acc: 0.984\n",
      "epoch:  2/30 batch 240/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  2/30 batch 241/375  Train Loss: 0.109, Acc: 0.938\n",
      "epoch:  2/30 batch 242/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch:  2/30 batch 243/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  2/30 batch 244/375  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  2/30 batch 245/375  Train Loss: 0.100, Acc: 0.977\n",
      "epoch:  2/30 batch 246/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  2/30 batch 247/375  Train Loss: 0.063, Acc: 0.961\n",
      "epoch:  2/30 batch 248/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  2/30 batch 249/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  2/30 batch 250/375  Train Loss: 0.153, Acc: 0.961\n",
      "epoch:  2/30 batch 251/375  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  2/30 batch 252/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  2/30 batch 253/375  Train Loss: 0.246, Acc: 0.938\n",
      "epoch:  2/30 batch 254/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  2/30 batch 255/375  Train Loss: 0.067, Acc: 0.992\n",
      "epoch:  2/30 batch 256/375  Train Loss: 0.131, Acc: 0.961\n",
      "epoch:  2/30 batch 257/375  Train Loss: 0.031, Acc: 1.000\n",
      "epoch:  2/30 batch 258/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  2/30 batch 259/375  Train Loss: 0.153, Acc: 0.953\n",
      "epoch:  2/30 batch 260/375  Train Loss: 0.128, Acc: 0.969\n",
      "epoch:  2/30 batch 261/375  Train Loss: 0.126, Acc: 0.969\n",
      "epoch:  2/30 batch 262/375  Train Loss: 0.100, Acc: 0.969\n",
      "epoch:  2/30 batch 263/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  2/30 batch 264/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  2/30 batch 265/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  2/30 batch 266/375  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  2/30 batch 267/375  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  2/30 batch 268/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  2/30 batch 269/375  Train Loss: 0.097, Acc: 0.961\n",
      "epoch:  2/30 batch 270/375  Train Loss: 0.095, Acc: 0.961\n",
      "epoch:  2/30 batch 271/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  2/30 batch 272/375  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  2/30 batch 273/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  2/30 batch 274/375  Train Loss: 0.099, Acc: 0.961\n",
      "epoch:  2/30 batch 275/375  Train Loss: 0.156, Acc: 0.969\n",
      "epoch:  2/30 batch 276/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  2/30 batch 277/375  Train Loss: 0.141, Acc: 0.938\n",
      "epoch:  2/30 batch 278/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  2/30 batch 279/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  2/30 batch 280/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  2/30 batch 281/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  2/30 batch 282/375  Train Loss: 0.057, Acc: 0.969\n",
      "epoch:  2/30 batch 283/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  2/30 batch 284/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  2/30 batch 285/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  2/30 batch 286/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  2/30 batch 287/375  Train Loss: 0.048, Acc: 0.969\n",
      "epoch:  2/30 batch 288/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  2/30 batch 289/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch:  2/30 batch 290/375  Train Loss: 0.073, Acc: 0.984\n",
      "epoch:  2/30 batch 291/375  Train Loss: 0.093, Acc: 0.969\n",
      "epoch:  2/30 batch 292/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  2/30 batch 293/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  2/30 batch 294/375  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  2/30 batch 295/375  Train Loss: 0.076, Acc: 0.961\n",
      "epoch:  2/30 batch 296/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  2/30 batch 297/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch:  2/30 batch 298/375  Train Loss: 0.166, Acc: 0.969\n",
      "epoch:  2/30 batch 299/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  2/30 batch 300/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  2/30 batch 301/375  Train Loss: 0.072, Acc: 0.984\n",
      "epoch:  2/30 batch 302/375  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  2/30 batch 303/375  Train Loss: 0.091, Acc: 0.961\n",
      "epoch:  2/30 batch 304/375  Train Loss: 0.145, Acc: 0.961\n",
      "epoch:  2/30 batch 305/375  Train Loss: 0.086, Acc: 0.961\n",
      "epoch:  2/30 batch 306/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  2/30 batch 307/375  Train Loss: 0.028, Acc: 1.000\n",
      "epoch:  2/30 batch 308/375  Train Loss: 0.118, Acc: 0.977\n",
      "epoch:  2/30 batch 309/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  2/30 batch 310/375  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  2/30 batch 311/375  Train Loss: 0.209, Acc: 0.945\n",
      "epoch:  2/30 batch 312/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  2/30 batch 313/375  Train Loss: 0.062, Acc: 0.992\n",
      "epoch:  2/30 batch 314/375  Train Loss: 0.098, Acc: 0.984\n",
      "epoch:  2/30 batch 315/375  Train Loss: 0.206, Acc: 0.922\n",
      "epoch:  2/30 batch 316/375  Train Loss: 0.098, Acc: 0.984\n",
      "epoch:  2/30 batch 317/375  Train Loss: 0.104, Acc: 0.977\n",
      "epoch:  2/30 batch 318/375  Train Loss: 0.153, Acc: 0.953\n",
      "epoch:  2/30 batch 319/375  Train Loss: 0.131, Acc: 0.953\n",
      "epoch:  2/30 batch 320/375  Train Loss: 0.169, Acc: 0.945\n",
      "epoch:  2/30 batch 321/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  2/30 batch 322/375  Train Loss: 0.024, Acc: 1.000\n",
      "epoch:  2/30 batch 323/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  2/30 batch 324/375  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  2/30 batch 325/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  2/30 batch 326/375  Train Loss: 0.069, Acc: 0.969\n",
      "epoch:  2/30 batch 327/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  2/30 batch 328/375  Train Loss: 0.138, Acc: 0.953\n",
      "epoch:  2/30 batch 329/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  2/30 batch 330/375  Train Loss: 0.099, Acc: 0.984\n",
      "epoch:  2/30 batch 331/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch:  2/30 batch 332/375  Train Loss: 0.168, Acc: 0.969\n",
      "epoch:  2/30 batch 333/375  Train Loss: 0.129, Acc: 0.953\n",
      "epoch:  2/30 batch 334/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  2/30 batch 335/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  2/30 batch 336/375  Train Loss: 0.141, Acc: 0.953\n",
      "epoch:  2/30 batch 337/375  Train Loss: 0.122, Acc: 0.969\n",
      "epoch:  2/30 batch 338/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  2/30 batch 339/375  Train Loss: 0.080, Acc: 0.984\n",
      "epoch:  2/30 batch 340/375  Train Loss: 0.098, Acc: 0.984\n",
      "epoch:  2/30 batch 341/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  2/30 batch 342/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  2/30 batch 343/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  2/30 batch 344/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  2/30 batch 345/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  2/30 batch 346/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  2/30 batch 347/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  2/30 batch 348/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  2/30 batch 349/375  Train Loss: 0.157, Acc: 0.969\n",
      "epoch:  2/30 batch 350/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  2/30 batch 351/375  Train Loss: 0.095, Acc: 0.977\n",
      "epoch:  2/30 batch 352/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  2/30 batch 353/375  Train Loss: 0.111, Acc: 0.977\n",
      "epoch:  2/30 batch 354/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  2/30 batch 355/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  2/30 batch 356/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  2/30 batch 357/375  Train Loss: 0.141, Acc: 0.969\n",
      "epoch:  2/30 batch 358/375  Train Loss: 0.054, Acc: 0.969\n",
      "epoch:  2/30 batch 359/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  2/30 batch 360/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  2/30 batch 361/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  2/30 batch 362/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  2/30 batch 363/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  2/30 batch 364/375  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  2/30 batch 365/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  2/30 batch 366/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  2/30 batch 367/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch:  2/30 batch 368/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  2/30 batch 369/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch:  2/30 batch 370/375  Train Loss: 0.068, Acc: 0.969\n",
      "epoch:  2/30 batch 371/375  Train Loss: 0.087, Acc: 0.961\n",
      "epoch:  2/30 batch 372/375  Train Loss: 0.180, Acc: 0.969\n",
      "epoch:  2/30 batch 373/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  2/30 batch 374/375  Train Loss: 0.063, Acc: 0.969\n",
      "Train Loss: 0.077026, Acc: 0.976\n",
      "Val Loss: 0.076964, Acc: 0.976\n",
      "epoch:  3/30 batch   0/375  Train Loss: 0.056, Acc: 0.969\n",
      "epoch:  3/30 batch   1/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  3/30 batch   2/375  Train Loss: 0.127, Acc: 0.977\n",
      "epoch:  3/30 batch   3/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  3/30 batch   4/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch:  3/30 batch   5/375  Train Loss: 0.125, Acc: 0.938\n",
      "epoch:  3/30 batch   6/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  3/30 batch   7/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  3/30 batch   8/375  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  3/30 batch   9/375  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  3/30 batch  10/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  3/30 batch  11/375  Train Loss: 0.111, Acc: 0.961\n",
      "epoch:  3/30 batch  12/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  3/30 batch  13/375  Train Loss: 0.066, Acc: 0.992\n",
      "epoch:  3/30 batch  14/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  3/30 batch  15/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  3/30 batch  16/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  3/30 batch  17/375  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  3/30 batch  18/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  3/30 batch  19/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  3/30 batch  20/375  Train Loss: 0.079, Acc: 0.961\n",
      "epoch:  3/30 batch  21/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch:  3/30 batch  22/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch:  3/30 batch  23/375  Train Loss: 0.073, Acc: 0.984\n",
      "epoch:  3/30 batch  24/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  3/30 batch  25/375  Train Loss: 0.086, Acc: 0.984\n",
      "epoch:  3/30 batch  26/375  Train Loss: 0.115, Acc: 0.977\n",
      "epoch:  3/30 batch  27/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  3/30 batch  28/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  3/30 batch  29/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  3/30 batch  30/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  3/30 batch  31/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  3/30 batch  32/375  Train Loss: 0.062, Acc: 0.953\n",
      "epoch:  3/30 batch  33/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  3/30 batch  34/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  3/30 batch  35/375  Train Loss: 0.154, Acc: 0.922\n",
      "epoch:  3/30 batch  36/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  3/30 batch  37/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  3/30 batch  38/375  Train Loss: 0.074, Acc: 0.992\n",
      "epoch:  3/30 batch  39/375  Train Loss: 0.100, Acc: 0.953\n",
      "epoch:  3/30 batch  40/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  3/30 batch  41/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  3/30 batch  42/375  Train Loss: 0.141, Acc: 0.953\n",
      "epoch:  3/30 batch  43/375  Train Loss: 0.165, Acc: 0.953\n",
      "epoch:  3/30 batch  44/375  Train Loss: 0.119, Acc: 0.969\n",
      "epoch:  3/30 batch  45/375  Train Loss: 0.110, Acc: 0.977\n",
      "epoch:  3/30 batch  46/375  Train Loss: 0.036, Acc: 0.977\n",
      "epoch:  3/30 batch  47/375  Train Loss: 0.131, Acc: 0.953\n",
      "epoch:  3/30 batch  48/375  Train Loss: 0.211, Acc: 0.945\n",
      "epoch:  3/30 batch  49/375  Train Loss: 0.124, Acc: 0.938\n",
      "epoch:  3/30 batch  50/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  3/30 batch  51/375  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  3/30 batch  52/375  Train Loss: 0.086, Acc: 0.992\n",
      "epoch:  3/30 batch  53/375  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  3/30 batch  54/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  3/30 batch  55/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  3/30 batch  56/375  Train Loss: 0.090, Acc: 0.984\n",
      "epoch:  3/30 batch  57/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  3/30 batch  58/375  Train Loss: 0.111, Acc: 0.961\n",
      "epoch:  3/30 batch  59/375  Train Loss: 0.072, Acc: 0.969\n",
      "epoch:  3/30 batch  60/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  3/30 batch  61/375  Train Loss: 0.083, Acc: 0.969\n",
      "epoch:  3/30 batch  62/375  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  3/30 batch  63/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  3/30 batch  64/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch:  3/30 batch  65/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch:  3/30 batch  66/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  3/30 batch  67/375  Train Loss: 0.056, Acc: 0.969\n",
      "epoch:  3/30 batch  68/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  3/30 batch  69/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch:  3/30 batch  70/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  3/30 batch  71/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  3/30 batch  72/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  3/30 batch  73/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  3/30 batch  74/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  3/30 batch  75/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  3/30 batch  76/375  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  3/30 batch  77/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  3/30 batch  78/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  3/30 batch  79/375  Train Loss: 0.121, Acc: 0.969\n",
      "epoch:  3/30 batch  80/375  Train Loss: 0.052, Acc: 0.969\n",
      "epoch:  3/30 batch  81/375  Train Loss: 0.093, Acc: 0.984\n",
      "epoch:  3/30 batch  82/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  3/30 batch  83/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  3/30 batch  84/375  Train Loss: 0.157, Acc: 0.961\n",
      "epoch:  3/30 batch  85/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  3/30 batch  86/375  Train Loss: 0.131, Acc: 0.977\n",
      "epoch:  3/30 batch  87/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  3/30 batch  88/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch:  3/30 batch  89/375  Train Loss: 0.154, Acc: 0.961\n",
      "epoch:  3/30 batch  90/375  Train Loss: 0.040, Acc: 1.000\n",
      "epoch:  3/30 batch  91/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  3/30 batch  92/375  Train Loss: 0.183, Acc: 0.961\n",
      "epoch:  3/30 batch  93/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  3/30 batch  94/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  3/30 batch  95/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  3/30 batch  96/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  3/30 batch  97/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  3/30 batch  98/375  Train Loss: 0.101, Acc: 0.977\n",
      "epoch:  3/30 batch  99/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  3/30 batch 100/375  Train Loss: 0.103, Acc: 0.961\n",
      "epoch:  3/30 batch 101/375  Train Loss: 0.130, Acc: 0.969\n",
      "epoch:  3/30 batch 102/375  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  3/30 batch 103/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  3/30 batch 104/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch:  3/30 batch 105/375  Train Loss: 0.097, Acc: 0.984\n",
      "epoch:  3/30 batch 106/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  3/30 batch 107/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  3/30 batch 108/375  Train Loss: 0.062, Acc: 0.969\n",
      "epoch:  3/30 batch 109/375  Train Loss: 0.117, Acc: 0.961\n",
      "epoch:  3/30 batch 110/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  3/30 batch 111/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  3/30 batch 112/375  Train Loss: 0.062, Acc: 0.969\n",
      "epoch:  3/30 batch 113/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  3/30 batch 114/375  Train Loss: 0.188, Acc: 0.961\n",
      "epoch:  3/30 batch 115/375  Train Loss: 0.058, Acc: 0.992\n",
      "epoch:  3/30 batch 116/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  3/30 batch 117/375  Train Loss: 0.113, Acc: 0.961\n",
      "epoch:  3/30 batch 118/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  3/30 batch 119/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  3/30 batch 120/375  Train Loss: 0.215, Acc: 0.938\n",
      "epoch:  3/30 batch 121/375  Train Loss: 0.181, Acc: 0.938\n",
      "epoch:  3/30 batch 122/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  3/30 batch 123/375  Train Loss: 0.167, Acc: 0.953\n",
      "epoch:  3/30 batch 124/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  3/30 batch 125/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  3/30 batch 126/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  3/30 batch 127/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  3/30 batch 128/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  3/30 batch 129/375  Train Loss: 0.124, Acc: 0.953\n",
      "epoch:  3/30 batch 130/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  3/30 batch 131/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  3/30 batch 132/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  3/30 batch 133/375  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  3/30 batch 134/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch:  3/30 batch 135/375  Train Loss: 0.118, Acc: 0.961\n",
      "epoch:  3/30 batch 136/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  3/30 batch 137/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  3/30 batch 138/375  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  3/30 batch 139/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  3/30 batch 140/375  Train Loss: 0.097, Acc: 0.953\n",
      "epoch:  3/30 batch 141/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch:  3/30 batch 142/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  3/30 batch 143/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  3/30 batch 144/375  Train Loss: 0.272, Acc: 0.930\n",
      "epoch:  3/30 batch 145/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  3/30 batch 146/375  Train Loss: 0.027, Acc: 1.000\n",
      "epoch:  3/30 batch 147/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  3/30 batch 148/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  3/30 batch 149/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  3/30 batch 150/375  Train Loss: 0.101, Acc: 0.977\n",
      "epoch:  3/30 batch 151/375  Train Loss: 0.091, Acc: 0.984\n",
      "epoch:  3/30 batch 152/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch:  3/30 batch 153/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  3/30 batch 154/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  3/30 batch 155/375  Train Loss: 0.124, Acc: 0.961\n",
      "epoch:  3/30 batch 156/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  3/30 batch 157/375  Train Loss: 0.150, Acc: 0.945\n",
      "epoch:  3/30 batch 158/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  3/30 batch 159/375  Train Loss: 0.032, Acc: 1.000\n",
      "epoch:  3/30 batch 160/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  3/30 batch 161/375  Train Loss: 0.154, Acc: 0.953\n",
      "epoch:  3/30 batch 162/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  3/30 batch 163/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch:  3/30 batch 164/375  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  3/30 batch 165/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  3/30 batch 166/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  3/30 batch 167/375  Train Loss: 0.111, Acc: 0.977\n",
      "epoch:  3/30 batch 168/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  3/30 batch 169/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  3/30 batch 170/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  3/30 batch 171/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  3/30 batch 172/375  Train Loss: 0.087, Acc: 0.961\n",
      "epoch:  3/30 batch 173/375  Train Loss: 0.072, Acc: 0.953\n",
      "epoch:  3/30 batch 174/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  3/30 batch 175/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  3/30 batch 176/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  3/30 batch 177/375  Train Loss: 0.099, Acc: 0.984\n",
      "epoch:  3/30 batch 178/375  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  3/30 batch 179/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  3/30 batch 180/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  3/30 batch 181/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  3/30 batch 182/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  3/30 batch 183/375  Train Loss: 0.105, Acc: 0.977\n",
      "epoch:  3/30 batch 184/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  3/30 batch 185/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  3/30 batch 186/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  3/30 batch 187/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  3/30 batch 188/375  Train Loss: 0.125, Acc: 0.961\n",
      "epoch:  3/30 batch 189/375  Train Loss: 0.117, Acc: 0.984\n",
      "epoch:  3/30 batch 190/375  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  3/30 batch 191/375  Train Loss: 0.184, Acc: 0.969\n",
      "epoch:  3/30 batch 192/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  3/30 batch 193/375  Train Loss: 0.121, Acc: 0.977\n",
      "epoch:  3/30 batch 194/375  Train Loss: 0.107, Acc: 0.961\n",
      "epoch:  3/30 batch 195/375  Train Loss: 0.107, Acc: 0.953\n",
      "epoch:  3/30 batch 196/375  Train Loss: 0.102, Acc: 0.953\n",
      "epoch:  3/30 batch 197/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  3/30 batch 198/375  Train Loss: 0.101, Acc: 0.977\n",
      "epoch:  3/30 batch 199/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  3/30 batch 200/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  3/30 batch 201/375  Train Loss: 0.076, Acc: 0.953\n",
      "epoch:  3/30 batch 202/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  3/30 batch 203/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  3/30 batch 204/375  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  3/30 batch 205/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  3/30 batch 206/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  3/30 batch 207/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  3/30 batch 208/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  3/30 batch 209/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  3/30 batch 210/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  3/30 batch 211/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  3/30 batch 212/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  3/30 batch 213/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  3/30 batch 214/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  3/30 batch 215/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  3/30 batch 216/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  3/30 batch 217/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  3/30 batch 218/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  3/30 batch 219/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  3/30 batch 220/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  3/30 batch 221/375  Train Loss: 0.096, Acc: 0.961\n",
      "epoch:  3/30 batch 222/375  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  3/30 batch 223/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch:  3/30 batch 224/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch:  3/30 batch 225/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  3/30 batch 226/375  Train Loss: 0.028, Acc: 1.000\n",
      "epoch:  3/30 batch 227/375  Train Loss: 0.079, Acc: 0.961\n",
      "epoch:  3/30 batch 228/375  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  3/30 batch 229/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  3/30 batch 230/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  3/30 batch 231/375  Train Loss: 0.129, Acc: 0.961\n",
      "epoch:  3/30 batch 232/375  Train Loss: 0.165, Acc: 0.922\n",
      "epoch:  3/30 batch 233/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  3/30 batch 234/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  3/30 batch 235/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  3/30 batch 236/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  3/30 batch 237/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  3/30 batch 238/375  Train Loss: 0.080, Acc: 0.961\n",
      "epoch:  3/30 batch 239/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  3/30 batch 240/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  3/30 batch 241/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  3/30 batch 242/375  Train Loss: 0.140, Acc: 0.969\n",
      "epoch:  3/30 batch 243/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  3/30 batch 244/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  3/30 batch 245/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  3/30 batch 246/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  3/30 batch 247/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  3/30 batch 248/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  3/30 batch 249/375  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  3/30 batch 250/375  Train Loss: 0.104, Acc: 0.977\n",
      "epoch:  3/30 batch 251/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  3/30 batch 252/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch:  3/30 batch 253/375  Train Loss: 0.080, Acc: 0.984\n",
      "epoch:  3/30 batch 254/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  3/30 batch 255/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  3/30 batch 256/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  3/30 batch 257/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  3/30 batch 258/375  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  3/30 batch 259/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  3/30 batch 260/375  Train Loss: 0.132, Acc: 0.953\n",
      "epoch:  3/30 batch 261/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  3/30 batch 262/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  3/30 batch 263/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  3/30 batch 264/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  3/30 batch 265/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  3/30 batch 266/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  3/30 batch 267/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  3/30 batch 268/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  3/30 batch 269/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  3/30 batch 270/375  Train Loss: 0.162, Acc: 0.977\n",
      "epoch:  3/30 batch 271/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  3/30 batch 272/375  Train Loss: 0.063, Acc: 0.969\n",
      "epoch:  3/30 batch 273/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch:  3/30 batch 274/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  3/30 batch 275/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  3/30 batch 276/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  3/30 batch 277/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch:  3/30 batch 278/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  3/30 batch 279/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  3/30 batch 280/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  3/30 batch 281/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  3/30 batch 282/375  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  3/30 batch 283/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  3/30 batch 284/375  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  3/30 batch 285/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  3/30 batch 286/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  3/30 batch 287/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  3/30 batch 288/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  3/30 batch 289/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  3/30 batch 290/375  Train Loss: 0.095, Acc: 0.984\n",
      "epoch:  3/30 batch 291/375  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  3/30 batch 292/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch:  3/30 batch 293/375  Train Loss: 0.125, Acc: 0.969\n",
      "epoch:  3/30 batch 294/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  3/30 batch 295/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  3/30 batch 296/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  3/30 batch 297/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  3/30 batch 298/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  3/30 batch 299/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  3/30 batch 300/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  3/30 batch 301/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  3/30 batch 302/375  Train Loss: 0.143, Acc: 0.977\n",
      "epoch:  3/30 batch 303/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  3/30 batch 304/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  3/30 batch 305/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  3/30 batch 306/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  3/30 batch 307/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  3/30 batch 308/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  3/30 batch 309/375  Train Loss: 0.105, Acc: 0.961\n",
      "epoch:  3/30 batch 310/375  Train Loss: 0.087, Acc: 0.953\n",
      "epoch:  3/30 batch 311/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  3/30 batch 312/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  3/30 batch 313/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  3/30 batch 314/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  3/30 batch 315/375  Train Loss: 0.118, Acc: 0.984\n",
      "epoch:  3/30 batch 316/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  3/30 batch 317/375  Train Loss: 0.141, Acc: 0.984\n",
      "epoch:  3/30 batch 318/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  3/30 batch 319/375  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  3/30 batch 320/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  3/30 batch 321/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  3/30 batch 322/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  3/30 batch 323/375  Train Loss: 0.105, Acc: 0.953\n",
      "epoch:  3/30 batch 324/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  3/30 batch 325/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  3/30 batch 326/375  Train Loss: 0.059, Acc: 0.992\n",
      "epoch:  3/30 batch 327/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  3/30 batch 328/375  Train Loss: 0.078, Acc: 0.961\n",
      "epoch:  3/30 batch 329/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch:  3/30 batch 330/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  3/30 batch 331/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  3/30 batch 332/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  3/30 batch 333/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  3/30 batch 334/375  Train Loss: 0.072, Acc: 0.961\n",
      "epoch:  3/30 batch 335/375  Train Loss: 0.125, Acc: 0.961\n",
      "epoch:  3/30 batch 336/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch:  3/30 batch 337/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch:  3/30 batch 338/375  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  3/30 batch 339/375  Train Loss: 0.119, Acc: 0.969\n",
      "epoch:  3/30 batch 340/375  Train Loss: 0.109, Acc: 0.969\n",
      "epoch:  3/30 batch 341/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  3/30 batch 342/375  Train Loss: 0.149, Acc: 0.953\n",
      "epoch:  3/30 batch 343/375  Train Loss: 0.147, Acc: 0.984\n",
      "epoch:  3/30 batch 344/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  3/30 batch 345/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  3/30 batch 346/375  Train Loss: 0.116, Acc: 0.953\n",
      "epoch:  3/30 batch 347/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch:  3/30 batch 348/375  Train Loss: 0.115, Acc: 0.961\n",
      "epoch:  3/30 batch 349/375  Train Loss: 0.250, Acc: 0.930\n",
      "epoch:  3/30 batch 350/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  3/30 batch 351/375  Train Loss: 0.108, Acc: 0.969\n",
      "epoch:  3/30 batch 352/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  3/30 batch 353/375  Train Loss: 0.058, Acc: 0.992\n",
      "epoch:  3/30 batch 354/375  Train Loss: 0.122, Acc: 0.969\n",
      "epoch:  3/30 batch 355/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  3/30 batch 356/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  3/30 batch 357/375  Train Loss: 0.134, Acc: 0.945\n",
      "epoch:  3/30 batch 358/375  Train Loss: 0.117, Acc: 0.953\n",
      "epoch:  3/30 batch 359/375  Train Loss: 0.087, Acc: 0.961\n",
      "epoch:  3/30 batch 360/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  3/30 batch 361/375  Train Loss: 0.128, Acc: 0.961\n",
      "epoch:  3/30 batch 362/375  Train Loss: 0.102, Acc: 0.977\n",
      "epoch:  3/30 batch 363/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  3/30 batch 364/375  Train Loss: 0.099, Acc: 0.977\n",
      "epoch:  3/30 batch 365/375  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  3/30 batch 366/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  3/30 batch 367/375  Train Loss: 0.140, Acc: 0.961\n",
      "epoch:  3/30 batch 368/375  Train Loss: 0.031, Acc: 1.000\n",
      "epoch:  3/30 batch 369/375  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  3/30 batch 370/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  3/30 batch 371/375  Train Loss: 0.175, Acc: 0.977\n",
      "epoch:  3/30 batch 372/375  Train Loss: 0.136, Acc: 0.961\n",
      "epoch:  3/30 batch 373/375  Train Loss: 0.095, Acc: 0.969\n",
      "epoch:  3/30 batch 374/375  Train Loss: 0.120, Acc: 0.961\n",
      "Train Loss: 0.072906, Acc: 0.977\n",
      "Val Loss: 0.081438, Acc: 0.975\n",
      "epoch:  4/30 batch   0/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch:  4/30 batch   1/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  4/30 batch   2/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  4/30 batch   3/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  4/30 batch   4/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  4/30 batch   5/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  4/30 batch   6/375  Train Loss: 0.165, Acc: 0.961\n",
      "epoch:  4/30 batch   7/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  4/30 batch   8/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  4/30 batch   9/375  Train Loss: 0.159, Acc: 0.938\n",
      "epoch:  4/30 batch  10/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  4/30 batch  11/375  Train Loss: 0.038, Acc: 0.977\n",
      "epoch:  4/30 batch  12/375  Train Loss: 0.084, Acc: 0.953\n",
      "epoch:  4/30 batch  13/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  4/30 batch  14/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  4/30 batch  15/375  Train Loss: 0.103, Acc: 0.977\n",
      "epoch:  4/30 batch  16/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  4/30 batch  17/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch:  4/30 batch  18/375  Train Loss: 0.093, Acc: 0.969\n",
      "epoch:  4/30 batch  19/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch:  4/30 batch  20/375  Train Loss: 0.056, Acc: 0.969\n",
      "epoch:  4/30 batch  21/375  Train Loss: 0.109, Acc: 0.961\n",
      "epoch:  4/30 batch  22/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  4/30 batch  23/375  Train Loss: 0.071, Acc: 0.969\n",
      "epoch:  4/30 batch  24/375  Train Loss: 0.104, Acc: 0.984\n",
      "epoch:  4/30 batch  25/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  4/30 batch  26/375  Train Loss: 0.087, Acc: 0.984\n",
      "epoch:  4/30 batch  27/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  4/30 batch  28/375  Train Loss: 0.109, Acc: 0.969\n",
      "epoch:  4/30 batch  29/375  Train Loss: 0.087, Acc: 0.984\n",
      "epoch:  4/30 batch  30/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  4/30 batch  31/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  4/30 batch  32/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  4/30 batch  33/375  Train Loss: 0.068, Acc: 0.969\n",
      "epoch:  4/30 batch  34/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  4/30 batch  35/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  4/30 batch  36/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  4/30 batch  37/375  Train Loss: 0.121, Acc: 0.969\n",
      "epoch:  4/30 batch  38/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch:  4/30 batch  39/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  4/30 batch  40/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  4/30 batch  41/375  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  4/30 batch  42/375  Train Loss: 0.071, Acc: 0.969\n",
      "epoch:  4/30 batch  43/375  Train Loss: 0.119, Acc: 0.977\n",
      "epoch:  4/30 batch  44/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  4/30 batch  45/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  4/30 batch  46/375  Train Loss: 0.093, Acc: 0.945\n",
      "epoch:  4/30 batch  47/375  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  4/30 batch  48/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  4/30 batch  49/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  4/30 batch  50/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  4/30 batch  51/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  4/30 batch  52/375  Train Loss: 0.085, Acc: 0.961\n",
      "epoch:  4/30 batch  53/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  4/30 batch  54/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  4/30 batch  55/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  4/30 batch  56/375  Train Loss: 0.102, Acc: 0.961\n",
      "epoch:  4/30 batch  57/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  4/30 batch  58/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  4/30 batch  59/375  Train Loss: 0.103, Acc: 0.977\n",
      "epoch:  4/30 batch  60/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  4/30 batch  61/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch:  4/30 batch  62/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  4/30 batch  63/375  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  4/30 batch  64/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  4/30 batch  65/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  4/30 batch  66/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  4/30 batch  67/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  4/30 batch  68/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  4/30 batch  69/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  4/30 batch  70/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  4/30 batch  71/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  4/30 batch  72/375  Train Loss: 0.112, Acc: 0.977\n",
      "epoch:  4/30 batch  73/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch:  4/30 batch  74/375  Train Loss: 0.095, Acc: 0.977\n",
      "epoch:  4/30 batch  75/375  Train Loss: 0.093, Acc: 0.961\n",
      "epoch:  4/30 batch  76/375  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  4/30 batch  77/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  4/30 batch  78/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch:  4/30 batch  79/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  4/30 batch  80/375  Train Loss: 0.082, Acc: 0.945\n",
      "epoch:  4/30 batch  81/375  Train Loss: 0.120, Acc: 0.969\n",
      "epoch:  4/30 batch  82/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  4/30 batch  83/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch:  4/30 batch  84/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  4/30 batch  85/375  Train Loss: 0.123, Acc: 0.961\n",
      "epoch:  4/30 batch  86/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  4/30 batch  87/375  Train Loss: 0.063, Acc: 0.992\n",
      "epoch:  4/30 batch  88/375  Train Loss: 0.135, Acc: 0.953\n",
      "epoch:  4/30 batch  89/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  4/30 batch  90/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  4/30 batch  91/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  4/30 batch  92/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  4/30 batch  93/375  Train Loss: 0.072, Acc: 0.969\n",
      "epoch:  4/30 batch  94/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  4/30 batch  95/375  Train Loss: 0.085, Acc: 0.961\n",
      "epoch:  4/30 batch  96/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  4/30 batch  97/375  Train Loss: 0.045, Acc: 1.000\n",
      "epoch:  4/30 batch  98/375  Train Loss: 0.089, Acc: 0.961\n",
      "epoch:  4/30 batch  99/375  Train Loss: 0.086, Acc: 0.984\n",
      "epoch:  4/30 batch 100/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  4/30 batch 101/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  4/30 batch 102/375  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  4/30 batch 103/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  4/30 batch 104/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch:  4/30 batch 105/375  Train Loss: 0.075, Acc: 0.984\n",
      "epoch:  4/30 batch 106/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  4/30 batch 107/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  4/30 batch 108/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  4/30 batch 109/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  4/30 batch 110/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  4/30 batch 111/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  4/30 batch 112/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  4/30 batch 113/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  4/30 batch 114/375  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  4/30 batch 115/375  Train Loss: 0.102, Acc: 0.984\n",
      "epoch:  4/30 batch 116/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  4/30 batch 117/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch:  4/30 batch 118/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch:  4/30 batch 119/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  4/30 batch 120/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  4/30 batch 121/375  Train Loss: 0.115, Acc: 0.961\n",
      "epoch:  4/30 batch 122/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  4/30 batch 123/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  4/30 batch 124/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch:  4/30 batch 125/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  4/30 batch 126/375  Train Loss: 0.132, Acc: 0.969\n",
      "epoch:  4/30 batch 127/375  Train Loss: 0.087, Acc: 0.961\n",
      "epoch:  4/30 batch 128/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch:  4/30 batch 129/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  4/30 batch 130/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch:  4/30 batch 131/375  Train Loss: 0.101, Acc: 0.961\n",
      "epoch:  4/30 batch 132/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch:  4/30 batch 133/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  4/30 batch 134/375  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  4/30 batch 135/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  4/30 batch 136/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  4/30 batch 137/375  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  4/30 batch 138/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch:  4/30 batch 139/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch:  4/30 batch 140/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  4/30 batch 141/375  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  4/30 batch 142/375  Train Loss: 0.099, Acc: 0.961\n",
      "epoch:  4/30 batch 143/375  Train Loss: 0.097, Acc: 0.961\n",
      "epoch:  4/30 batch 144/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  4/30 batch 145/375  Train Loss: 0.134, Acc: 0.953\n",
      "epoch:  4/30 batch 146/375  Train Loss: 0.111, Acc: 0.953\n",
      "epoch:  4/30 batch 147/375  Train Loss: 0.149, Acc: 0.961\n",
      "epoch:  4/30 batch 148/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  4/30 batch 149/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  4/30 batch 150/375  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  4/30 batch 151/375  Train Loss: 0.146, Acc: 0.977\n",
      "epoch:  4/30 batch 152/375  Train Loss: 0.195, Acc: 0.930\n",
      "epoch:  4/30 batch 153/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  4/30 batch 154/375  Train Loss: 0.103, Acc: 0.984\n",
      "epoch:  4/30 batch 155/375  Train Loss: 0.099, Acc: 0.961\n",
      "epoch:  4/30 batch 156/375  Train Loss: 0.083, Acc: 0.984\n",
      "epoch:  4/30 batch 157/375  Train Loss: 0.083, Acc: 0.984\n",
      "epoch:  4/30 batch 158/375  Train Loss: 0.191, Acc: 0.922\n",
      "epoch:  4/30 batch 159/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  4/30 batch 160/375  Train Loss: 0.193, Acc: 0.953\n",
      "epoch:  4/30 batch 161/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  4/30 batch 162/375  Train Loss: 0.122, Acc: 0.945\n",
      "epoch:  4/30 batch 163/375  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  4/30 batch 164/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  4/30 batch 165/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  4/30 batch 166/375  Train Loss: 0.052, Acc: 0.969\n",
      "epoch:  4/30 batch 167/375  Train Loss: 0.063, Acc: 0.969\n",
      "epoch:  4/30 batch 168/375  Train Loss: 0.084, Acc: 0.961\n",
      "epoch:  4/30 batch 169/375  Train Loss: 0.080, Acc: 0.984\n",
      "epoch:  4/30 batch 170/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch:  4/30 batch 171/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  4/30 batch 172/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch:  4/30 batch 173/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  4/30 batch 174/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  4/30 batch 175/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  4/30 batch 176/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  4/30 batch 177/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch:  4/30 batch 178/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  4/30 batch 179/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  4/30 batch 180/375  Train Loss: 0.142, Acc: 0.969\n",
      "epoch:  4/30 batch 181/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  4/30 batch 182/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  4/30 batch 183/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  4/30 batch 184/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  4/30 batch 185/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  4/30 batch 186/375  Train Loss: 0.093, Acc: 0.977\n",
      "epoch:  4/30 batch 187/375  Train Loss: 0.050, Acc: 0.969\n",
      "epoch:  4/30 batch 188/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  4/30 batch 189/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  4/30 batch 190/375  Train Loss: 0.064, Acc: 0.992\n",
      "epoch:  4/30 batch 191/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  4/30 batch 192/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  4/30 batch 193/375  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  4/30 batch 194/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  4/30 batch 195/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  4/30 batch 196/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  4/30 batch 197/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  4/30 batch 198/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  4/30 batch 199/375  Train Loss: 0.117, Acc: 0.945\n",
      "epoch:  4/30 batch 200/375  Train Loss: 0.031, Acc: 1.000\n",
      "epoch:  4/30 batch 201/375  Train Loss: 0.189, Acc: 0.961\n",
      "epoch:  4/30 batch 202/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  4/30 batch 203/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  4/30 batch 204/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  4/30 batch 205/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  4/30 batch 206/375  Train Loss: 0.134, Acc: 0.953\n",
      "epoch:  4/30 batch 207/375  Train Loss: 0.116, Acc: 0.953\n",
      "epoch:  4/30 batch 208/375  Train Loss: 0.137, Acc: 0.977\n",
      "epoch:  4/30 batch 209/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  4/30 batch 210/375  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  4/30 batch 211/375  Train Loss: 0.069, Acc: 0.969\n",
      "epoch:  4/30 batch 212/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  4/30 batch 213/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  4/30 batch 214/375  Train Loss: 0.067, Acc: 0.992\n",
      "epoch:  4/30 batch 215/375  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  4/30 batch 216/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  4/30 batch 217/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  4/30 batch 218/375  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  4/30 batch 219/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  4/30 batch 220/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  4/30 batch 221/375  Train Loss: 0.141, Acc: 0.977\n",
      "epoch:  4/30 batch 222/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  4/30 batch 223/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  4/30 batch 224/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  4/30 batch 225/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  4/30 batch 226/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  4/30 batch 227/375  Train Loss: 0.109, Acc: 0.969\n",
      "epoch:  4/30 batch 228/375  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  4/30 batch 229/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  4/30 batch 230/375  Train Loss: 0.082, Acc: 0.984\n",
      "epoch:  4/30 batch 231/375  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  4/30 batch 232/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch:  4/30 batch 233/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  4/30 batch 234/375  Train Loss: 0.155, Acc: 0.969\n",
      "epoch:  4/30 batch 235/375  Train Loss: 0.106, Acc: 0.953\n",
      "epoch:  4/30 batch 236/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  4/30 batch 237/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  4/30 batch 238/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  4/30 batch 239/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  4/30 batch 240/375  Train Loss: 0.118, Acc: 0.961\n",
      "epoch:  4/30 batch 241/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  4/30 batch 242/375  Train Loss: 0.086, Acc: 0.984\n",
      "epoch:  4/30 batch 243/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  4/30 batch 244/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch:  4/30 batch 245/375  Train Loss: 0.172, Acc: 0.953\n",
      "epoch:  4/30 batch 246/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  4/30 batch 247/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch:  4/30 batch 248/375  Train Loss: 0.109, Acc: 0.984\n",
      "epoch:  4/30 batch 249/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch:  4/30 batch 250/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  4/30 batch 251/375  Train Loss: 0.102, Acc: 0.961\n",
      "epoch:  4/30 batch 252/375  Train Loss: 0.157, Acc: 0.945\n",
      "epoch:  4/30 batch 253/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  4/30 batch 254/375  Train Loss: 0.155, Acc: 0.945\n",
      "epoch:  4/30 batch 255/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  4/30 batch 256/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  4/30 batch 257/375  Train Loss: 0.151, Acc: 0.977\n",
      "epoch:  4/30 batch 258/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  4/30 batch 259/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  4/30 batch 260/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  4/30 batch 261/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  4/30 batch 262/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  4/30 batch 263/375  Train Loss: 0.124, Acc: 0.961\n",
      "epoch:  4/30 batch 264/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  4/30 batch 265/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  4/30 batch 266/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  4/30 batch 267/375  Train Loss: 0.101, Acc: 0.961\n",
      "epoch:  4/30 batch 268/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch:  4/30 batch 269/375  Train Loss: 0.066, Acc: 0.969\n",
      "epoch:  4/30 batch 270/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  4/30 batch 271/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  4/30 batch 272/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  4/30 batch 273/375  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  4/30 batch 274/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  4/30 batch 275/375  Train Loss: 0.068, Acc: 0.969\n",
      "epoch:  4/30 batch 276/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  4/30 batch 277/375  Train Loss: 0.103, Acc: 0.984\n",
      "epoch:  4/30 batch 278/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  4/30 batch 279/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  4/30 batch 280/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  4/30 batch 281/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  4/30 batch 282/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  4/30 batch 283/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  4/30 batch 284/375  Train Loss: 0.132, Acc: 0.945\n",
      "epoch:  4/30 batch 285/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  4/30 batch 286/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch:  4/30 batch 287/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  4/30 batch 288/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  4/30 batch 289/375  Train Loss: 0.100, Acc: 0.969\n",
      "epoch:  4/30 batch 290/375  Train Loss: 0.120, Acc: 0.953\n",
      "epoch:  4/30 batch 291/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  4/30 batch 292/375  Train Loss: 0.097, Acc: 0.953\n",
      "epoch:  4/30 batch 293/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  4/30 batch 294/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  4/30 batch 295/375  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  4/30 batch 296/375  Train Loss: 0.062, Acc: 0.969\n",
      "epoch:  4/30 batch 297/375  Train Loss: 0.086, Acc: 0.961\n",
      "epoch:  4/30 batch 298/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch:  4/30 batch 299/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  4/30 batch 300/375  Train Loss: 0.092, Acc: 0.961\n",
      "epoch:  4/30 batch 301/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  4/30 batch 302/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  4/30 batch 303/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  4/30 batch 304/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  4/30 batch 305/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  4/30 batch 306/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  4/30 batch 307/375  Train Loss: 0.109, Acc: 0.969\n",
      "epoch:  4/30 batch 308/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  4/30 batch 309/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  4/30 batch 310/375  Train Loss: 0.141, Acc: 0.953\n",
      "epoch:  4/30 batch 311/375  Train Loss: 0.088, Acc: 0.984\n",
      "epoch:  4/30 batch 312/375  Train Loss: 0.082, Acc: 0.992\n",
      "epoch:  4/30 batch 313/375  Train Loss: 0.145, Acc: 0.945\n",
      "epoch:  4/30 batch 314/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  4/30 batch 315/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  4/30 batch 316/375  Train Loss: 0.115, Acc: 0.945\n",
      "epoch:  4/30 batch 317/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch:  4/30 batch 318/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch:  4/30 batch 319/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  4/30 batch 320/375  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  4/30 batch 321/375  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  4/30 batch 322/375  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  4/30 batch 323/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  4/30 batch 324/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  4/30 batch 325/375  Train Loss: 0.099, Acc: 0.969\n",
      "epoch:  4/30 batch 326/375  Train Loss: 0.065, Acc: 0.992\n",
      "epoch:  4/30 batch 327/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  4/30 batch 328/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  4/30 batch 329/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  4/30 batch 330/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  4/30 batch 331/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  4/30 batch 332/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  4/30 batch 333/375  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  4/30 batch 334/375  Train Loss: 0.059, Acc: 0.969\n",
      "epoch:  4/30 batch 335/375  Train Loss: 0.070, Acc: 0.992\n",
      "epoch:  4/30 batch 336/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  4/30 batch 337/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  4/30 batch 338/375  Train Loss: 0.136, Acc: 0.977\n",
      "epoch:  4/30 batch 339/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  4/30 batch 340/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  4/30 batch 341/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  4/30 batch 342/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  4/30 batch 343/375  Train Loss: 0.084, Acc: 0.969\n",
      "epoch:  4/30 batch 344/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  4/30 batch 345/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  4/30 batch 346/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  4/30 batch 347/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  4/30 batch 348/375  Train Loss: 0.115, Acc: 0.977\n",
      "epoch:  4/30 batch 349/375  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  4/30 batch 350/375  Train Loss: 0.143, Acc: 0.953\n",
      "epoch:  4/30 batch 351/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch:  4/30 batch 352/375  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  4/30 batch 353/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  4/30 batch 354/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  4/30 batch 355/375  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  4/30 batch 356/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  4/30 batch 357/375  Train Loss: 0.161, Acc: 0.977\n",
      "epoch:  4/30 batch 358/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  4/30 batch 359/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  4/30 batch 360/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  4/30 batch 361/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  4/30 batch 362/375  Train Loss: 0.135, Acc: 0.953\n",
      "epoch:  4/30 batch 363/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  4/30 batch 364/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  4/30 batch 365/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  4/30 batch 366/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch:  4/30 batch 367/375  Train Loss: 0.124, Acc: 0.961\n",
      "epoch:  4/30 batch 368/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  4/30 batch 369/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  4/30 batch 370/375  Train Loss: 0.119, Acc: 0.961\n",
      "epoch:  4/30 batch 371/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  4/30 batch 372/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  4/30 batch 373/375  Train Loss: 0.093, Acc: 0.977\n",
      "epoch:  4/30 batch 374/375  Train Loss: 0.091, Acc: 0.984\n",
      "Train Loss: 0.068556, Acc: 0.978\n",
      "Val Loss: 0.087375, Acc: 0.973\n",
      "epoch:  5/30 batch   0/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  5/30 batch   1/375  Train Loss: 0.061, Acc: 0.969\n",
      "epoch:  5/30 batch   2/375  Train Loss: 0.033, Acc: 1.000\n",
      "epoch:  5/30 batch   3/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  5/30 batch   4/375  Train Loss: 0.156, Acc: 0.969\n",
      "epoch:  5/30 batch   5/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  5/30 batch   6/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  5/30 batch   7/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  5/30 batch   8/375  Train Loss: 0.089, Acc: 0.961\n",
      "epoch:  5/30 batch   9/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  5/30 batch  10/375  Train Loss: 0.079, Acc: 0.992\n",
      "epoch:  5/30 batch  11/375  Train Loss: 0.147, Acc: 0.969\n",
      "epoch:  5/30 batch  12/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  5/30 batch  13/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  5/30 batch  14/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  5/30 batch  15/375  Train Loss: 0.187, Acc: 0.945\n",
      "epoch:  5/30 batch  16/375  Train Loss: 0.112, Acc: 0.977\n",
      "epoch:  5/30 batch  17/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  5/30 batch  18/375  Train Loss: 0.068, Acc: 0.969\n",
      "epoch:  5/30 batch  19/375  Train Loss: 0.084, Acc: 0.969\n",
      "epoch:  5/30 batch  20/375  Train Loss: 0.090, Acc: 0.961\n",
      "epoch:  5/30 batch  21/375  Train Loss: 0.213, Acc: 0.938\n",
      "epoch:  5/30 batch  22/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  5/30 batch  23/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  5/30 batch  24/375  Train Loss: 0.111, Acc: 0.984\n",
      "epoch:  5/30 batch  25/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  5/30 batch  26/375  Train Loss: 0.220, Acc: 0.922\n",
      "epoch:  5/30 batch  27/375  Train Loss: 0.118, Acc: 0.969\n",
      "epoch:  5/30 batch  28/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  5/30 batch  29/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  5/30 batch  30/375  Train Loss: 0.083, Acc: 0.961\n",
      "epoch:  5/30 batch  31/375  Train Loss: 0.125, Acc: 0.930\n",
      "epoch:  5/30 batch  32/375  Train Loss: 0.168, Acc: 0.945\n",
      "epoch:  5/30 batch  33/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  5/30 batch  34/375  Train Loss: 0.024, Acc: 1.000\n",
      "epoch:  5/30 batch  35/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  5/30 batch  36/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  5/30 batch  37/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  5/30 batch  38/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch:  5/30 batch  39/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  5/30 batch  40/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  5/30 batch  41/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  5/30 batch  42/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch:  5/30 batch  43/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  5/30 batch  44/375  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  5/30 batch  45/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  5/30 batch  46/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  5/30 batch  47/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  5/30 batch  48/375  Train Loss: 0.097, Acc: 0.984\n",
      "epoch:  5/30 batch  49/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  5/30 batch  50/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  5/30 batch  51/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch:  5/30 batch  52/375  Train Loss: 0.107, Acc: 0.984\n",
      "epoch:  5/30 batch  53/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  5/30 batch  54/375  Train Loss: 0.113, Acc: 0.961\n",
      "epoch:  5/30 batch  55/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  5/30 batch  56/375  Train Loss: 0.127, Acc: 0.961\n",
      "epoch:  5/30 batch  57/375  Train Loss: 0.117, Acc: 0.969\n",
      "epoch:  5/30 batch  58/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch:  5/30 batch  59/375  Train Loss: 0.147, Acc: 0.961\n",
      "epoch:  5/30 batch  60/375  Train Loss: 0.127, Acc: 0.961\n",
      "epoch:  5/30 batch  61/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  5/30 batch  62/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch:  5/30 batch  63/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  5/30 batch  64/375  Train Loss: 0.027, Acc: 1.000\n",
      "epoch:  5/30 batch  65/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  5/30 batch  66/375  Train Loss: 0.079, Acc: 0.984\n",
      "epoch:  5/30 batch  67/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  5/30 batch  68/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  5/30 batch  69/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  5/30 batch  70/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  5/30 batch  71/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  5/30 batch  72/375  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  5/30 batch  73/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  5/30 batch  74/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch:  5/30 batch  75/375  Train Loss: 0.072, Acc: 0.984\n",
      "epoch:  5/30 batch  76/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch:  5/30 batch  77/375  Train Loss: 0.148, Acc: 0.969\n",
      "epoch:  5/30 batch  78/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  5/30 batch  79/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  5/30 batch  80/375  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  5/30 batch  81/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  5/30 batch  82/375  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  5/30 batch  83/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  5/30 batch  84/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  5/30 batch  85/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  5/30 batch  86/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  5/30 batch  87/375  Train Loss: 0.133, Acc: 0.961\n",
      "epoch:  5/30 batch  88/375  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  5/30 batch  89/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  5/30 batch  90/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  5/30 batch  91/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  5/30 batch  92/375  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  5/30 batch  93/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  5/30 batch  94/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch:  5/30 batch  95/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch:  5/30 batch  96/375  Train Loss: 0.136, Acc: 0.969\n",
      "epoch:  5/30 batch  97/375  Train Loss: 0.111, Acc: 0.961\n",
      "epoch:  5/30 batch  98/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  5/30 batch  99/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  5/30 batch 100/375  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  5/30 batch 101/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  5/30 batch 102/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch:  5/30 batch 103/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  5/30 batch 104/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch:  5/30 batch 105/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  5/30 batch 106/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  5/30 batch 107/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch:  5/30 batch 108/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  5/30 batch 109/375  Train Loss: 0.084, Acc: 0.984\n",
      "epoch:  5/30 batch 110/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  5/30 batch 111/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  5/30 batch 112/375  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  5/30 batch 113/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch:  5/30 batch 114/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  5/30 batch 115/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  5/30 batch 116/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  5/30 batch 117/375  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  5/30 batch 118/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  5/30 batch 119/375  Train Loss: 0.033, Acc: 0.977\n",
      "epoch:  5/30 batch 120/375  Train Loss: 0.100, Acc: 0.984\n",
      "epoch:  5/30 batch 121/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  5/30 batch 122/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  5/30 batch 123/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  5/30 batch 124/375  Train Loss: 0.103, Acc: 0.977\n",
      "epoch:  5/30 batch 125/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  5/30 batch 126/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  5/30 batch 127/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  5/30 batch 128/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  5/30 batch 129/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  5/30 batch 130/375  Train Loss: 0.072, Acc: 0.984\n",
      "epoch:  5/30 batch 131/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  5/30 batch 132/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  5/30 batch 133/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  5/30 batch 134/375  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  5/30 batch 135/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  5/30 batch 136/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  5/30 batch 137/375  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  5/30 batch 138/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  5/30 batch 139/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  5/30 batch 140/375  Train Loss: 0.105, Acc: 0.984\n",
      "epoch:  5/30 batch 141/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  5/30 batch 142/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch:  5/30 batch 143/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  5/30 batch 144/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  5/30 batch 145/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  5/30 batch 146/375  Train Loss: 0.038, Acc: 0.977\n",
      "epoch:  5/30 batch 147/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  5/30 batch 148/375  Train Loss: 0.235, Acc: 0.945\n",
      "epoch:  5/30 batch 149/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  5/30 batch 150/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  5/30 batch 151/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  5/30 batch 152/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  5/30 batch 153/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  5/30 batch 154/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  5/30 batch 155/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch:  5/30 batch 156/375  Train Loss: 0.057, Acc: 0.992\n",
      "epoch:  5/30 batch 157/375  Train Loss: 0.042, Acc: 0.969\n",
      "epoch:  5/30 batch 158/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  5/30 batch 159/375  Train Loss: 0.140, Acc: 0.961\n",
      "epoch:  5/30 batch 160/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  5/30 batch 161/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  5/30 batch 162/375  Train Loss: 0.150, Acc: 0.969\n",
      "epoch:  5/30 batch 163/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  5/30 batch 164/375  Train Loss: 0.038, Acc: 0.977\n",
      "epoch:  5/30 batch 165/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch:  5/30 batch 166/375  Train Loss: 0.130, Acc: 0.953\n",
      "epoch:  5/30 batch 167/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  5/30 batch 168/375  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  5/30 batch 169/375  Train Loss: 0.069, Acc: 0.969\n",
      "epoch:  5/30 batch 170/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  5/30 batch 171/375  Train Loss: 0.093, Acc: 0.953\n",
      "epoch:  5/30 batch 172/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  5/30 batch 173/375  Train Loss: 0.051, Acc: 0.969\n",
      "epoch:  5/30 batch 174/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  5/30 batch 175/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  5/30 batch 176/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  5/30 batch 177/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  5/30 batch 178/375  Train Loss: 0.107, Acc: 0.961\n",
      "epoch:  5/30 batch 179/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  5/30 batch 180/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch:  5/30 batch 181/375  Train Loss: 0.057, Acc: 0.969\n",
      "epoch:  5/30 batch 182/375  Train Loss: 0.109, Acc: 0.977\n",
      "epoch:  5/30 batch 183/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  5/30 batch 184/375  Train Loss: 0.138, Acc: 0.961\n",
      "epoch:  5/30 batch 185/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  5/30 batch 186/375  Train Loss: 0.069, Acc: 0.969\n",
      "epoch:  5/30 batch 187/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  5/30 batch 188/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  5/30 batch 189/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  5/30 batch 190/375  Train Loss: 0.065, Acc: 0.961\n",
      "epoch:  5/30 batch 191/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch:  5/30 batch 192/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch:  5/30 batch 193/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  5/30 batch 194/375  Train Loss: 0.101, Acc: 0.961\n",
      "epoch:  5/30 batch 195/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  5/30 batch 196/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch:  5/30 batch 197/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch:  5/30 batch 198/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  5/30 batch 199/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  5/30 batch 200/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  5/30 batch 201/375  Train Loss: 0.051, Acc: 0.969\n",
      "epoch:  5/30 batch 202/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  5/30 batch 203/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  5/30 batch 204/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  5/30 batch 205/375  Train Loss: 0.059, Acc: 0.992\n",
      "epoch:  5/30 batch 206/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  5/30 batch 207/375  Train Loss: 0.084, Acc: 0.969\n",
      "epoch:  5/30 batch 208/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  5/30 batch 209/375  Train Loss: 0.057, Acc: 0.969\n",
      "epoch:  5/30 batch 210/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  5/30 batch 211/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  5/30 batch 212/375  Train Loss: 0.058, Acc: 0.992\n",
      "epoch:  5/30 batch 213/375  Train Loss: 0.122, Acc: 0.953\n",
      "epoch:  5/30 batch 214/375  Train Loss: 0.108, Acc: 0.977\n",
      "epoch:  5/30 batch 215/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch:  5/30 batch 216/375  Train Loss: 0.124, Acc: 0.969\n",
      "epoch:  5/30 batch 217/375  Train Loss: 0.109, Acc: 0.969\n",
      "epoch:  5/30 batch 218/375  Train Loss: 0.066, Acc: 0.992\n",
      "epoch:  5/30 batch 219/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  5/30 batch 220/375  Train Loss: 0.090, Acc: 0.984\n",
      "epoch:  5/30 batch 221/375  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  5/30 batch 222/375  Train Loss: 0.085, Acc: 0.953\n",
      "epoch:  5/30 batch 223/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  5/30 batch 224/375  Train Loss: 0.072, Acc: 0.984\n",
      "epoch:  5/30 batch 225/375  Train Loss: 0.066, Acc: 0.961\n",
      "epoch:  5/30 batch 226/375  Train Loss: 0.106, Acc: 0.945\n",
      "epoch:  5/30 batch 227/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  5/30 batch 228/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  5/30 batch 229/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  5/30 batch 230/375  Train Loss: 0.100, Acc: 0.969\n",
      "epoch:  5/30 batch 231/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  5/30 batch 232/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  5/30 batch 233/375  Train Loss: 0.105, Acc: 0.977\n",
      "epoch:  5/30 batch 234/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch:  5/30 batch 235/375  Train Loss: 0.072, Acc: 0.969\n",
      "epoch:  5/30 batch 236/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  5/30 batch 237/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  5/30 batch 238/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  5/30 batch 239/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  5/30 batch 240/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  5/30 batch 241/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  5/30 batch 242/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  5/30 batch 243/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch:  5/30 batch 244/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  5/30 batch 245/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  5/30 batch 246/375  Train Loss: 0.034, Acc: 0.977\n",
      "epoch:  5/30 batch 247/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  5/30 batch 248/375  Train Loss: 0.038, Acc: 0.969\n",
      "epoch:  5/30 batch 249/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  5/30 batch 250/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  5/30 batch 251/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  5/30 batch 252/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  5/30 batch 253/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  5/30 batch 254/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  5/30 batch 255/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  5/30 batch 256/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  5/30 batch 257/375  Train Loss: 0.056, Acc: 0.969\n",
      "epoch:  5/30 batch 258/375  Train Loss: 0.097, Acc: 0.984\n",
      "epoch:  5/30 batch 259/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch:  5/30 batch 260/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  5/30 batch 261/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  5/30 batch 262/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  5/30 batch 263/375  Train Loss: 0.100, Acc: 0.984\n",
      "epoch:  5/30 batch 264/375  Train Loss: 0.182, Acc: 0.938\n",
      "epoch:  5/30 batch 265/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  5/30 batch 266/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  5/30 batch 267/375  Train Loss: 0.143, Acc: 0.938\n",
      "epoch:  5/30 batch 268/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  5/30 batch 269/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  5/30 batch 270/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  5/30 batch 271/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  5/30 batch 272/375  Train Loss: 0.114, Acc: 0.961\n",
      "epoch:  5/30 batch 273/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  5/30 batch 274/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  5/30 batch 275/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  5/30 batch 276/375  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  5/30 batch 277/375  Train Loss: 0.134, Acc: 0.938\n",
      "epoch:  5/30 batch 278/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  5/30 batch 279/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch:  5/30 batch 280/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  5/30 batch 281/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  5/30 batch 282/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  5/30 batch 283/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  5/30 batch 284/375  Train Loss: 0.088, Acc: 0.953\n",
      "epoch:  5/30 batch 285/375  Train Loss: 0.155, Acc: 0.961\n",
      "epoch:  5/30 batch 286/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  5/30 batch 287/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  5/30 batch 288/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  5/30 batch 289/375  Train Loss: 0.117, Acc: 0.977\n",
      "epoch:  5/30 batch 290/375  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  5/30 batch 291/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  5/30 batch 292/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch:  5/30 batch 293/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  5/30 batch 294/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  5/30 batch 295/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  5/30 batch 296/375  Train Loss: 0.227, Acc: 0.961\n",
      "epoch:  5/30 batch 297/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  5/30 batch 298/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  5/30 batch 299/375  Train Loss: 0.117, Acc: 0.953\n",
      "epoch:  5/30 batch 300/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  5/30 batch 301/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  5/30 batch 302/375  Train Loss: 0.108, Acc: 0.969\n",
      "epoch:  5/30 batch 303/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  5/30 batch 304/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  5/30 batch 305/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  5/30 batch 306/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch:  5/30 batch 307/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch:  5/30 batch 308/375  Train Loss: 0.095, Acc: 0.977\n",
      "epoch:  5/30 batch 309/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  5/30 batch 310/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  5/30 batch 311/375  Train Loss: 0.073, Acc: 0.992\n",
      "epoch:  5/30 batch 312/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch:  5/30 batch 313/375  Train Loss: 0.096, Acc: 0.984\n",
      "epoch:  5/30 batch 314/375  Train Loss: 0.152, Acc: 0.945\n",
      "epoch:  5/30 batch 315/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  5/30 batch 316/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  5/30 batch 317/375  Train Loss: 0.077, Acc: 0.984\n",
      "epoch:  5/30 batch 318/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  5/30 batch 319/375  Train Loss: 0.105, Acc: 0.953\n",
      "epoch:  5/30 batch 320/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch:  5/30 batch 321/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  5/30 batch 322/375  Train Loss: 0.158, Acc: 0.953\n",
      "epoch:  5/30 batch 323/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  5/30 batch 324/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  5/30 batch 325/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  5/30 batch 326/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  5/30 batch 327/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  5/30 batch 328/375  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  5/30 batch 329/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  5/30 batch 330/375  Train Loss: 0.075, Acc: 0.984\n",
      "epoch:  5/30 batch 331/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  5/30 batch 332/375  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  5/30 batch 333/375  Train Loss: 0.090, Acc: 0.984\n",
      "epoch:  5/30 batch 334/375  Train Loss: 0.149, Acc: 0.938\n",
      "epoch:  5/30 batch 335/375  Train Loss: 0.190, Acc: 0.930\n",
      "epoch:  5/30 batch 336/375  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  5/30 batch 337/375  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  5/30 batch 338/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  5/30 batch 339/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  5/30 batch 340/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  5/30 batch 341/375  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  5/30 batch 342/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  5/30 batch 343/375  Train Loss: 0.115, Acc: 0.953\n",
      "epoch:  5/30 batch 344/375  Train Loss: 0.154, Acc: 0.977\n",
      "epoch:  5/30 batch 345/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch:  5/30 batch 346/375  Train Loss: 0.085, Acc: 0.961\n",
      "epoch:  5/30 batch 347/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  5/30 batch 348/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  5/30 batch 349/375  Train Loss: 0.056, Acc: 0.969\n",
      "epoch:  5/30 batch 350/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  5/30 batch 351/375  Train Loss: 0.171, Acc: 0.953\n",
      "epoch:  5/30 batch 352/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  5/30 batch 353/375  Train Loss: 0.110, Acc: 0.953\n",
      "epoch:  5/30 batch 354/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  5/30 batch 355/375  Train Loss: 0.094, Acc: 0.969\n",
      "epoch:  5/30 batch 356/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  5/30 batch 357/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  5/30 batch 358/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  5/30 batch 359/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch:  5/30 batch 360/375  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  5/30 batch 361/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  5/30 batch 362/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  5/30 batch 363/375  Train Loss: 0.132, Acc: 0.961\n",
      "epoch:  5/30 batch 364/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  5/30 batch 365/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch:  5/30 batch 366/375  Train Loss: 0.144, Acc: 0.953\n",
      "epoch:  5/30 batch 367/375  Train Loss: 0.129, Acc: 0.961\n",
      "epoch:  5/30 batch 368/375  Train Loss: 0.098, Acc: 0.984\n",
      "epoch:  5/30 batch 369/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  5/30 batch 370/375  Train Loss: 0.113, Acc: 0.969\n",
      "epoch:  5/30 batch 371/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  5/30 batch 372/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch:  5/30 batch 373/375  Train Loss: 0.086, Acc: 0.961\n",
      "epoch:  5/30 batch 374/375  Train Loss: 0.125, Acc: 0.961\n",
      "Train Loss: 0.067766, Acc: 0.979\n",
      "Val Loss: 0.068118, Acc: 0.979\n",
      "epoch:  6/30 batch   0/375  Train Loss: 0.145, Acc: 0.953\n",
      "epoch:  6/30 batch   1/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  6/30 batch   2/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  6/30 batch   3/375  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  6/30 batch   4/375  Train Loss: 0.109, Acc: 0.961\n",
      "epoch:  6/30 batch   5/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  6/30 batch   6/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  6/30 batch   7/375  Train Loss: 0.161, Acc: 0.953\n",
      "epoch:  6/30 batch   8/375  Train Loss: 0.097, Acc: 0.945\n",
      "epoch:  6/30 batch   9/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  6/30 batch  10/375  Train Loss: 0.119, Acc: 0.969\n",
      "epoch:  6/30 batch  11/375  Train Loss: 0.113, Acc: 0.961\n",
      "epoch:  6/30 batch  12/375  Train Loss: 0.168, Acc: 0.938\n",
      "epoch:  6/30 batch  13/375  Train Loss: 0.050, Acc: 0.969\n",
      "epoch:  6/30 batch  14/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch:  6/30 batch  15/375  Train Loss: 0.079, Acc: 0.984\n",
      "epoch:  6/30 batch  16/375  Train Loss: 0.115, Acc: 0.969\n",
      "epoch:  6/30 batch  17/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  6/30 batch  18/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  6/30 batch  19/375  Train Loss: 0.104, Acc: 0.969\n",
      "epoch:  6/30 batch  20/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch:  6/30 batch  21/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  6/30 batch  22/375  Train Loss: 0.103, Acc: 0.977\n",
      "epoch:  6/30 batch  23/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  6/30 batch  24/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch:  6/30 batch  25/375  Train Loss: 0.116, Acc: 0.969\n",
      "epoch:  6/30 batch  26/375  Train Loss: 0.065, Acc: 0.969\n",
      "epoch:  6/30 batch  27/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch:  6/30 batch  28/375  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  6/30 batch  29/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  6/30 batch  30/375  Train Loss: 0.399, Acc: 0.898\n",
      "epoch:  6/30 batch  31/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  6/30 batch  32/375  Train Loss: 0.134, Acc: 0.969\n",
      "epoch:  6/30 batch  33/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  6/30 batch  34/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  6/30 batch  35/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  6/30 batch  36/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  6/30 batch  37/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  6/30 batch  38/375  Train Loss: 0.211, Acc: 0.953\n",
      "epoch:  6/30 batch  39/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  6/30 batch  40/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  6/30 batch  41/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  6/30 batch  42/375  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  6/30 batch  43/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  6/30 batch  44/375  Train Loss: 0.183, Acc: 0.977\n",
      "epoch:  6/30 batch  45/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch:  6/30 batch  46/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  6/30 batch  47/375  Train Loss: 0.091, Acc: 0.977\n",
      "epoch:  6/30 batch  48/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  6/30 batch  49/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  6/30 batch  50/375  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  6/30 batch  51/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  6/30 batch  52/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  6/30 batch  53/375  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  6/30 batch  54/375  Train Loss: 0.095, Acc: 0.961\n",
      "epoch:  6/30 batch  55/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  6/30 batch  56/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  6/30 batch  57/375  Train Loss: 0.131, Acc: 0.969\n",
      "epoch:  6/30 batch  58/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  6/30 batch  59/375  Train Loss: 0.063, Acc: 0.992\n",
      "epoch:  6/30 batch  60/375  Train Loss: 0.108, Acc: 0.953\n",
      "epoch:  6/30 batch  61/375  Train Loss: 0.078, Acc: 0.984\n",
      "epoch:  6/30 batch  62/375  Train Loss: 0.081, Acc: 0.984\n",
      "epoch:  6/30 batch  63/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  6/30 batch  64/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  6/30 batch  65/375  Train Loss: 0.121, Acc: 0.969\n",
      "epoch:  6/30 batch  66/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch:  6/30 batch  67/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  6/30 batch  68/375  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  6/30 batch  69/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  6/30 batch  70/375  Train Loss: 0.084, Acc: 0.969\n",
      "epoch:  6/30 batch  71/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  6/30 batch  72/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  6/30 batch  73/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch:  6/30 batch  74/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  6/30 batch  75/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch:  6/30 batch  76/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  6/30 batch  77/375  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  6/30 batch  78/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  6/30 batch  79/375  Train Loss: 0.104, Acc: 0.961\n",
      "epoch:  6/30 batch  80/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  6/30 batch  81/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch:  6/30 batch  82/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch:  6/30 batch  83/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  6/30 batch  84/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  6/30 batch  85/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  6/30 batch  86/375  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  6/30 batch  87/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  6/30 batch  88/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  6/30 batch  89/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  6/30 batch  90/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  6/30 batch  91/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch:  6/30 batch  92/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  6/30 batch  93/375  Train Loss: 0.137, Acc: 0.938\n",
      "epoch:  6/30 batch  94/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  6/30 batch  95/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  6/30 batch  96/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  6/30 batch  97/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  6/30 batch  98/375  Train Loss: 0.133, Acc: 0.992\n",
      "epoch:  6/30 batch  99/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  6/30 batch 100/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  6/30 batch 101/375  Train Loss: 0.071, Acc: 0.961\n",
      "epoch:  6/30 batch 102/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  6/30 batch 103/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  6/30 batch 104/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  6/30 batch 105/375  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  6/30 batch 106/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  6/30 batch 107/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  6/30 batch 108/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch:  6/30 batch 109/375  Train Loss: 0.137, Acc: 0.977\n",
      "epoch:  6/30 batch 110/375  Train Loss: 0.138, Acc: 0.961\n",
      "epoch:  6/30 batch 111/375  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  6/30 batch 112/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  6/30 batch 113/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch:  6/30 batch 114/375  Train Loss: 0.106, Acc: 0.938\n",
      "epoch:  6/30 batch 115/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  6/30 batch 116/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch:  6/30 batch 117/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  6/30 batch 118/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  6/30 batch 119/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  6/30 batch 120/375  Train Loss: 0.179, Acc: 0.953\n",
      "epoch:  6/30 batch 121/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  6/30 batch 122/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  6/30 batch 123/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  6/30 batch 124/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  6/30 batch 125/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch:  6/30 batch 126/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  6/30 batch 127/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  6/30 batch 128/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  6/30 batch 129/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  6/30 batch 130/375  Train Loss: 0.099, Acc: 0.961\n",
      "epoch:  6/30 batch 131/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  6/30 batch 132/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  6/30 batch 133/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  6/30 batch 134/375  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  6/30 batch 135/375  Train Loss: 0.095, Acc: 0.969\n",
      "epoch:  6/30 batch 136/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  6/30 batch 137/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch:  6/30 batch 138/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  6/30 batch 139/375  Train Loss: 0.120, Acc: 0.945\n",
      "epoch:  6/30 batch 140/375  Train Loss: 0.090, Acc: 0.961\n",
      "epoch:  6/30 batch 141/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  6/30 batch 142/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  6/30 batch 143/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  6/30 batch 144/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  6/30 batch 145/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  6/30 batch 146/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  6/30 batch 147/375  Train Loss: 0.116, Acc: 0.953\n",
      "epoch:  6/30 batch 148/375  Train Loss: 0.154, Acc: 0.945\n",
      "epoch:  6/30 batch 149/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch:  6/30 batch 150/375  Train Loss: 0.117, Acc: 0.984\n",
      "epoch:  6/30 batch 151/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch:  6/30 batch 152/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  6/30 batch 153/375  Train Loss: 0.066, Acc: 0.969\n",
      "epoch:  6/30 batch 154/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  6/30 batch 155/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  6/30 batch 156/375  Train Loss: 0.030, Acc: 0.977\n",
      "epoch:  6/30 batch 157/375  Train Loss: 0.065, Acc: 0.969\n",
      "epoch:  6/30 batch 158/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  6/30 batch 159/375  Train Loss: 0.111, Acc: 0.984\n",
      "epoch:  6/30 batch 160/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  6/30 batch 161/375  Train Loss: 0.138, Acc: 0.969\n",
      "epoch:  6/30 batch 162/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  6/30 batch 163/375  Train Loss: 0.113, Acc: 0.938\n",
      "epoch:  6/30 batch 164/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch:  6/30 batch 165/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  6/30 batch 166/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  6/30 batch 167/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  6/30 batch 168/375  Train Loss: 0.156, Acc: 0.977\n",
      "epoch:  6/30 batch 169/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  6/30 batch 170/375  Train Loss: 0.072, Acc: 0.984\n",
      "epoch:  6/30 batch 171/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  6/30 batch 172/375  Train Loss: 0.035, Acc: 0.977\n",
      "epoch:  6/30 batch 173/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  6/30 batch 174/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  6/30 batch 175/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  6/30 batch 176/375  Train Loss: 0.096, Acc: 0.977\n",
      "epoch:  6/30 batch 177/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch:  6/30 batch 178/375  Train Loss: 0.090, Acc: 0.969\n",
      "epoch:  6/30 batch 179/375  Train Loss: 0.080, Acc: 0.961\n",
      "epoch:  6/30 batch 180/375  Train Loss: 0.130, Acc: 0.969\n",
      "epoch:  6/30 batch 181/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  6/30 batch 182/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  6/30 batch 183/375  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  6/30 batch 184/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  6/30 batch 185/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  6/30 batch 186/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  6/30 batch 187/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  6/30 batch 188/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  6/30 batch 189/375  Train Loss: 0.170, Acc: 0.953\n",
      "epoch:  6/30 batch 190/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  6/30 batch 191/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  6/30 batch 192/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  6/30 batch 193/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch:  6/30 batch 194/375  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  6/30 batch 195/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch:  6/30 batch 196/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  6/30 batch 197/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  6/30 batch 198/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  6/30 batch 199/375  Train Loss: 0.066, Acc: 0.961\n",
      "epoch:  6/30 batch 200/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  6/30 batch 201/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch:  6/30 batch 202/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  6/30 batch 203/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  6/30 batch 204/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  6/30 batch 205/375  Train Loss: 0.083, Acc: 0.969\n",
      "epoch:  6/30 batch 206/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  6/30 batch 207/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  6/30 batch 208/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  6/30 batch 209/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  6/30 batch 210/375  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  6/30 batch 211/375  Train Loss: 0.093, Acc: 0.953\n",
      "epoch:  6/30 batch 212/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch:  6/30 batch 213/375  Train Loss: 0.066, Acc: 0.961\n",
      "epoch:  6/30 batch 214/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  6/30 batch 215/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  6/30 batch 216/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  6/30 batch 217/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  6/30 batch 218/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  6/30 batch 219/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch:  6/30 batch 220/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch:  6/30 batch 221/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch:  6/30 batch 222/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  6/30 batch 223/375  Train Loss: 0.113, Acc: 0.961\n",
      "epoch:  6/30 batch 224/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  6/30 batch 225/375  Train Loss: 0.097, Acc: 0.961\n",
      "epoch:  6/30 batch 226/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  6/30 batch 227/375  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  6/30 batch 228/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  6/30 batch 229/375  Train Loss: 0.110, Acc: 0.977\n",
      "epoch:  6/30 batch 230/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  6/30 batch 231/375  Train Loss: 0.116, Acc: 0.953\n",
      "epoch:  6/30 batch 232/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  6/30 batch 233/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  6/30 batch 234/375  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  6/30 batch 235/375  Train Loss: 0.067, Acc: 0.984\n",
      "epoch:  6/30 batch 236/375  Train Loss: 0.030, Acc: 1.000\n",
      "epoch:  6/30 batch 237/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  6/30 batch 238/375  Train Loss: 0.095, Acc: 0.961\n",
      "epoch:  6/30 batch 239/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch:  6/30 batch 240/375  Train Loss: 0.185, Acc: 0.938\n",
      "epoch:  6/30 batch 241/375  Train Loss: 0.072, Acc: 0.984\n",
      "epoch:  6/30 batch 242/375  Train Loss: 0.092, Acc: 0.961\n",
      "epoch:  6/30 batch 243/375  Train Loss: 0.118, Acc: 0.969\n",
      "epoch:  6/30 batch 244/375  Train Loss: 0.147, Acc: 0.945\n",
      "epoch:  6/30 batch 245/375  Train Loss: 0.100, Acc: 0.977\n",
      "epoch:  6/30 batch 246/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  6/30 batch 247/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  6/30 batch 248/375  Train Loss: 0.112, Acc: 0.961\n",
      "epoch:  6/30 batch 249/375  Train Loss: 0.132, Acc: 0.953\n",
      "epoch:  6/30 batch 250/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  6/30 batch 251/375  Train Loss: 0.152, Acc: 0.945\n",
      "epoch:  6/30 batch 252/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  6/30 batch 253/375  Train Loss: 0.095, Acc: 0.969\n",
      "epoch:  6/30 batch 254/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  6/30 batch 255/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  6/30 batch 256/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  6/30 batch 257/375  Train Loss: 0.118, Acc: 0.969\n",
      "epoch:  6/30 batch 258/375  Train Loss: 0.128, Acc: 0.953\n",
      "epoch:  6/30 batch 259/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  6/30 batch 260/375  Train Loss: 0.125, Acc: 0.969\n",
      "epoch:  6/30 batch 261/375  Train Loss: 0.064, Acc: 0.992\n",
      "epoch:  6/30 batch 262/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch:  6/30 batch 263/375  Train Loss: 0.066, Acc: 0.969\n",
      "epoch:  6/30 batch 264/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch:  6/30 batch 265/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  6/30 batch 266/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  6/30 batch 267/375  Train Loss: 0.105, Acc: 0.977\n",
      "epoch:  6/30 batch 268/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  6/30 batch 269/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  6/30 batch 270/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  6/30 batch 271/375  Train Loss: 0.100, Acc: 0.969\n",
      "epoch:  6/30 batch 272/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  6/30 batch 273/375  Train Loss: 0.125, Acc: 0.961\n",
      "epoch:  6/30 batch 274/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  6/30 batch 275/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch:  6/30 batch 276/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  6/30 batch 277/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  6/30 batch 278/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch:  6/30 batch 279/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch:  6/30 batch 280/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  6/30 batch 281/375  Train Loss: 0.102, Acc: 0.953\n",
      "epoch:  6/30 batch 282/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  6/30 batch 283/375  Train Loss: 0.129, Acc: 0.969\n",
      "epoch:  6/30 batch 284/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  6/30 batch 285/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch:  6/30 batch 286/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  6/30 batch 287/375  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  6/30 batch 288/375  Train Loss: 0.120, Acc: 0.969\n",
      "epoch:  6/30 batch 289/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  6/30 batch 290/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  6/30 batch 291/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  6/30 batch 292/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  6/30 batch 293/375  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  6/30 batch 294/375  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  6/30 batch 295/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  6/30 batch 296/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch:  6/30 batch 297/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  6/30 batch 298/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  6/30 batch 299/375  Train Loss: 0.111, Acc: 0.977\n",
      "epoch:  6/30 batch 300/375  Train Loss: 0.120, Acc: 0.953\n",
      "epoch:  6/30 batch 301/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  6/30 batch 302/375  Train Loss: 0.065, Acc: 0.969\n",
      "epoch:  6/30 batch 303/375  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  6/30 batch 304/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  6/30 batch 305/375  Train Loss: 0.068, Acc: 0.969\n",
      "epoch:  6/30 batch 306/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  6/30 batch 307/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  6/30 batch 308/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  6/30 batch 309/375  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  6/30 batch 310/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  6/30 batch 311/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  6/30 batch 312/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  6/30 batch 313/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  6/30 batch 314/375  Train Loss: 0.072, Acc: 0.992\n",
      "epoch:  6/30 batch 315/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  6/30 batch 316/375  Train Loss: 0.086, Acc: 0.961\n",
      "epoch:  6/30 batch 317/375  Train Loss: 0.122, Acc: 0.969\n",
      "epoch:  6/30 batch 318/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  6/30 batch 319/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  6/30 batch 320/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  6/30 batch 321/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  6/30 batch 322/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  6/30 batch 323/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  6/30 batch 324/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  6/30 batch 325/375  Train Loss: 0.139, Acc: 0.961\n",
      "epoch:  6/30 batch 326/375  Train Loss: 0.176, Acc: 0.953\n",
      "epoch:  6/30 batch 327/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  6/30 batch 328/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  6/30 batch 329/375  Train Loss: 0.087, Acc: 0.992\n",
      "epoch:  6/30 batch 330/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  6/30 batch 331/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  6/30 batch 332/375  Train Loss: 0.136, Acc: 0.953\n",
      "epoch:  6/30 batch 333/375  Train Loss: 0.090, Acc: 0.984\n",
      "epoch:  6/30 batch 334/375  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  6/30 batch 335/375  Train Loss: 0.109, Acc: 0.961\n",
      "epoch:  6/30 batch 336/375  Train Loss: 0.071, Acc: 0.969\n",
      "epoch:  6/30 batch 337/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  6/30 batch 338/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  6/30 batch 339/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  6/30 batch 340/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  6/30 batch 341/375  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  6/30 batch 342/375  Train Loss: 0.058, Acc: 0.992\n",
      "epoch:  6/30 batch 343/375  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  6/30 batch 344/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  6/30 batch 345/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  6/30 batch 346/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  6/30 batch 347/375  Train Loss: 0.152, Acc: 0.953\n",
      "epoch:  6/30 batch 348/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch:  6/30 batch 349/375  Train Loss: 0.084, Acc: 0.961\n",
      "epoch:  6/30 batch 350/375  Train Loss: 0.116, Acc: 0.977\n",
      "epoch:  6/30 batch 351/375  Train Loss: 0.121, Acc: 0.961\n",
      "epoch:  6/30 batch 352/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  6/30 batch 353/375  Train Loss: 0.145, Acc: 0.969\n",
      "epoch:  6/30 batch 354/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  6/30 batch 355/375  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  6/30 batch 356/375  Train Loss: 0.130, Acc: 0.961\n",
      "epoch:  6/30 batch 357/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch:  6/30 batch 358/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  6/30 batch 359/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  6/30 batch 360/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  6/30 batch 361/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  6/30 batch 362/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  6/30 batch 363/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch:  6/30 batch 364/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  6/30 batch 365/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  6/30 batch 366/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  6/30 batch 367/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  6/30 batch 368/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  6/30 batch 369/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  6/30 batch 370/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  6/30 batch 371/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  6/30 batch 372/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  6/30 batch 373/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  6/30 batch 374/375  Train Loss: 0.085, Acc: 0.977\n",
      "Train Loss: 0.069415, Acc: 0.978\n",
      "Val Loss: 0.072997, Acc: 0.978\n",
      "epoch:  7/30 batch   0/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  7/30 batch   1/375  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  7/30 batch   2/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  7/30 batch   3/375  Train Loss: 0.134, Acc: 0.953\n",
      "epoch:  7/30 batch   4/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  7/30 batch   5/375  Train Loss: 0.361, Acc: 0.906\n",
      "epoch:  7/30 batch   6/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  7/30 batch   7/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  7/30 batch   8/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  7/30 batch   9/375  Train Loss: 0.156, Acc: 0.938\n",
      "epoch:  7/30 batch  10/375  Train Loss: 0.116, Acc: 0.953\n",
      "epoch:  7/30 batch  11/375  Train Loss: 0.074, Acc: 0.961\n",
      "epoch:  7/30 batch  12/375  Train Loss: 0.117, Acc: 0.984\n",
      "epoch:  7/30 batch  13/375  Train Loss: 0.114, Acc: 0.961\n",
      "epoch:  7/30 batch  14/375  Train Loss: 0.066, Acc: 0.961\n",
      "epoch:  7/30 batch  15/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  7/30 batch  16/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  7/30 batch  17/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  7/30 batch  18/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  7/30 batch  19/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  7/30 batch  20/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch:  7/30 batch  21/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  7/30 batch  22/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch:  7/30 batch  23/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  7/30 batch  24/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  7/30 batch  25/375  Train Loss: 0.161, Acc: 0.992\n",
      "epoch:  7/30 batch  26/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch:  7/30 batch  27/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  7/30 batch  28/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  7/30 batch  29/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  7/30 batch  30/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  7/30 batch  31/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  7/30 batch  32/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  7/30 batch  33/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  7/30 batch  34/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  7/30 batch  35/375  Train Loss: 0.114, Acc: 0.969\n",
      "epoch:  7/30 batch  36/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  7/30 batch  37/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch:  7/30 batch  38/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  7/30 batch  39/375  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  7/30 batch  40/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  7/30 batch  41/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  7/30 batch  42/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch:  7/30 batch  43/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch:  7/30 batch  44/375  Train Loss: 0.072, Acc: 0.969\n",
      "epoch:  7/30 batch  45/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  7/30 batch  46/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  7/30 batch  47/375  Train Loss: 0.062, Acc: 0.969\n",
      "epoch:  7/30 batch  48/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  7/30 batch  49/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  7/30 batch  50/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  7/30 batch  51/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  7/30 batch  52/375  Train Loss: 0.118, Acc: 0.953\n",
      "epoch:  7/30 batch  53/375  Train Loss: 0.073, Acc: 0.961\n",
      "epoch:  7/30 batch  54/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  7/30 batch  55/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  7/30 batch  56/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch:  7/30 batch  57/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  7/30 batch  58/375  Train Loss: 0.110, Acc: 0.992\n",
      "epoch:  7/30 batch  59/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  7/30 batch  60/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  7/30 batch  61/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  7/30 batch  62/375  Train Loss: 0.093, Acc: 0.977\n",
      "epoch:  7/30 batch  63/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  7/30 batch  64/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  7/30 batch  65/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  7/30 batch  66/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  7/30 batch  67/375  Train Loss: 0.097, Acc: 0.969\n",
      "epoch:  7/30 batch  68/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch:  7/30 batch  69/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch:  7/30 batch  70/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  7/30 batch  71/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  7/30 batch  72/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  7/30 batch  73/375  Train Loss: 0.032, Acc: 0.977\n",
      "epoch:  7/30 batch  74/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  7/30 batch  75/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  7/30 batch  76/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  7/30 batch  77/375  Train Loss: 0.080, Acc: 0.984\n",
      "epoch:  7/30 batch  78/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  7/30 batch  79/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  7/30 batch  80/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch:  7/30 batch  81/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  7/30 batch  82/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  7/30 batch  83/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch:  7/30 batch  84/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  7/30 batch  85/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  7/30 batch  86/375  Train Loss: 0.087, Acc: 0.984\n",
      "epoch:  7/30 batch  87/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  7/30 batch  88/375  Train Loss: 0.108, Acc: 0.969\n",
      "epoch:  7/30 batch  89/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  7/30 batch  90/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch:  7/30 batch  91/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  7/30 batch  92/375  Train Loss: 0.087, Acc: 0.977\n",
      "epoch:  7/30 batch  93/375  Train Loss: 0.052, Acc: 0.969\n",
      "epoch:  7/30 batch  94/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch:  7/30 batch  95/375  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  7/30 batch  96/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  7/30 batch  97/375  Train Loss: 0.091, Acc: 0.961\n",
      "epoch:  7/30 batch  98/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  7/30 batch  99/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  7/30 batch 100/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch:  7/30 batch 101/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch:  7/30 batch 102/375  Train Loss: 0.133, Acc: 0.961\n",
      "epoch:  7/30 batch 103/375  Train Loss: 0.083, Acc: 0.984\n",
      "epoch:  7/30 batch 104/375  Train Loss: 0.060, Acc: 0.992\n",
      "epoch:  7/30 batch 105/375  Train Loss: 0.161, Acc: 0.945\n",
      "epoch:  7/30 batch 106/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  7/30 batch 107/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  7/30 batch 108/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  7/30 batch 109/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  7/30 batch 110/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  7/30 batch 111/375  Train Loss: 0.144, Acc: 0.953\n",
      "epoch:  7/30 batch 112/375  Train Loss: 0.070, Acc: 0.961\n",
      "epoch:  7/30 batch 113/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  7/30 batch 114/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  7/30 batch 115/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  7/30 batch 116/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  7/30 batch 117/375  Train Loss: 0.086, Acc: 0.961\n",
      "epoch:  7/30 batch 118/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  7/30 batch 119/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch:  7/30 batch 120/375  Train Loss: 0.066, Acc: 0.969\n",
      "epoch:  7/30 batch 121/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  7/30 batch 122/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch:  7/30 batch 123/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  7/30 batch 124/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  7/30 batch 125/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  7/30 batch 126/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch:  7/30 batch 127/375  Train Loss: 0.029, Acc: 1.000\n",
      "epoch:  7/30 batch 128/375  Train Loss: 0.096, Acc: 0.977\n",
      "epoch:  7/30 batch 129/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  7/30 batch 130/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  7/30 batch 131/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch:  7/30 batch 132/375  Train Loss: 0.087, Acc: 0.961\n",
      "epoch:  7/30 batch 133/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  7/30 batch 134/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  7/30 batch 135/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  7/30 batch 136/375  Train Loss: 0.131, Acc: 0.969\n",
      "epoch:  7/30 batch 137/375  Train Loss: 0.109, Acc: 0.969\n",
      "epoch:  7/30 batch 138/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  7/30 batch 139/375  Train Loss: 0.168, Acc: 0.961\n",
      "epoch:  7/30 batch 140/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  7/30 batch 141/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  7/30 batch 142/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  7/30 batch 143/375  Train Loss: 0.127, Acc: 0.961\n",
      "epoch:  7/30 batch 144/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  7/30 batch 145/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch:  7/30 batch 146/375  Train Loss: 0.061, Acc: 0.969\n",
      "epoch:  7/30 batch 147/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  7/30 batch 148/375  Train Loss: 0.129, Acc: 0.961\n",
      "epoch:  7/30 batch 149/375  Train Loss: 0.122, Acc: 0.961\n",
      "epoch:  7/30 batch 150/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  7/30 batch 151/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  7/30 batch 152/375  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  7/30 batch 153/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  7/30 batch 154/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  7/30 batch 155/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch:  7/30 batch 156/375  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  7/30 batch 157/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  7/30 batch 158/375  Train Loss: 0.035, Acc: 0.977\n",
      "epoch:  7/30 batch 159/375  Train Loss: 0.142, Acc: 0.961\n",
      "epoch:  7/30 batch 160/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  7/30 batch 161/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  7/30 batch 162/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  7/30 batch 163/375  Train Loss: 0.144, Acc: 0.961\n",
      "epoch:  7/30 batch 164/375  Train Loss: 0.063, Acc: 0.992\n",
      "epoch:  7/30 batch 165/375  Train Loss: 0.193, Acc: 0.938\n",
      "epoch:  7/30 batch 166/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch:  7/30 batch 167/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  7/30 batch 168/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  7/30 batch 169/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  7/30 batch 170/375  Train Loss: 0.091, Acc: 0.984\n",
      "epoch:  7/30 batch 171/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  7/30 batch 172/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch:  7/30 batch 173/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch:  7/30 batch 174/375  Train Loss: 0.101, Acc: 0.961\n",
      "epoch:  7/30 batch 175/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  7/30 batch 176/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch:  7/30 batch 177/375  Train Loss: 0.059, Acc: 0.969\n",
      "epoch:  7/30 batch 178/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  7/30 batch 179/375  Train Loss: 0.093, Acc: 0.953\n",
      "epoch:  7/30 batch 180/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  7/30 batch 181/375  Train Loss: 0.047, Acc: 0.961\n",
      "epoch:  7/30 batch 182/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  7/30 batch 183/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  7/30 batch 184/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  7/30 batch 185/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch:  7/30 batch 186/375  Train Loss: 0.069, Acc: 0.969\n",
      "epoch:  7/30 batch 187/375  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  7/30 batch 188/375  Train Loss: 0.028, Acc: 1.000\n",
      "epoch:  7/30 batch 189/375  Train Loss: 0.118, Acc: 0.953\n",
      "epoch:  7/30 batch 190/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  7/30 batch 191/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  7/30 batch 192/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  7/30 batch 193/375  Train Loss: 0.157, Acc: 0.969\n",
      "epoch:  7/30 batch 194/375  Train Loss: 0.165, Acc: 0.953\n",
      "epoch:  7/30 batch 195/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch:  7/30 batch 196/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  7/30 batch 197/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch:  7/30 batch 198/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  7/30 batch 199/375  Train Loss: 0.109, Acc: 0.961\n",
      "epoch:  7/30 batch 200/375  Train Loss: 0.126, Acc: 0.953\n",
      "epoch:  7/30 batch 201/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  7/30 batch 202/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  7/30 batch 203/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  7/30 batch 204/375  Train Loss: 0.135, Acc: 0.969\n",
      "epoch:  7/30 batch 205/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  7/30 batch 206/375  Train Loss: 0.114, Acc: 0.969\n",
      "epoch:  7/30 batch 207/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  7/30 batch 208/375  Train Loss: 0.130, Acc: 0.938\n",
      "epoch:  7/30 batch 209/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  7/30 batch 210/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch:  7/30 batch 211/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch:  7/30 batch 212/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  7/30 batch 213/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  7/30 batch 214/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch:  7/30 batch 215/375  Train Loss: 0.088, Acc: 0.961\n",
      "epoch:  7/30 batch 216/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch:  7/30 batch 217/375  Train Loss: 0.093, Acc: 0.961\n",
      "epoch:  7/30 batch 218/375  Train Loss: 0.063, Acc: 0.969\n",
      "epoch:  7/30 batch 219/375  Train Loss: 0.140, Acc: 0.953\n",
      "epoch:  7/30 batch 220/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  7/30 batch 221/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  7/30 batch 222/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch:  7/30 batch 223/375  Train Loss: 0.031, Acc: 0.977\n",
      "epoch:  7/30 batch 224/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  7/30 batch 225/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch:  7/30 batch 226/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  7/30 batch 227/375  Train Loss: 0.063, Acc: 0.969\n",
      "epoch:  7/30 batch 228/375  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  7/30 batch 229/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  7/30 batch 230/375  Train Loss: 0.116, Acc: 0.977\n",
      "epoch:  7/30 batch 231/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch:  7/30 batch 232/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  7/30 batch 233/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch:  7/30 batch 234/375  Train Loss: 0.090, Acc: 0.961\n",
      "epoch:  7/30 batch 235/375  Train Loss: 0.194, Acc: 0.953\n",
      "epoch:  7/30 batch 236/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  7/30 batch 237/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  7/30 batch 238/375  Train Loss: 0.094, Acc: 0.961\n",
      "epoch:  7/30 batch 239/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch:  7/30 batch 240/375  Train Loss: 0.156, Acc: 0.961\n",
      "epoch:  7/30 batch 241/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch:  7/30 batch 242/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  7/30 batch 243/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  7/30 batch 244/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  7/30 batch 245/375  Train Loss: 0.041, Acc: 0.969\n",
      "epoch:  7/30 batch 246/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  7/30 batch 247/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  7/30 batch 248/375  Train Loss: 0.132, Acc: 0.969\n",
      "epoch:  7/30 batch 249/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  7/30 batch 250/375  Train Loss: 0.134, Acc: 0.945\n",
      "epoch:  7/30 batch 251/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  7/30 batch 252/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  7/30 batch 253/375  Train Loss: 0.108, Acc: 0.953\n",
      "epoch:  7/30 batch 254/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  7/30 batch 255/375  Train Loss: 0.116, Acc: 0.977\n",
      "epoch:  7/30 batch 256/375  Train Loss: 0.113, Acc: 0.969\n",
      "epoch:  7/30 batch 257/375  Train Loss: 0.088, Acc: 0.961\n",
      "epoch:  7/30 batch 258/375  Train Loss: 0.051, Acc: 0.969\n",
      "epoch:  7/30 batch 259/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  7/30 batch 260/375  Train Loss: 0.143, Acc: 0.953\n",
      "epoch:  7/30 batch 261/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  7/30 batch 262/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  7/30 batch 263/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  7/30 batch 264/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  7/30 batch 265/375  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  7/30 batch 266/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  7/30 batch 267/375  Train Loss: 0.076, Acc: 0.992\n",
      "epoch:  7/30 batch 268/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  7/30 batch 269/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch:  7/30 batch 270/375  Train Loss: 0.050, Acc: 0.969\n",
      "epoch:  7/30 batch 271/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  7/30 batch 272/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  7/30 batch 273/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  7/30 batch 274/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch:  7/30 batch 275/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  7/30 batch 276/375  Train Loss: 0.084, Acc: 0.984\n",
      "epoch:  7/30 batch 277/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  7/30 batch 278/375  Train Loss: 0.126, Acc: 0.977\n",
      "epoch:  7/30 batch 279/375  Train Loss: 0.104, Acc: 0.977\n",
      "epoch:  7/30 batch 280/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  7/30 batch 281/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch:  7/30 batch 282/375  Train Loss: 0.198, Acc: 0.938\n",
      "epoch:  7/30 batch 283/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch:  7/30 batch 284/375  Train Loss: 0.083, Acc: 0.984\n",
      "epoch:  7/30 batch 285/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  7/30 batch 286/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  7/30 batch 287/375  Train Loss: 0.087, Acc: 0.961\n",
      "epoch:  7/30 batch 288/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  7/30 batch 289/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  7/30 batch 290/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch:  7/30 batch 291/375  Train Loss: 0.132, Acc: 0.953\n",
      "epoch:  7/30 batch 292/375  Train Loss: 0.094, Acc: 0.984\n",
      "epoch:  7/30 batch 293/375  Train Loss: 0.112, Acc: 0.961\n",
      "epoch:  7/30 batch 294/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch:  7/30 batch 295/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  7/30 batch 296/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  7/30 batch 297/375  Train Loss: 0.108, Acc: 0.969\n",
      "epoch:  7/30 batch 298/375  Train Loss: 0.088, Acc: 0.953\n",
      "epoch:  7/30 batch 299/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch:  7/30 batch 300/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  7/30 batch 301/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  7/30 batch 302/375  Train Loss: 0.106, Acc: 0.969\n",
      "epoch:  7/30 batch 303/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  7/30 batch 304/375  Train Loss: 0.086, Acc: 0.984\n",
      "epoch:  7/30 batch 305/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  7/30 batch 306/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  7/30 batch 307/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  7/30 batch 308/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  7/30 batch 309/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch:  7/30 batch 310/375  Train Loss: 0.080, Acc: 0.984\n",
      "epoch:  7/30 batch 311/375  Train Loss: 0.069, Acc: 0.992\n",
      "epoch:  7/30 batch 312/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch:  7/30 batch 313/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch:  7/30 batch 314/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  7/30 batch 315/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  7/30 batch 316/375  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  7/30 batch 317/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  7/30 batch 318/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  7/30 batch 319/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  7/30 batch 320/375  Train Loss: 0.085, Acc: 0.961\n",
      "epoch:  7/30 batch 321/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch:  7/30 batch 322/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  7/30 batch 323/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch:  7/30 batch 324/375  Train Loss: 0.143, Acc: 0.977\n",
      "epoch:  7/30 batch 325/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  7/30 batch 326/375  Train Loss: 0.168, Acc: 0.930\n",
      "epoch:  7/30 batch 327/375  Train Loss: 0.089, Acc: 0.961\n",
      "epoch:  7/30 batch 328/375  Train Loss: 0.118, Acc: 0.969\n",
      "epoch:  7/30 batch 329/375  Train Loss: 0.083, Acc: 0.961\n",
      "epoch:  7/30 batch 330/375  Train Loss: 0.171, Acc: 0.938\n",
      "epoch:  7/30 batch 331/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  7/30 batch 332/375  Train Loss: 0.118, Acc: 0.969\n",
      "epoch:  7/30 batch 333/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  7/30 batch 334/375  Train Loss: 0.096, Acc: 0.961\n",
      "epoch:  7/30 batch 335/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch:  7/30 batch 336/375  Train Loss: 0.073, Acc: 0.984\n",
      "epoch:  7/30 batch 337/375  Train Loss: 0.106, Acc: 0.969\n",
      "epoch:  7/30 batch 338/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  7/30 batch 339/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch:  7/30 batch 340/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  7/30 batch 341/375  Train Loss: 0.073, Acc: 0.961\n",
      "epoch:  7/30 batch 342/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  7/30 batch 343/375  Train Loss: 0.124, Acc: 0.969\n",
      "epoch:  7/30 batch 344/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  7/30 batch 345/375  Train Loss: 0.061, Acc: 0.969\n",
      "epoch:  7/30 batch 346/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  7/30 batch 347/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch:  7/30 batch 348/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  7/30 batch 349/375  Train Loss: 0.181, Acc: 0.938\n",
      "epoch:  7/30 batch 350/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  7/30 batch 351/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  7/30 batch 352/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  7/30 batch 353/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  7/30 batch 354/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  7/30 batch 355/375  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  7/30 batch 356/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  7/30 batch 357/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch:  7/30 batch 358/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  7/30 batch 359/375  Train Loss: 0.073, Acc: 0.992\n",
      "epoch:  7/30 batch 360/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  7/30 batch 361/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  7/30 batch 362/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  7/30 batch 363/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch:  7/30 batch 364/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch:  7/30 batch 365/375  Train Loss: 0.064, Acc: 0.992\n",
      "epoch:  7/30 batch 366/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  7/30 batch 367/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  7/30 batch 368/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  7/30 batch 369/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  7/30 batch 370/375  Train Loss: 0.096, Acc: 0.977\n",
      "epoch:  7/30 batch 371/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  7/30 batch 372/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  7/30 batch 373/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  7/30 batch 374/375  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.065098, Acc: 0.979\n",
      "Val Loss: 0.101730, Acc: 0.969\n",
      "epoch:  8/30 batch   0/375  Train Loss: 0.121, Acc: 0.969\n",
      "epoch:  8/30 batch   1/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  8/30 batch   2/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch:  8/30 batch   3/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch:  8/30 batch   4/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  8/30 batch   5/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  8/30 batch   6/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  8/30 batch   7/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  8/30 batch   8/375  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  8/30 batch   9/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  8/30 batch  10/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  8/30 batch  11/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch:  8/30 batch  12/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  8/30 batch  13/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  8/30 batch  14/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  8/30 batch  15/375  Train Loss: 0.124, Acc: 0.961\n",
      "epoch:  8/30 batch  16/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch:  8/30 batch  17/375  Train Loss: 0.087, Acc: 0.984\n",
      "epoch:  8/30 batch  18/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  8/30 batch  19/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  8/30 batch  20/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch:  8/30 batch  21/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  8/30 batch  22/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  8/30 batch  23/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch:  8/30 batch  24/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch:  8/30 batch  25/375  Train Loss: 0.092, Acc: 0.961\n",
      "epoch:  8/30 batch  26/375  Train Loss: 0.173, Acc: 0.953\n",
      "epoch:  8/30 batch  27/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  8/30 batch  28/375  Train Loss: 0.112, Acc: 0.969\n",
      "epoch:  8/30 batch  29/375  Train Loss: 0.055, Acc: 0.969\n",
      "epoch:  8/30 batch  30/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  8/30 batch  31/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch:  8/30 batch  32/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  8/30 batch  33/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  8/30 batch  34/375  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  8/30 batch  35/375  Train Loss: 0.069, Acc: 0.969\n",
      "epoch:  8/30 batch  36/375  Train Loss: 0.062, Acc: 0.969\n",
      "epoch:  8/30 batch  37/375  Train Loss: 0.065, Acc: 0.969\n",
      "epoch:  8/30 batch  38/375  Train Loss: 0.103, Acc: 0.961\n",
      "epoch:  8/30 batch  39/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  8/30 batch  40/375  Train Loss: 0.075, Acc: 0.984\n",
      "epoch:  8/30 batch  41/375  Train Loss: 0.045, Acc: 0.969\n",
      "epoch:  8/30 batch  42/375  Train Loss: 0.060, Acc: 0.992\n",
      "epoch:  8/30 batch  43/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  8/30 batch  44/375  Train Loss: 0.101, Acc: 0.953\n",
      "epoch:  8/30 batch  45/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  8/30 batch  46/375  Train Loss: 0.141, Acc: 0.969\n",
      "epoch:  8/30 batch  47/375  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  8/30 batch  48/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  8/30 batch  49/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  8/30 batch  50/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch:  8/30 batch  51/375  Train Loss: 0.056, Acc: 0.961\n",
      "epoch:  8/30 batch  52/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch:  8/30 batch  53/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch:  8/30 batch  54/375  Train Loss: 0.116, Acc: 0.969\n",
      "epoch:  8/30 batch  55/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  8/30 batch  56/375  Train Loss: 0.098, Acc: 0.945\n",
      "epoch:  8/30 batch  57/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch:  8/30 batch  58/375  Train Loss: 0.064, Acc: 0.992\n",
      "epoch:  8/30 batch  59/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  8/30 batch  60/375  Train Loss: 0.117, Acc: 0.984\n",
      "epoch:  8/30 batch  61/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  8/30 batch  62/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch:  8/30 batch  63/375  Train Loss: 0.116, Acc: 0.969\n",
      "epoch:  8/30 batch  64/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch:  8/30 batch  65/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  8/30 batch  66/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  8/30 batch  67/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  8/30 batch  68/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch:  8/30 batch  69/375  Train Loss: 0.124, Acc: 0.953\n",
      "epoch:  8/30 batch  70/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  8/30 batch  71/375  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  8/30 batch  72/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  8/30 batch  73/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  8/30 batch  74/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  8/30 batch  75/375  Train Loss: 0.101, Acc: 0.977\n",
      "epoch:  8/30 batch  76/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  8/30 batch  77/375  Train Loss: 0.135, Acc: 0.969\n",
      "epoch:  8/30 batch  78/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  8/30 batch  79/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  8/30 batch  80/375  Train Loss: 0.102, Acc: 0.961\n",
      "epoch:  8/30 batch  81/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch:  8/30 batch  82/375  Train Loss: 0.074, Acc: 0.961\n",
      "epoch:  8/30 batch  83/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  8/30 batch  84/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  8/30 batch  85/375  Train Loss: 0.133, Acc: 0.953\n",
      "epoch:  8/30 batch  86/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  8/30 batch  87/375  Train Loss: 0.099, Acc: 0.969\n",
      "epoch:  8/30 batch  88/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  8/30 batch  89/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  8/30 batch  90/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  8/30 batch  91/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  8/30 batch  92/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  8/30 batch  93/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch:  8/30 batch  94/375  Train Loss: 0.095, Acc: 0.977\n",
      "epoch:  8/30 batch  95/375  Train Loss: 0.164, Acc: 0.945\n",
      "epoch:  8/30 batch  96/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch:  8/30 batch  97/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  8/30 batch  98/375  Train Loss: 0.087, Acc: 0.984\n",
      "epoch:  8/30 batch  99/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  8/30 batch 100/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  8/30 batch 101/375  Train Loss: 0.078, Acc: 0.977\n",
      "epoch:  8/30 batch 102/375  Train Loss: 0.116, Acc: 0.961\n",
      "epoch:  8/30 batch 103/375  Train Loss: 0.111, Acc: 0.969\n",
      "epoch:  8/30 batch 104/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  8/30 batch 105/375  Train Loss: 0.143, Acc: 0.961\n",
      "epoch:  8/30 batch 106/375  Train Loss: 0.032, Acc: 1.000\n",
      "epoch:  8/30 batch 107/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  8/30 batch 108/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  8/30 batch 109/375  Train Loss: 0.090, Acc: 0.984\n",
      "epoch:  8/30 batch 110/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  8/30 batch 111/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch:  8/30 batch 112/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  8/30 batch 113/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  8/30 batch 114/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  8/30 batch 115/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  8/30 batch 116/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  8/30 batch 117/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch:  8/30 batch 118/375  Train Loss: 0.050, Acc: 0.969\n",
      "epoch:  8/30 batch 119/375  Train Loss: 0.086, Acc: 0.961\n",
      "epoch:  8/30 batch 120/375  Train Loss: 0.102, Acc: 0.984\n",
      "epoch:  8/30 batch 121/375  Train Loss: 0.083, Acc: 0.969\n",
      "epoch:  8/30 batch 122/375  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  8/30 batch 123/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch:  8/30 batch 124/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch:  8/30 batch 125/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  8/30 batch 126/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch:  8/30 batch 127/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  8/30 batch 128/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  8/30 batch 129/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  8/30 batch 130/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  8/30 batch 131/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  8/30 batch 132/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch:  8/30 batch 133/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  8/30 batch 134/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  8/30 batch 135/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  8/30 batch 136/375  Train Loss: 0.217, Acc: 0.938\n",
      "epoch:  8/30 batch 137/375  Train Loss: 0.091, Acc: 0.961\n",
      "epoch:  8/30 batch 138/375  Train Loss: 0.080, Acc: 0.984\n",
      "epoch:  8/30 batch 139/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  8/30 batch 140/375  Train Loss: 0.139, Acc: 0.969\n",
      "epoch:  8/30 batch 141/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch:  8/30 batch 142/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch:  8/30 batch 143/375  Train Loss: 0.028, Acc: 1.000\n",
      "epoch:  8/30 batch 144/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  8/30 batch 145/375  Train Loss: 0.181, Acc: 0.938\n",
      "epoch:  8/30 batch 146/375  Train Loss: 0.128, Acc: 0.969\n",
      "epoch:  8/30 batch 147/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  8/30 batch 148/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  8/30 batch 149/375  Train Loss: 0.089, Acc: 0.969\n",
      "epoch:  8/30 batch 150/375  Train Loss: 0.098, Acc: 0.969\n",
      "epoch:  8/30 batch 151/375  Train Loss: 0.159, Acc: 0.938\n",
      "epoch:  8/30 batch 152/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  8/30 batch 153/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  8/30 batch 154/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  8/30 batch 155/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  8/30 batch 156/375  Train Loss: 0.067, Acc: 0.969\n",
      "epoch:  8/30 batch 157/375  Train Loss: 0.117, Acc: 0.961\n",
      "epoch:  8/30 batch 158/375  Train Loss: 0.063, Acc: 0.969\n",
      "epoch:  8/30 batch 159/375  Train Loss: 0.148, Acc: 0.969\n",
      "epoch:  8/30 batch 160/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch:  8/30 batch 161/375  Train Loss: 0.092, Acc: 0.969\n",
      "epoch:  8/30 batch 162/375  Train Loss: 0.096, Acc: 0.961\n",
      "epoch:  8/30 batch 163/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  8/30 batch 164/375  Train Loss: 0.095, Acc: 0.977\n",
      "epoch:  8/30 batch 165/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  8/30 batch 166/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  8/30 batch 167/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  8/30 batch 168/375  Train Loss: 0.099, Acc: 0.969\n",
      "epoch:  8/30 batch 169/375  Train Loss: 0.075, Acc: 0.984\n",
      "epoch:  8/30 batch 170/375  Train Loss: 0.115, Acc: 0.977\n",
      "epoch:  8/30 batch 171/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  8/30 batch 172/375  Train Loss: 0.114, Acc: 0.961\n",
      "epoch:  8/30 batch 173/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  8/30 batch 174/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  8/30 batch 175/375  Train Loss: 0.182, Acc: 0.945\n",
      "epoch:  8/30 batch 176/375  Train Loss: 0.060, Acc: 0.992\n",
      "epoch:  8/30 batch 177/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  8/30 batch 178/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  8/30 batch 179/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  8/30 batch 180/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  8/30 batch 181/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  8/30 batch 182/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  8/30 batch 183/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  8/30 batch 184/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  8/30 batch 185/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  8/30 batch 186/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  8/30 batch 187/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch:  8/30 batch 188/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  8/30 batch 189/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  8/30 batch 190/375  Train Loss: 0.143, Acc: 0.961\n",
      "epoch:  8/30 batch 191/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  8/30 batch 192/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  8/30 batch 193/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  8/30 batch 194/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch:  8/30 batch 195/375  Train Loss: 0.149, Acc: 0.953\n",
      "epoch:  8/30 batch 196/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  8/30 batch 197/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  8/30 batch 198/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  8/30 batch 199/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch:  8/30 batch 200/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  8/30 batch 201/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch:  8/30 batch 202/375  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  8/30 batch 203/375  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  8/30 batch 204/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch:  8/30 batch 205/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch:  8/30 batch 206/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  8/30 batch 207/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  8/30 batch 208/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  8/30 batch 209/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  8/30 batch 210/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  8/30 batch 211/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  8/30 batch 212/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  8/30 batch 213/375  Train Loss: 0.077, Acc: 0.984\n",
      "epoch:  8/30 batch 214/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  8/30 batch 215/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  8/30 batch 216/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  8/30 batch 217/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  8/30 batch 218/375  Train Loss: 0.060, Acc: 0.992\n",
      "epoch:  8/30 batch 219/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  8/30 batch 220/375  Train Loss: 0.062, Acc: 0.969\n",
      "epoch:  8/30 batch 221/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  8/30 batch 222/375  Train Loss: 0.184, Acc: 0.984\n",
      "epoch:  8/30 batch 223/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  8/30 batch 224/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  8/30 batch 225/375  Train Loss: 0.102, Acc: 0.977\n",
      "epoch:  8/30 batch 226/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  8/30 batch 227/375  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  8/30 batch 228/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  8/30 batch 229/375  Train Loss: 0.150, Acc: 0.938\n",
      "epoch:  8/30 batch 230/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  8/30 batch 231/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  8/30 batch 232/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  8/30 batch 233/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  8/30 batch 234/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  8/30 batch 235/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  8/30 batch 236/375  Train Loss: 0.085, Acc: 0.953\n",
      "epoch:  8/30 batch 237/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch:  8/30 batch 238/375  Train Loss: 0.082, Acc: 0.961\n",
      "epoch:  8/30 batch 239/375  Train Loss: 0.093, Acc: 0.961\n",
      "epoch:  8/30 batch 240/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch:  8/30 batch 241/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  8/30 batch 242/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  8/30 batch 243/375  Train Loss: 0.149, Acc: 0.961\n",
      "epoch:  8/30 batch 244/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  8/30 batch 245/375  Train Loss: 0.065, Acc: 0.992\n",
      "epoch:  8/30 batch 246/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch:  8/30 batch 247/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch:  8/30 batch 248/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  8/30 batch 249/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch:  8/30 batch 250/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  8/30 batch 251/375  Train Loss: 0.098, Acc: 0.977\n",
      "epoch:  8/30 batch 252/375  Train Loss: 0.034, Acc: 1.000\n",
      "epoch:  8/30 batch 253/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  8/30 batch 254/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  8/30 batch 255/375  Train Loss: 0.073, Acc: 0.961\n",
      "epoch:  8/30 batch 256/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  8/30 batch 257/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  8/30 batch 258/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  8/30 batch 259/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  8/30 batch 260/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  8/30 batch 261/375  Train Loss: 0.097, Acc: 0.984\n",
      "epoch:  8/30 batch 262/375  Train Loss: 0.120, Acc: 0.977\n",
      "epoch:  8/30 batch 263/375  Train Loss: 0.082, Acc: 0.969\n",
      "epoch:  8/30 batch 264/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  8/30 batch 265/375  Train Loss: 0.079, Acc: 0.984\n",
      "epoch:  8/30 batch 266/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  8/30 batch 267/375  Train Loss: 0.107, Acc: 0.977\n",
      "epoch:  8/30 batch 268/375  Train Loss: 0.136, Acc: 0.969\n",
      "epoch:  8/30 batch 269/375  Train Loss: 0.079, Acc: 0.984\n",
      "epoch:  8/30 batch 270/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  8/30 batch 271/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  8/30 batch 272/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  8/30 batch 273/375  Train Loss: 0.079, Acc: 0.953\n",
      "epoch:  8/30 batch 274/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  8/30 batch 275/375  Train Loss: 0.068, Acc: 0.969\n",
      "epoch:  8/30 batch 276/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch:  8/30 batch 277/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  8/30 batch 278/375  Train Loss: 0.069, Acc: 0.953\n",
      "epoch:  8/30 batch 279/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  8/30 batch 280/375  Train Loss: 0.176, Acc: 0.945\n",
      "epoch:  8/30 batch 281/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  8/30 batch 282/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  8/30 batch 283/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  8/30 batch 284/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  8/30 batch 285/375  Train Loss: 0.089, Acc: 0.961\n",
      "epoch:  8/30 batch 286/375  Train Loss: 0.095, Acc: 0.961\n",
      "epoch:  8/30 batch 287/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  8/30 batch 288/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  8/30 batch 289/375  Train Loss: 0.024, Acc: 1.000\n",
      "epoch:  8/30 batch 290/375  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  8/30 batch 291/375  Train Loss: 0.061, Acc: 0.969\n",
      "epoch:  8/30 batch 292/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  8/30 batch 293/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  8/30 batch 294/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch:  8/30 batch 295/375  Train Loss: 0.137, Acc: 0.969\n",
      "epoch:  8/30 batch 296/375  Train Loss: 0.089, Acc: 0.984\n",
      "epoch:  8/30 batch 297/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  8/30 batch 298/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  8/30 batch 299/375  Train Loss: 0.115, Acc: 0.969\n",
      "epoch:  8/30 batch 300/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  8/30 batch 301/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch:  8/30 batch 302/375  Train Loss: 0.173, Acc: 0.953\n",
      "epoch:  8/30 batch 303/375  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  8/30 batch 304/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch:  8/30 batch 305/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  8/30 batch 306/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  8/30 batch 307/375  Train Loss: 0.083, Acc: 0.984\n",
      "epoch:  8/30 batch 308/375  Train Loss: 0.083, Acc: 0.992\n",
      "epoch:  8/30 batch 309/375  Train Loss: 0.087, Acc: 0.961\n",
      "epoch:  8/30 batch 310/375  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  8/30 batch 311/375  Train Loss: 0.131, Acc: 0.953\n",
      "epoch:  8/30 batch 312/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch:  8/30 batch 313/375  Train Loss: 0.119, Acc: 0.984\n",
      "epoch:  8/30 batch 314/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch:  8/30 batch 315/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  8/30 batch 316/375  Train Loss: 0.125, Acc: 0.977\n",
      "epoch:  8/30 batch 317/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch:  8/30 batch 318/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  8/30 batch 319/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch:  8/30 batch 320/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch:  8/30 batch 321/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  8/30 batch 322/375  Train Loss: 0.142, Acc: 0.984\n",
      "epoch:  8/30 batch 323/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch:  8/30 batch 324/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  8/30 batch 325/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch:  8/30 batch 326/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  8/30 batch 327/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  8/30 batch 328/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  8/30 batch 329/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch:  8/30 batch 330/375  Train Loss: 0.063, Acc: 0.969\n",
      "epoch:  8/30 batch 331/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch:  8/30 batch 332/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch:  8/30 batch 333/375  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  8/30 batch 334/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  8/30 batch 335/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch:  8/30 batch 336/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  8/30 batch 337/375  Train Loss: 0.067, Acc: 0.961\n",
      "epoch:  8/30 batch 338/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  8/30 batch 339/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  8/30 batch 340/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  8/30 batch 341/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  8/30 batch 342/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  8/30 batch 343/375  Train Loss: 0.063, Acc: 0.969\n",
      "epoch:  8/30 batch 344/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  8/30 batch 345/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  8/30 batch 346/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  8/30 batch 347/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  8/30 batch 348/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch:  8/30 batch 349/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  8/30 batch 350/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  8/30 batch 351/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  8/30 batch 352/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch:  8/30 batch 353/375  Train Loss: 0.106, Acc: 0.961\n",
      "epoch:  8/30 batch 354/375  Train Loss: 0.097, Acc: 0.977\n",
      "epoch:  8/30 batch 355/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  8/30 batch 356/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  8/30 batch 357/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  8/30 batch 358/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  8/30 batch 359/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  8/30 batch 360/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  8/30 batch 361/375  Train Loss: 0.067, Acc: 0.992\n",
      "epoch:  8/30 batch 362/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  8/30 batch 363/375  Train Loss: 0.200, Acc: 0.945\n",
      "epoch:  8/30 batch 364/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  8/30 batch 365/375  Train Loss: 0.129, Acc: 0.977\n",
      "epoch:  8/30 batch 366/375  Train Loss: 0.126, Acc: 0.984\n",
      "epoch:  8/30 batch 367/375  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  8/30 batch 368/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch:  8/30 batch 369/375  Train Loss: 0.147, Acc: 0.961\n",
      "epoch:  8/30 batch 370/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  8/30 batch 371/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch:  8/30 batch 372/375  Train Loss: 0.076, Acc: 0.969\n",
      "epoch:  8/30 batch 373/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch:  8/30 batch 374/375  Train Loss: 0.043, Acc: 0.984\n",
      "Train Loss: 0.062631, Acc: 0.981\n",
      "Val Loss: 0.056022, Acc: 0.982\n",
      "epoch:  9/30 batch   0/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch:  9/30 batch   1/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  9/30 batch   2/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  9/30 batch   3/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  9/30 batch   4/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  9/30 batch   5/375  Train Loss: 0.095, Acc: 0.977\n",
      "epoch:  9/30 batch   6/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch:  9/30 batch   7/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch:  9/30 batch   8/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch:  9/30 batch   9/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  9/30 batch  10/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  9/30 batch  11/375  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  9/30 batch  12/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  9/30 batch  13/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  9/30 batch  14/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  9/30 batch  15/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  9/30 batch  16/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  9/30 batch  17/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  9/30 batch  18/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  9/30 batch  19/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch:  9/30 batch  20/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch:  9/30 batch  21/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  9/30 batch  22/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  9/30 batch  23/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  9/30 batch  24/375  Train Loss: 0.075, Acc: 0.961\n",
      "epoch:  9/30 batch  25/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch:  9/30 batch  26/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  9/30 batch  27/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  9/30 batch  28/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch:  9/30 batch  29/375  Train Loss: 0.118, Acc: 0.961\n",
      "epoch:  9/30 batch  30/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  9/30 batch  31/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch:  9/30 batch  32/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  9/30 batch  33/375  Train Loss: 0.103, Acc: 0.961\n",
      "epoch:  9/30 batch  34/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  9/30 batch  35/375  Train Loss: 0.118, Acc: 0.969\n",
      "epoch:  9/30 batch  36/375  Train Loss: 0.108, Acc: 0.977\n",
      "epoch:  9/30 batch  37/375  Train Loss: 0.182, Acc: 0.961\n",
      "epoch:  9/30 batch  38/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  9/30 batch  39/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  9/30 batch  40/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch:  9/30 batch  41/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch:  9/30 batch  42/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch:  9/30 batch  43/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  9/30 batch  44/375  Train Loss: 0.098, Acc: 0.961\n",
      "epoch:  9/30 batch  45/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  9/30 batch  46/375  Train Loss: 0.091, Acc: 0.969\n",
      "epoch:  9/30 batch  47/375  Train Loss: 0.084, Acc: 0.984\n",
      "epoch:  9/30 batch  48/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch:  9/30 batch  49/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  9/30 batch  50/375  Train Loss: 0.027, Acc: 1.000\n",
      "epoch:  9/30 batch  51/375  Train Loss: 0.123, Acc: 0.953\n",
      "epoch:  9/30 batch  52/375  Train Loss: 0.072, Acc: 0.992\n",
      "epoch:  9/30 batch  53/375  Train Loss: 0.033, Acc: 1.000\n",
      "epoch:  9/30 batch  54/375  Train Loss: 0.084, Acc: 0.984\n",
      "epoch:  9/30 batch  55/375  Train Loss: 0.128, Acc: 0.977\n",
      "epoch:  9/30 batch  56/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  9/30 batch  57/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  9/30 batch  58/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  9/30 batch  59/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  9/30 batch  60/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  9/30 batch  61/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  9/30 batch  62/375  Train Loss: 0.105, Acc: 0.969\n",
      "epoch:  9/30 batch  63/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch:  9/30 batch  64/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  9/30 batch  65/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  9/30 batch  66/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  9/30 batch  67/375  Train Loss: 0.073, Acc: 0.992\n",
      "epoch:  9/30 batch  68/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch:  9/30 batch  69/375  Train Loss: 0.061, Acc: 0.992\n",
      "epoch:  9/30 batch  70/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch:  9/30 batch  71/375  Train Loss: 0.075, Acc: 0.984\n",
      "epoch:  9/30 batch  72/375  Train Loss: 0.115, Acc: 0.969\n",
      "epoch:  9/30 batch  73/375  Train Loss: 0.096, Acc: 0.961\n",
      "epoch:  9/30 batch  74/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  9/30 batch  75/375  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  9/30 batch  76/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch:  9/30 batch  77/375  Train Loss: 0.180, Acc: 0.953\n",
      "epoch:  9/30 batch  78/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch:  9/30 batch  79/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  9/30 batch  80/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch:  9/30 batch  81/375  Train Loss: 0.150, Acc: 0.977\n",
      "epoch:  9/30 batch  82/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  9/30 batch  83/375  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  9/30 batch  84/375  Train Loss: 0.077, Acc: 0.969\n",
      "epoch:  9/30 batch  85/375  Train Loss: 0.186, Acc: 0.953\n",
      "epoch:  9/30 batch  86/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  9/30 batch  87/375  Train Loss: 0.041, Acc: 1.000\n",
      "epoch:  9/30 batch  88/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  9/30 batch  89/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch:  9/30 batch  90/375  Train Loss: 0.143, Acc: 0.969\n",
      "epoch:  9/30 batch  91/375  Train Loss: 0.089, Acc: 0.984\n",
      "epoch:  9/30 batch  92/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  9/30 batch  93/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  9/30 batch  94/375  Train Loss: 0.092, Acc: 0.961\n",
      "epoch:  9/30 batch  95/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch:  9/30 batch  96/375  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  9/30 batch  97/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch:  9/30 batch  98/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch:  9/30 batch  99/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch:  9/30 batch 100/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch:  9/30 batch 101/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch:  9/30 batch 102/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  9/30 batch 103/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  9/30 batch 104/375  Train Loss: 0.078, Acc: 0.969\n",
      "epoch:  9/30 batch 105/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch:  9/30 batch 106/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch:  9/30 batch 107/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch:  9/30 batch 108/375  Train Loss: 0.084, Acc: 0.977\n",
      "epoch:  9/30 batch 109/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  9/30 batch 110/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  9/30 batch 111/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch:  9/30 batch 112/375  Train Loss: 0.100, Acc: 0.961\n",
      "epoch:  9/30 batch 113/375  Train Loss: 0.070, Acc: 0.969\n",
      "epoch:  9/30 batch 114/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch:  9/30 batch 115/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch:  9/30 batch 116/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  9/30 batch 117/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch:  9/30 batch 118/375  Train Loss: 0.090, Acc: 0.977\n",
      "epoch:  9/30 batch 119/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch:  9/30 batch 120/375  Train Loss: 0.107, Acc: 0.969\n",
      "epoch:  9/30 batch 121/375  Train Loss: 0.046, Acc: 0.969\n",
      "epoch:  9/30 batch 122/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch:  9/30 batch 123/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  9/30 batch 124/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  9/30 batch 125/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  9/30 batch 126/375  Train Loss: 0.096, Acc: 0.961\n",
      "epoch:  9/30 batch 127/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch:  9/30 batch 128/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch:  9/30 batch 129/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  9/30 batch 130/375  Train Loss: 0.091, Acc: 0.953\n",
      "epoch:  9/30 batch 131/375  Train Loss: 0.186, Acc: 0.961\n",
      "epoch:  9/30 batch 132/375  Train Loss: 0.123, Acc: 0.977\n",
      "epoch:  9/30 batch 133/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch:  9/30 batch 134/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  9/30 batch 135/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch:  9/30 batch 136/375  Train Loss: 0.080, Acc: 0.961\n",
      "epoch:  9/30 batch 137/375  Train Loss: 0.173, Acc: 0.945\n",
      "epoch:  9/30 batch 138/375  Train Loss: 0.149, Acc: 0.961\n",
      "epoch:  9/30 batch 139/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  9/30 batch 140/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  9/30 batch 141/375  Train Loss: 0.142, Acc: 0.938\n",
      "epoch:  9/30 batch 142/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch:  9/30 batch 143/375  Train Loss: 0.112, Acc: 0.961\n",
      "epoch:  9/30 batch 144/375  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  9/30 batch 145/375  Train Loss: 0.067, Acc: 0.992\n",
      "epoch:  9/30 batch 146/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  9/30 batch 147/375  Train Loss: 0.128, Acc: 0.961\n",
      "epoch:  9/30 batch 148/375  Train Loss: 0.097, Acc: 0.961\n",
      "epoch:  9/30 batch 149/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  9/30 batch 150/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  9/30 batch 151/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch:  9/30 batch 152/375  Train Loss: 0.068, Acc: 0.992\n",
      "epoch:  9/30 batch 153/375  Train Loss: 0.028, Acc: 1.000\n",
      "epoch:  9/30 batch 154/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  9/30 batch 155/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  9/30 batch 156/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch:  9/30 batch 157/375  Train Loss: 0.096, Acc: 0.977\n",
      "epoch:  9/30 batch 158/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  9/30 batch 159/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch:  9/30 batch 160/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch:  9/30 batch 161/375  Train Loss: 0.085, Acc: 0.977\n",
      "epoch:  9/30 batch 162/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  9/30 batch 163/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch:  9/30 batch 164/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch:  9/30 batch 165/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch:  9/30 batch 166/375  Train Loss: 0.098, Acc: 0.953\n",
      "epoch:  9/30 batch 167/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  9/30 batch 168/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch:  9/30 batch 169/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  9/30 batch 170/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch:  9/30 batch 171/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch:  9/30 batch 172/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  9/30 batch 173/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch:  9/30 batch 174/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch:  9/30 batch 175/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  9/30 batch 176/375  Train Loss: 0.081, Acc: 0.984\n",
      "epoch:  9/30 batch 177/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch:  9/30 batch 178/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch:  9/30 batch 179/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  9/30 batch 180/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  9/30 batch 181/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch:  9/30 batch 182/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch:  9/30 batch 183/375  Train Loss: 0.134, Acc: 0.961\n",
      "epoch:  9/30 batch 184/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  9/30 batch 185/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch:  9/30 batch 186/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  9/30 batch 187/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  9/30 batch 188/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  9/30 batch 189/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  9/30 batch 190/375  Train Loss: 0.096, Acc: 0.984\n",
      "epoch:  9/30 batch 191/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch:  9/30 batch 192/375  Train Loss: 0.208, Acc: 0.945\n",
      "epoch:  9/30 batch 193/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  9/30 batch 194/375  Train Loss: 0.077, Acc: 0.977\n",
      "epoch:  9/30 batch 195/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  9/30 batch 196/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  9/30 batch 197/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  9/30 batch 198/375  Train Loss: 0.088, Acc: 0.977\n",
      "epoch:  9/30 batch 199/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch:  9/30 batch 200/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  9/30 batch 201/375  Train Loss: 0.066, Acc: 0.992\n",
      "epoch:  9/30 batch 202/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  9/30 batch 203/375  Train Loss: 0.073, Acc: 0.953\n",
      "epoch:  9/30 batch 204/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch:  9/30 batch 205/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  9/30 batch 206/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch:  9/30 batch 207/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch:  9/30 batch 208/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  9/30 batch 209/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  9/30 batch 210/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch:  9/30 batch 211/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch:  9/30 batch 212/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  9/30 batch 213/375  Train Loss: 0.103, Acc: 0.953\n",
      "epoch:  9/30 batch 214/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  9/30 batch 215/375  Train Loss: 0.058, Acc: 0.961\n",
      "epoch:  9/30 batch 216/375  Train Loss: 0.121, Acc: 0.961\n",
      "epoch:  9/30 batch 217/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  9/30 batch 218/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch:  9/30 batch 219/375  Train Loss: 0.080, Acc: 0.969\n",
      "epoch:  9/30 batch 220/375  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  9/30 batch 221/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch:  9/30 batch 222/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch:  9/30 batch 223/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch:  9/30 batch 224/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  9/30 batch 225/375  Train Loss: 0.076, Acc: 0.969\n",
      "epoch:  9/30 batch 226/375  Train Loss: 0.093, Acc: 0.969\n",
      "epoch:  9/30 batch 227/375  Train Loss: 0.092, Acc: 0.961\n",
      "epoch:  9/30 batch 228/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  9/30 batch 229/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch:  9/30 batch 230/375  Train Loss: 0.101, Acc: 0.969\n",
      "epoch:  9/30 batch 231/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  9/30 batch 232/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  9/30 batch 233/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  9/30 batch 234/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch:  9/30 batch 235/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch:  9/30 batch 236/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch:  9/30 batch 237/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch:  9/30 batch 238/375  Train Loss: 0.099, Acc: 0.977\n",
      "epoch:  9/30 batch 239/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  9/30 batch 240/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  9/30 batch 241/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  9/30 batch 242/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch:  9/30 batch 243/375  Train Loss: 0.058, Acc: 0.992\n",
      "epoch:  9/30 batch 244/375  Train Loss: 0.159, Acc: 0.961\n",
      "epoch:  9/30 batch 245/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  9/30 batch 246/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  9/30 batch 247/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  9/30 batch 248/375  Train Loss: 0.065, Acc: 0.969\n",
      "epoch:  9/30 batch 249/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  9/30 batch 250/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  9/30 batch 251/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  9/30 batch 252/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  9/30 batch 253/375  Train Loss: 0.104, Acc: 0.977\n",
      "epoch:  9/30 batch 254/375  Train Loss: 0.024, Acc: 1.000\n",
      "epoch:  9/30 batch 255/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  9/30 batch 256/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  9/30 batch 257/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch:  9/30 batch 258/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch:  9/30 batch 259/375  Train Loss: 0.194, Acc: 0.938\n",
      "epoch:  9/30 batch 260/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch:  9/30 batch 261/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  9/30 batch 262/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  9/30 batch 263/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch:  9/30 batch 264/375  Train Loss: 0.075, Acc: 0.984\n",
      "epoch:  9/30 batch 265/375  Train Loss: 0.161, Acc: 0.961\n",
      "epoch:  9/30 batch 266/375  Train Loss: 0.118, Acc: 0.969\n",
      "epoch:  9/30 batch 267/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch:  9/30 batch 268/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch:  9/30 batch 269/375  Train Loss: 0.138, Acc: 0.977\n",
      "epoch:  9/30 batch 270/375  Train Loss: 0.083, Acc: 0.977\n",
      "epoch:  9/30 batch 271/375  Train Loss: 0.100, Acc: 0.977\n",
      "epoch:  9/30 batch 272/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  9/30 batch 273/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch:  9/30 batch 274/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch:  9/30 batch 275/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch:  9/30 batch 276/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  9/30 batch 277/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  9/30 batch 278/375  Train Loss: 0.089, Acc: 0.977\n",
      "epoch:  9/30 batch 279/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch:  9/30 batch 280/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch:  9/30 batch 281/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch:  9/30 batch 282/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch:  9/30 batch 283/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch:  9/30 batch 284/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch:  9/30 batch 285/375  Train Loss: 0.053, Acc: 0.969\n",
      "epoch:  9/30 batch 286/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch:  9/30 batch 287/375  Train Loss: 0.093, Acc: 0.984\n",
      "epoch:  9/30 batch 288/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  9/30 batch 289/375  Train Loss: 0.076, Acc: 0.977\n",
      "epoch:  9/30 batch 290/375  Train Loss: 0.066, Acc: 0.969\n",
      "epoch:  9/30 batch 291/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch:  9/30 batch 292/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch:  9/30 batch 293/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  9/30 batch 294/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch:  9/30 batch 295/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  9/30 batch 296/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  9/30 batch 297/375  Train Loss: 0.205, Acc: 0.969\n",
      "epoch:  9/30 batch 298/375  Train Loss: 0.141, Acc: 0.961\n",
      "epoch:  9/30 batch 299/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch:  9/30 batch 300/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  9/30 batch 301/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  9/30 batch 302/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  9/30 batch 303/375  Train Loss: 0.092, Acc: 0.977\n",
      "epoch:  9/30 batch 304/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch:  9/30 batch 305/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch:  9/30 batch 306/375  Train Loss: 0.075, Acc: 0.992\n",
      "epoch:  9/30 batch 307/375  Train Loss: 0.111, Acc: 0.977\n",
      "epoch:  9/30 batch 308/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch:  9/30 batch 309/375  Train Loss: 0.138, Acc: 0.969\n",
      "epoch:  9/30 batch 310/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch:  9/30 batch 311/375  Train Loss: 0.118, Acc: 0.961\n",
      "epoch:  9/30 batch 312/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch:  9/30 batch 313/375  Train Loss: 0.118, Acc: 0.953\n",
      "epoch:  9/30 batch 314/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch:  9/30 batch 315/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch:  9/30 batch 316/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  9/30 batch 317/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch:  9/30 batch 318/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  9/30 batch 319/375  Train Loss: 0.101, Acc: 0.984\n",
      "epoch:  9/30 batch 320/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch:  9/30 batch 321/375  Train Loss: 0.145, Acc: 0.945\n",
      "epoch:  9/30 batch 322/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch:  9/30 batch 323/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch:  9/30 batch 324/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch:  9/30 batch 325/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  9/30 batch 326/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch:  9/30 batch 327/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch:  9/30 batch 328/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch:  9/30 batch 329/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch:  9/30 batch 330/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch:  9/30 batch 331/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch:  9/30 batch 332/375  Train Loss: 0.118, Acc: 0.945\n",
      "epoch:  9/30 batch 333/375  Train Loss: 0.146, Acc: 0.969\n",
      "epoch:  9/30 batch 334/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch:  9/30 batch 335/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch:  9/30 batch 336/375  Train Loss: 0.050, Acc: 0.969\n",
      "epoch:  9/30 batch 337/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch:  9/30 batch 338/375  Train Loss: 0.108, Acc: 0.969\n",
      "epoch:  9/30 batch 339/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch:  9/30 batch 340/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch:  9/30 batch 341/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch:  9/30 batch 342/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch:  9/30 batch 343/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch:  9/30 batch 344/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch:  9/30 batch 345/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch:  9/30 batch 346/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch:  9/30 batch 347/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch:  9/30 batch 348/375  Train Loss: 0.073, Acc: 0.969\n",
      "epoch:  9/30 batch 349/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch:  9/30 batch 350/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch:  9/30 batch 351/375  Train Loss: 0.032, Acc: 1.000\n",
      "epoch:  9/30 batch 352/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch:  9/30 batch 353/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch:  9/30 batch 354/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch:  9/30 batch 355/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch:  9/30 batch 356/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch:  9/30 batch 357/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch:  9/30 batch 358/375  Train Loss: 0.180, Acc: 0.969\n",
      "epoch:  9/30 batch 359/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch:  9/30 batch 360/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch:  9/30 batch 361/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch:  9/30 batch 362/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch:  9/30 batch 363/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch:  9/30 batch 364/375  Train Loss: 0.092, Acc: 0.961\n",
      "epoch:  9/30 batch 365/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch:  9/30 batch 366/375  Train Loss: 0.087, Acc: 0.969\n",
      "epoch:  9/30 batch 367/375  Train Loss: 0.055, Acc: 0.961\n",
      "epoch:  9/30 batch 368/375  Train Loss: 0.078, Acc: 0.961\n",
      "epoch:  9/30 batch 369/375  Train Loss: 0.101, Acc: 0.961\n",
      "epoch:  9/30 batch 370/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch:  9/30 batch 371/375  Train Loss: 0.078, Acc: 0.961\n",
      "epoch:  9/30 batch 372/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch:  9/30 batch 373/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch:  9/30 batch 374/375  Train Loss: 0.048, Acc: 0.984\n",
      "Train Loss: 0.060676, Acc: 0.981\n",
      "Val Loss: 0.069966, Acc: 0.977\n",
      "epoch: 10/30 batch   0/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 10/30 batch   1/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 10/30 batch   2/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 10/30 batch   3/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 10/30 batch   4/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 10/30 batch   5/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 10/30 batch   6/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 10/30 batch   7/375  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 10/30 batch   8/375  Train Loss: 0.143, Acc: 0.961\n",
      "epoch: 10/30 batch   9/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch  10/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 10/30 batch  11/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 10/30 batch  12/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 10/30 batch  13/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 10/30 batch  14/375  Train Loss: 0.057, Acc: 0.961\n",
      "epoch: 10/30 batch  15/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 10/30 batch  16/375  Train Loss: 0.180, Acc: 0.984\n",
      "epoch: 10/30 batch  17/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 10/30 batch  18/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 10/30 batch  19/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 10/30 batch  20/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 10/30 batch  21/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 10/30 batch  22/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 10/30 batch  23/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 10/30 batch  24/375  Train Loss: 0.094, Acc: 0.969\n",
      "epoch: 10/30 batch  25/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 10/30 batch  26/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 10/30 batch  27/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 10/30 batch  28/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 10/30 batch  29/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 10/30 batch  30/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 10/30 batch  31/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 10/30 batch  32/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 10/30 batch  33/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 10/30 batch  34/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 10/30 batch  35/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch: 10/30 batch  36/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 10/30 batch  37/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 10/30 batch  38/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 10/30 batch  39/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 10/30 batch  40/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 10/30 batch  41/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 10/30 batch  42/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 10/30 batch  43/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 10/30 batch  44/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch  45/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch  46/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 10/30 batch  47/375  Train Loss: 0.150, Acc: 0.938\n",
      "epoch: 10/30 batch  48/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 10/30 batch  49/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 10/30 batch  50/375  Train Loss: 0.099, Acc: 0.984\n",
      "epoch: 10/30 batch  51/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch  52/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 10/30 batch  53/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 10/30 batch  54/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 10/30 batch  55/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 10/30 batch  56/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 10/30 batch  57/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 10/30 batch  58/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 10/30 batch  59/375  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 10/30 batch  60/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch  61/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 10/30 batch  62/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 10/30 batch  63/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 10/30 batch  64/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 10/30 batch  65/375  Train Loss: 0.085, Acc: 0.984\n",
      "epoch: 10/30 batch  66/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 10/30 batch  67/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 10/30 batch  68/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch  69/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 10/30 batch  70/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch  71/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch  72/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 10/30 batch  73/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 10/30 batch  74/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 10/30 batch  75/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 10/30 batch  76/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 10/30 batch  77/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 10/30 batch  78/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 10/30 batch  79/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 10/30 batch  80/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 10/30 batch  81/375  Train Loss: 0.077, Acc: 0.984\n",
      "epoch: 10/30 batch  82/375  Train Loss: 0.074, Acc: 0.969\n",
      "epoch: 10/30 batch  83/375  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 10/30 batch  84/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 10/30 batch  85/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 10/30 batch  86/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 10/30 batch  87/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 10/30 batch  88/375  Train Loss: 0.037, Acc: 0.977\n",
      "epoch: 10/30 batch  89/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 10/30 batch  90/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 10/30 batch  91/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 10/30 batch  92/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 10/30 batch  93/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 10/30 batch  94/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 10/30 batch  95/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 10/30 batch  96/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 10/30 batch  97/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 10/30 batch  98/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 10/30 batch  99/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 10/30 batch 100/375  Train Loss: 0.112, Acc: 0.977\n",
      "epoch: 10/30 batch 101/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 10/30 batch 102/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 10/30 batch 103/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch 104/375  Train Loss: 0.076, Acc: 0.992\n",
      "epoch: 10/30 batch 105/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 10/30 batch 106/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 10/30 batch 107/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 10/30 batch 108/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 10/30 batch 109/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 10/30 batch 110/375  Train Loss: 0.082, Acc: 0.984\n",
      "epoch: 10/30 batch 111/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 10/30 batch 112/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 10/30 batch 113/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch 114/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 10/30 batch 115/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 10/30 batch 116/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 10/30 batch 117/375  Train Loss: 0.066, Acc: 0.969\n",
      "epoch: 10/30 batch 118/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 10/30 batch 119/375  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 10/30 batch 120/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 10/30 batch 121/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 10/30 batch 122/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 10/30 batch 123/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 10/30 batch 124/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 10/30 batch 125/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 10/30 batch 126/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 10/30 batch 127/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 10/30 batch 128/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 10/30 batch 129/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 10/30 batch 130/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 10/30 batch 131/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 10/30 batch 132/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 10/30 batch 133/375  Train Loss: 0.095, Acc: 0.984\n",
      "epoch: 10/30 batch 134/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 10/30 batch 135/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 10/30 batch 136/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 10/30 batch 137/375  Train Loss: 0.087, Acc: 0.984\n",
      "epoch: 10/30 batch 138/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 10/30 batch 139/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 10/30 batch 140/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 10/30 batch 141/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 10/30 batch 142/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 10/30 batch 143/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 10/30 batch 144/375  Train Loss: 0.078, Acc: 0.969\n",
      "epoch: 10/30 batch 145/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 10/30 batch 146/375  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 10/30 batch 147/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch 148/375  Train Loss: 0.030, Acc: 0.977\n",
      "epoch: 10/30 batch 149/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 10/30 batch 150/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 10/30 batch 151/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 10/30 batch 152/375  Train Loss: 0.008, Acc: 0.992\n",
      "epoch: 10/30 batch 153/375  Train Loss: 0.090, Acc: 0.984\n",
      "epoch: 10/30 batch 154/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 10/30 batch 155/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 10/30 batch 156/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 10/30 batch 157/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 10/30 batch 158/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 10/30 batch 159/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 10/30 batch 160/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 10/30 batch 161/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 10/30 batch 162/375  Train Loss: 0.096, Acc: 0.969\n",
      "epoch: 10/30 batch 163/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 10/30 batch 164/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 10/30 batch 165/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 10/30 batch 166/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 10/30 batch 167/375  Train Loss: 0.033, Acc: 0.977\n",
      "epoch: 10/30 batch 168/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 10/30 batch 169/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 10/30 batch 170/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 10/30 batch 171/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 10/30 batch 172/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 10/30 batch 173/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 10/30 batch 174/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 10/30 batch 175/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 10/30 batch 176/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 10/30 batch 177/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 10/30 batch 178/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 10/30 batch 179/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 10/30 batch 180/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 10/30 batch 181/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 10/30 batch 182/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 10/30 batch 183/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 10/30 batch 184/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 10/30 batch 185/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 10/30 batch 186/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 10/30 batch 187/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 10/30 batch 188/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 10/30 batch 189/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 10/30 batch 190/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 10/30 batch 191/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch 192/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 10/30 batch 193/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 10/30 batch 194/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch 195/375  Train Loss: 0.085, Acc: 0.969\n",
      "epoch: 10/30 batch 196/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 10/30 batch 197/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 10/30 batch 198/375  Train Loss: 0.091, Acc: 0.969\n",
      "epoch: 10/30 batch 199/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 10/30 batch 200/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch: 10/30 batch 201/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 10/30 batch 202/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 10/30 batch 203/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 10/30 batch 204/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 10/30 batch 205/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 10/30 batch 206/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 10/30 batch 207/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 10/30 batch 208/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 10/30 batch 209/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 10/30 batch 210/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 10/30 batch 211/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 10/30 batch 212/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 10/30 batch 213/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 10/30 batch 214/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 10/30 batch 215/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch 216/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 10/30 batch 217/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 10/30 batch 218/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 10/30 batch 219/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch 220/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 10/30 batch 221/375  Train Loss: 0.036, Acc: 0.977\n",
      "epoch: 10/30 batch 222/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 10/30 batch 223/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 10/30 batch 224/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 10/30 batch 225/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 10/30 batch 226/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 10/30 batch 227/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 10/30 batch 228/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 10/30 batch 229/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 10/30 batch 230/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 10/30 batch 231/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 10/30 batch 232/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 10/30 batch 233/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch 234/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 10/30 batch 235/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 10/30 batch 236/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 10/30 batch 237/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 10/30 batch 238/375  Train Loss: 0.028, Acc: 0.977\n",
      "epoch: 10/30 batch 239/375  Train Loss: 0.097, Acc: 0.984\n",
      "epoch: 10/30 batch 240/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch 241/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 10/30 batch 242/375  Train Loss: 0.093, Acc: 0.961\n",
      "epoch: 10/30 batch 243/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 10/30 batch 244/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 10/30 batch 245/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch 246/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch 247/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch: 10/30 batch 248/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 10/30 batch 249/375  Train Loss: 0.102, Acc: 0.977\n",
      "epoch: 10/30 batch 250/375  Train Loss: 0.080, Acc: 0.953\n",
      "epoch: 10/30 batch 251/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 10/30 batch 252/375  Train Loss: 0.093, Acc: 0.984\n",
      "epoch: 10/30 batch 253/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 10/30 batch 254/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 10/30 batch 255/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 10/30 batch 256/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 10/30 batch 257/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 10/30 batch 258/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 10/30 batch 259/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 10/30 batch 260/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 10/30 batch 261/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 10/30 batch 262/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 10/30 batch 263/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 10/30 batch 264/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 10/30 batch 265/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 10/30 batch 266/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 10/30 batch 267/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch 268/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 10/30 batch 269/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 10/30 batch 270/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 10/30 batch 271/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 10/30 batch 272/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 10/30 batch 273/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 10/30 batch 274/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 10/30 batch 275/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 10/30 batch 276/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch 277/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 10/30 batch 278/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 10/30 batch 279/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 10/30 batch 280/375  Train Loss: 0.085, Acc: 0.992\n",
      "epoch: 10/30 batch 281/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 10/30 batch 282/375  Train Loss: 0.056, Acc: 0.969\n",
      "epoch: 10/30 batch 283/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch 284/375  Train Loss: 0.084, Acc: 0.984\n",
      "epoch: 10/30 batch 285/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch 286/375  Train Loss: 0.086, Acc: 0.969\n",
      "epoch: 10/30 batch 287/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 10/30 batch 288/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 10/30 batch 289/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 10/30 batch 290/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 10/30 batch 291/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 10/30 batch 292/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 10/30 batch 293/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 10/30 batch 294/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 10/30 batch 295/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 10/30 batch 296/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 10/30 batch 297/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 10/30 batch 298/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch 299/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 10/30 batch 300/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 10/30 batch 301/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 10/30 batch 302/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 10/30 batch 303/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 10/30 batch 304/375  Train Loss: 0.088, Acc: 0.984\n",
      "epoch: 10/30 batch 305/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 10/30 batch 306/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch 307/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 10/30 batch 308/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 10/30 batch 309/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 10/30 batch 310/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 10/30 batch 311/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 10/30 batch 312/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 10/30 batch 313/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 10/30 batch 314/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 10/30 batch 315/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 10/30 batch 316/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 10/30 batch 317/375  Train Loss: 0.031, Acc: 0.977\n",
      "epoch: 10/30 batch 318/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 10/30 batch 319/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 10/30 batch 320/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 10/30 batch 321/375  Train Loss: 0.077, Acc: 0.984\n",
      "epoch: 10/30 batch 322/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 10/30 batch 323/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 10/30 batch 324/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 10/30 batch 325/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 10/30 batch 326/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 10/30 batch 327/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch 328/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 10/30 batch 329/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 10/30 batch 330/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 10/30 batch 331/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 10/30 batch 332/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 10/30 batch 333/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 10/30 batch 334/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 10/30 batch 335/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 10/30 batch 336/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 10/30 batch 337/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 10/30 batch 338/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 10/30 batch 339/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 10/30 batch 340/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 10/30 batch 341/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 10/30 batch 342/375  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 10/30 batch 343/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 10/30 batch 344/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 10/30 batch 345/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch 346/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 10/30 batch 347/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch 348/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 10/30 batch 349/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 10/30 batch 350/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 10/30 batch 351/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 10/30 batch 352/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 10/30 batch 353/375  Train Loss: 0.071, Acc: 0.984\n",
      "epoch: 10/30 batch 354/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 10/30 batch 355/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 10/30 batch 356/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 10/30 batch 357/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 10/30 batch 358/375  Train Loss: 0.038, Acc: 0.977\n",
      "epoch: 10/30 batch 359/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 10/30 batch 360/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 10/30 batch 361/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 10/30 batch 362/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 10/30 batch 363/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch 364/375  Train Loss: 0.056, Acc: 0.969\n",
      "epoch: 10/30 batch 365/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 10/30 batch 366/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 10/30 batch 367/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 10/30 batch 368/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 10/30 batch 369/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 10/30 batch 370/375  Train Loss: 0.033, Acc: 0.977\n",
      "epoch: 10/30 batch 371/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 10/30 batch 372/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 10/30 batch 373/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 10/30 batch 374/375  Train Loss: 0.010, Acc: 1.000\n",
      "Train Loss: 0.033775, Acc: 0.990\n",
      "Val Loss: 0.036655, Acc: 0.989\n",
      "epoch: 11/30 batch   0/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 11/30 batch   1/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 11/30 batch   2/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 11/30 batch   3/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 11/30 batch   4/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 11/30 batch   5/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 11/30 batch   6/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 11/30 batch   7/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 11/30 batch   8/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 11/30 batch   9/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 11/30 batch  10/375  Train Loss: 0.133, Acc: 0.977\n",
      "epoch: 11/30 batch  11/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 11/30 batch  12/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 11/30 batch  13/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 11/30 batch  14/375  Train Loss: 0.069, Acc: 0.969\n",
      "epoch: 11/30 batch  15/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch  16/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 11/30 batch  17/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 11/30 batch  18/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 11/30 batch  19/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch  20/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 11/30 batch  21/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch  22/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 11/30 batch  23/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 11/30 batch  24/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch  25/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 11/30 batch  26/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 11/30 batch  27/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 11/30 batch  28/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 11/30 batch  29/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 11/30 batch  30/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 11/30 batch  31/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 11/30 batch  32/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 11/30 batch  33/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 11/30 batch  34/375  Train Loss: 0.072, Acc: 0.961\n",
      "epoch: 11/30 batch  35/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 11/30 batch  36/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 11/30 batch  37/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 11/30 batch  38/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 11/30 batch  39/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch  40/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 11/30 batch  41/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch  42/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 11/30 batch  43/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 11/30 batch  44/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 11/30 batch  45/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 11/30 batch  46/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 11/30 batch  47/375  Train Loss: 0.078, Acc: 0.992\n",
      "epoch: 11/30 batch  48/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 11/30 batch  49/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch  50/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 11/30 batch  51/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 11/30 batch  52/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 11/30 batch  53/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 11/30 batch  54/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 11/30 batch  55/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 11/30 batch  56/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch  57/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 11/30 batch  58/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 11/30 batch  59/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 11/30 batch  60/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 11/30 batch  61/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 11/30 batch  62/375  Train Loss: 0.018, Acc: 0.984\n",
      "epoch: 11/30 batch  63/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 11/30 batch  64/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 11/30 batch  65/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 11/30 batch  66/375  Train Loss: 0.091, Acc: 0.977\n",
      "epoch: 11/30 batch  67/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 11/30 batch  68/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch  69/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 11/30 batch  70/375  Train Loss: 0.130, Acc: 0.977\n",
      "epoch: 11/30 batch  71/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 11/30 batch  72/375  Train Loss: 0.059, Acc: 0.969\n",
      "epoch: 11/30 batch  73/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 11/30 batch  74/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch  75/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 11/30 batch  76/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch  77/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 11/30 batch  78/375  Train Loss: 0.052, Acc: 0.969\n",
      "epoch: 11/30 batch  79/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 11/30 batch  80/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 11/30 batch  81/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 11/30 batch  82/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 11/30 batch  83/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 11/30 batch  84/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 11/30 batch  85/375  Train Loss: 0.113, Acc: 0.984\n",
      "epoch: 11/30 batch  86/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch  87/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 11/30 batch  88/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 11/30 batch  89/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 11/30 batch  90/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 11/30 batch  91/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 11/30 batch  92/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 11/30 batch  93/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 11/30 batch  94/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 11/30 batch  95/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 11/30 batch  96/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 11/30 batch  97/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 11/30 batch  98/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 11/30 batch  99/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 11/30 batch 100/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 101/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 11/30 batch 102/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 103/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 11/30 batch 104/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch 105/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 11/30 batch 106/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 107/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 11/30 batch 108/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 11/30 batch 109/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch 110/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 11/30 batch 111/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 11/30 batch 112/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 11/30 batch 113/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 11/30 batch 114/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 11/30 batch 115/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 11/30 batch 116/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 11/30 batch 117/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 11/30 batch 118/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 11/30 batch 119/375  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 11/30 batch 120/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 11/30 batch 121/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 11/30 batch 122/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 11/30 batch 123/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 11/30 batch 124/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch 125/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 11/30 batch 126/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 127/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 11/30 batch 128/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch 129/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch 130/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 11/30 batch 131/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 11/30 batch 132/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 11/30 batch 133/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 134/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 11/30 batch 135/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 11/30 batch 136/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 11/30 batch 137/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 11/30 batch 138/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 139/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 11/30 batch 140/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 11/30 batch 141/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 11/30 batch 142/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 11/30 batch 143/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 144/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 11/30 batch 145/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 11/30 batch 146/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 11/30 batch 147/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 11/30 batch 148/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 11/30 batch 149/375  Train Loss: 0.028, Acc: 0.977\n",
      "epoch: 11/30 batch 150/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 11/30 batch 151/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 11/30 batch 152/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 11/30 batch 153/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 154/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 11/30 batch 155/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 11/30 batch 156/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 157/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 11/30 batch 158/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 11/30 batch 159/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 160/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 11/30 batch 161/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 11/30 batch 162/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 11/30 batch 163/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 11/30 batch 164/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch 165/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 11/30 batch 166/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 11/30 batch 167/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 11/30 batch 168/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 11/30 batch 169/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 11/30 batch 170/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 11/30 batch 171/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 11/30 batch 172/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 11/30 batch 173/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 11/30 batch 174/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch 175/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 11/30 batch 176/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 11/30 batch 177/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 11/30 batch 178/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 11/30 batch 179/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 180/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 11/30 batch 181/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 182/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 11/30 batch 183/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 184/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 11/30 batch 185/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch 186/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 11/30 batch 187/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 11/30 batch 188/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 11/30 batch 189/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 11/30 batch 190/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 11/30 batch 191/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 11/30 batch 192/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 11/30 batch 193/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 11/30 batch 194/375  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 11/30 batch 195/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 11/30 batch 196/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 11/30 batch 197/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 11/30 batch 198/375  Train Loss: 0.076, Acc: 0.984\n",
      "epoch: 11/30 batch 199/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch 200/375  Train Loss: 0.036, Acc: 0.977\n",
      "epoch: 11/30 batch 201/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 11/30 batch 202/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 11/30 batch 203/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 11/30 batch 204/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 11/30 batch 205/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 11/30 batch 206/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 11/30 batch 207/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 11/30 batch 208/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 11/30 batch 209/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch 210/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 11/30 batch 211/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 11/30 batch 212/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 11/30 batch 213/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 11/30 batch 214/375  Train Loss: 0.108, Acc: 0.969\n",
      "epoch: 11/30 batch 215/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 11/30 batch 216/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 11/30 batch 217/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 11/30 batch 218/375  Train Loss: 0.107, Acc: 0.984\n",
      "epoch: 11/30 batch 219/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 11/30 batch 220/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 11/30 batch 221/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 11/30 batch 222/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 11/30 batch 223/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch 224/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 11/30 batch 225/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 11/30 batch 226/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch 227/375  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 11/30 batch 228/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 11/30 batch 229/375  Train Loss: 0.084, Acc: 0.977\n",
      "epoch: 11/30 batch 230/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 11/30 batch 231/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 11/30 batch 232/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 11/30 batch 233/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 234/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 11/30 batch 235/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 11/30 batch 236/375  Train Loss: 0.085, Acc: 0.961\n",
      "epoch: 11/30 batch 237/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 11/30 batch 238/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch 239/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 11/30 batch 240/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 11/30 batch 241/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 11/30 batch 242/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 11/30 batch 243/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 11/30 batch 244/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 245/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 11/30 batch 246/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 11/30 batch 247/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 11/30 batch 248/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 249/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 11/30 batch 250/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch 251/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 11/30 batch 252/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 11/30 batch 253/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 11/30 batch 254/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 11/30 batch 255/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 11/30 batch 256/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 11/30 batch 257/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 11/30 batch 258/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 259/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 11/30 batch 260/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 11/30 batch 261/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 11/30 batch 262/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 11/30 batch 263/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 11/30 batch 264/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 11/30 batch 265/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 266/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 11/30 batch 267/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 11/30 batch 268/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 269/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 11/30 batch 270/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 11/30 batch 271/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 272/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 11/30 batch 273/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 11/30 batch 274/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 11/30 batch 275/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 11/30 batch 276/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 11/30 batch 277/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 11/30 batch 278/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 11/30 batch 279/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 11/30 batch 280/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 11/30 batch 281/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 11/30 batch 282/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 283/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 11/30 batch 284/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 11/30 batch 285/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 11/30 batch 286/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 11/30 batch 287/375  Train Loss: 0.145, Acc: 0.984\n",
      "epoch: 11/30 batch 288/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 11/30 batch 289/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 290/375  Train Loss: 0.100, Acc: 0.984\n",
      "epoch: 11/30 batch 291/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 11/30 batch 292/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 11/30 batch 293/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 11/30 batch 294/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 11/30 batch 295/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 11/30 batch 296/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 11/30 batch 297/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 11/30 batch 298/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 11/30 batch 299/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 11/30 batch 300/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 11/30 batch 301/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 11/30 batch 302/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 303/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 11/30 batch 304/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 11/30 batch 305/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 306/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 11/30 batch 307/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 11/30 batch 308/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 11/30 batch 309/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 11/30 batch 310/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 11/30 batch 311/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 11/30 batch 312/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 11/30 batch 313/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 11/30 batch 314/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 11/30 batch 315/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 316/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 11/30 batch 317/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 318/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 319/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 320/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 11/30 batch 321/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 11/30 batch 322/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 323/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 11/30 batch 324/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 11/30 batch 325/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 11/30 batch 326/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 11/30 batch 327/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 11/30 batch 328/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 11/30 batch 329/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 330/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 11/30 batch 331/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 11/30 batch 332/375  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 11/30 batch 333/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 11/30 batch 334/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 11/30 batch 335/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 11/30 batch 336/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 11/30 batch 337/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 11/30 batch 338/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 11/30 batch 339/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 11/30 batch 340/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 11/30 batch 341/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 11/30 batch 342/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 11/30 batch 343/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch 344/375  Train Loss: 0.085, Acc: 0.977\n",
      "epoch: 11/30 batch 345/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 11/30 batch 346/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 347/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 11/30 batch 348/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 11/30 batch 349/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 11/30 batch 350/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 11/30 batch 351/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 11/30 batch 352/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 11/30 batch 353/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 11/30 batch 354/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 11/30 batch 355/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 11/30 batch 356/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 11/30 batch 357/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 11/30 batch 358/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 11/30 batch 359/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 11/30 batch 360/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 11/30 batch 361/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 11/30 batch 362/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 11/30 batch 363/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 11/30 batch 364/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 11/30 batch 365/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 11/30 batch 366/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 11/30 batch 367/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 11/30 batch 368/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 11/30 batch 369/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 11/30 batch 370/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 11/30 batch 371/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 11/30 batch 372/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 11/30 batch 373/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 11/30 batch 374/375  Train Loss: 0.044, Acc: 0.992\n",
      "Train Loss: 0.028249, Acc: 0.992\n",
      "Val Loss: 0.034384, Acc: 0.989\n",
      "epoch: 12/30 batch   0/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch   1/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 12/30 batch   2/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 12/30 batch   3/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 12/30 batch   4/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch   5/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 12/30 batch   6/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 12/30 batch   7/375  Train Loss: 0.072, Acc: 0.961\n",
      "epoch: 12/30 batch   8/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 12/30 batch   9/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 12/30 batch  10/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 12/30 batch  11/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 12/30 batch  12/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 12/30 batch  13/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 12/30 batch  14/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 12/30 batch  15/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 12/30 batch  16/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch  17/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 12/30 batch  18/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 12/30 batch  19/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 12/30 batch  20/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch  21/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 12/30 batch  22/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch  23/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 12/30 batch  24/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 12/30 batch  25/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 12/30 batch  26/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 12/30 batch  27/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 12/30 batch  28/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 12/30 batch  29/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 12/30 batch  30/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 12/30 batch  31/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 12/30 batch  32/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 12/30 batch  33/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 12/30 batch  34/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 12/30 batch  35/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 12/30 batch  36/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 12/30 batch  37/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 12/30 batch  38/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 12/30 batch  39/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 12/30 batch  40/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 12/30 batch  41/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 12/30 batch  42/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch  43/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 12/30 batch  44/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 12/30 batch  45/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 12/30 batch  46/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 12/30 batch  47/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 12/30 batch  48/375  Train Loss: 0.035, Acc: 0.977\n",
      "epoch: 12/30 batch  49/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch  50/375  Train Loss: 0.080, Acc: 0.984\n",
      "epoch: 12/30 batch  51/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 12/30 batch  52/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 12/30 batch  53/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 12/30 batch  54/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 12/30 batch  55/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 12/30 batch  56/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch  57/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 12/30 batch  58/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 12/30 batch  59/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch  60/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch  61/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 12/30 batch  62/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch  63/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 12/30 batch  64/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 12/30 batch  65/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 12/30 batch  66/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 12/30 batch  67/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 12/30 batch  68/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 12/30 batch  69/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 12/30 batch  70/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 12/30 batch  71/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 12/30 batch  72/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 12/30 batch  73/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 12/30 batch  74/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch  75/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch  76/375  Train Loss: 0.046, Acc: 0.969\n",
      "epoch: 12/30 batch  77/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 12/30 batch  78/375  Train Loss: 0.032, Acc: 0.977\n",
      "epoch: 12/30 batch  79/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch  80/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 12/30 batch  81/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 12/30 batch  82/375  Train Loss: 0.102, Acc: 0.969\n",
      "epoch: 12/30 batch  83/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 12/30 batch  84/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 12/30 batch  85/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 12/30 batch  86/375  Train Loss: 0.108, Acc: 0.992\n",
      "epoch: 12/30 batch  87/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch  88/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 12/30 batch  89/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 12/30 batch  90/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 12/30 batch  91/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 12/30 batch  92/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 12/30 batch  93/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 12/30 batch  94/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 12/30 batch  95/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 12/30 batch  96/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch  97/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 12/30 batch  98/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 12/30 batch  99/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 12/30 batch 100/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 12/30 batch 101/375  Train Loss: 0.097, Acc: 0.984\n",
      "epoch: 12/30 batch 102/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch 103/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch 104/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 12/30 batch 105/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 12/30 batch 106/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 12/30 batch 107/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 12/30 batch 108/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 12/30 batch 109/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 12/30 batch 110/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 12/30 batch 111/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 12/30 batch 112/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 12/30 batch 113/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 12/30 batch 114/375  Train Loss: 0.073, Acc: 0.992\n",
      "epoch: 12/30 batch 115/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch 116/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 12/30 batch 117/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 12/30 batch 118/375  Train Loss: 0.050, Acc: 0.969\n",
      "epoch: 12/30 batch 119/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 120/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 12/30 batch 121/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 12/30 batch 122/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 12/30 batch 123/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 12/30 batch 124/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 12/30 batch 125/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 12/30 batch 126/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 12/30 batch 127/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 12/30 batch 128/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 12/30 batch 129/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 12/30 batch 130/375  Train Loss: 0.131, Acc: 0.961\n",
      "epoch: 12/30 batch 131/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch 132/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 12/30 batch 133/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 12/30 batch 134/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 12/30 batch 135/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 12/30 batch 136/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch 137/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 12/30 batch 138/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 12/30 batch 139/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 12/30 batch 140/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 12/30 batch 141/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 12/30 batch 142/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 12/30 batch 143/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 12/30 batch 144/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 12/30 batch 145/375  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 12/30 batch 146/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 12/30 batch 147/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 148/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 12/30 batch 149/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 12/30 batch 150/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch: 12/30 batch 151/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 12/30 batch 152/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 153/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 154/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 12/30 batch 155/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 12/30 batch 156/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 12/30 batch 157/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 12/30 batch 158/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 12/30 batch 159/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 12/30 batch 160/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 12/30 batch 161/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 162/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 163/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 12/30 batch 164/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 12/30 batch 165/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 12/30 batch 166/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 12/30 batch 167/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 12/30 batch 168/375  Train Loss: 0.075, Acc: 0.984\n",
      "epoch: 12/30 batch 169/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 12/30 batch 170/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 171/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 12/30 batch 172/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 173/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch 174/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch 175/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 12/30 batch 176/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 12/30 batch 177/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 178/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 12/30 batch 179/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 12/30 batch 180/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 12/30 batch 181/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 12/30 batch 182/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 12/30 batch 183/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 12/30 batch 184/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 185/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch 186/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch 187/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 12/30 batch 188/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 12/30 batch 189/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 12/30 batch 190/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 12/30 batch 191/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 12/30 batch 192/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch 193/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 12/30 batch 194/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 12/30 batch 195/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 12/30 batch 196/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 12/30 batch 197/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 12/30 batch 198/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 12/30 batch 199/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 12/30 batch 200/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 12/30 batch 201/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 12/30 batch 202/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 12/30 batch 203/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 12/30 batch 204/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 12/30 batch 205/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 12/30 batch 206/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 12/30 batch 207/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 208/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 12/30 batch 209/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 210/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 211/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 12/30 batch 212/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 12/30 batch 213/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 12/30 batch 214/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 12/30 batch 215/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 12/30 batch 216/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 12/30 batch 217/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 12/30 batch 218/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 12/30 batch 219/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 12/30 batch 220/375  Train Loss: 0.088, Acc: 0.984\n",
      "epoch: 12/30 batch 221/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 12/30 batch 222/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 12/30 batch 223/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch 224/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 12/30 batch 225/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 12/30 batch 226/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 12/30 batch 227/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 12/30 batch 228/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 12/30 batch 229/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 12/30 batch 230/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 12/30 batch 231/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 12/30 batch 232/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 12/30 batch 233/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch 234/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 12/30 batch 235/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 12/30 batch 236/375  Train Loss: 0.099, Acc: 0.984\n",
      "epoch: 12/30 batch 237/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 12/30 batch 238/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 12/30 batch 239/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch 240/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 12/30 batch 241/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 12/30 batch 242/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 12/30 batch 243/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 12/30 batch 244/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 12/30 batch 245/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 12/30 batch 246/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 12/30 batch 247/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 12/30 batch 248/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch 249/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 12/30 batch 250/375  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 12/30 batch 251/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 12/30 batch 252/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 12/30 batch 253/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 12/30 batch 254/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 255/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 12/30 batch 256/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 12/30 batch 257/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 12/30 batch 258/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 12/30 batch 259/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 12/30 batch 260/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 12/30 batch 261/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 12/30 batch 262/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch 263/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 12/30 batch 264/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 12/30 batch 265/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 12/30 batch 266/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 12/30 batch 267/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 12/30 batch 268/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 12/30 batch 269/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 12/30 batch 270/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 12/30 batch 271/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 12/30 batch 272/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 12/30 batch 273/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 12/30 batch 274/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 12/30 batch 275/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 12/30 batch 276/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 12/30 batch 277/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 12/30 batch 278/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 12/30 batch 279/375  Train Loss: 0.077, Acc: 0.984\n",
      "epoch: 12/30 batch 280/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 12/30 batch 281/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 12/30 batch 282/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 12/30 batch 283/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 12/30 batch 284/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 12/30 batch 285/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 12/30 batch 286/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 12/30 batch 287/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 288/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 12/30 batch 289/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 12/30 batch 290/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 12/30 batch 291/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 12/30 batch 292/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 12/30 batch 293/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 12/30 batch 294/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 12/30 batch 295/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 12/30 batch 296/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 12/30 batch 297/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 12/30 batch 298/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 12/30 batch 299/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 12/30 batch 300/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 12/30 batch 301/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 12/30 batch 302/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 12/30 batch 303/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 304/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch 305/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 12/30 batch 306/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 307/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 12/30 batch 308/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 12/30 batch 309/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 12/30 batch 310/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch 311/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 12/30 batch 312/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 12/30 batch 313/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 12/30 batch 314/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 12/30 batch 315/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 12/30 batch 316/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 12/30 batch 317/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 12/30 batch 318/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 12/30 batch 319/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 12/30 batch 320/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 12/30 batch 321/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 322/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 12/30 batch 323/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 12/30 batch 324/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 12/30 batch 325/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 12/30 batch 326/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 12/30 batch 327/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 12/30 batch 328/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 12/30 batch 329/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 12/30 batch 330/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 12/30 batch 331/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 12/30 batch 332/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 12/30 batch 333/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 12/30 batch 334/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 12/30 batch 335/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 12/30 batch 336/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 12/30 batch 337/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 12/30 batch 338/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 12/30 batch 339/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 12/30 batch 340/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 341/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 12/30 batch 342/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 12/30 batch 343/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch 344/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 12/30 batch 345/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 12/30 batch 346/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 12/30 batch 347/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 12/30 batch 348/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 12/30 batch 349/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 350/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 12/30 batch 351/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 12/30 batch 352/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch 353/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 12/30 batch 354/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 12/30 batch 355/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 12/30 batch 356/375  Train Loss: 0.081, Acc: 0.977\n",
      "epoch: 12/30 batch 357/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 12/30 batch 358/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch 359/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 12/30 batch 360/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 12/30 batch 361/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 12/30 batch 362/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 12/30 batch 363/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 12/30 batch 364/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 12/30 batch 365/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 12/30 batch 366/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 12/30 batch 367/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 12/30 batch 368/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 12/30 batch 369/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 12/30 batch 370/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 12/30 batch 371/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 12/30 batch 372/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 12/30 batch 373/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 12/30 batch 374/375  Train Loss: 0.021, Acc: 0.992\n",
      "Train Loss: 0.027351, Acc: 0.992\n",
      "Val Loss: 0.035046, Acc: 0.989\n",
      "epoch: 13/30 batch   0/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 13/30 batch   1/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 13/30 batch   2/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch   3/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 13/30 batch   4/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 13/30 batch   5/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch   6/375  Train Loss: 0.084, Acc: 0.969\n",
      "epoch: 13/30 batch   7/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 13/30 batch   8/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 13/30 batch   9/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 13/30 batch  10/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 13/30 batch  11/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 13/30 batch  12/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch  13/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 13/30 batch  14/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 13/30 batch  15/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch  16/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 13/30 batch  17/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 13/30 batch  18/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 13/30 batch  19/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 13/30 batch  20/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 13/30 batch  21/375  Train Loss: 0.038, Acc: 0.977\n",
      "epoch: 13/30 batch  22/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 13/30 batch  23/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch  24/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 13/30 batch  25/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 13/30 batch  26/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 13/30 batch  27/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 13/30 batch  28/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 13/30 batch  29/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch  30/375  Train Loss: 0.060, Acc: 0.992\n",
      "epoch: 13/30 batch  31/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch  32/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 13/30 batch  33/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 13/30 batch  34/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 13/30 batch  35/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 13/30 batch  36/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 13/30 batch  37/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch  38/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch  39/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch  40/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 13/30 batch  41/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 13/30 batch  42/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch  43/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch  44/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch  45/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 13/30 batch  46/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 13/30 batch  47/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch  48/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch  49/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 13/30 batch  50/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 13/30 batch  51/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch  52/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 13/30 batch  53/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch  54/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 13/30 batch  55/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 13/30 batch  56/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch  57/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch  58/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch  59/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 13/30 batch  60/375  Train Loss: 0.072, Acc: 0.969\n",
      "epoch: 13/30 batch  61/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 13/30 batch  62/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 13/30 batch  63/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch: 13/30 batch  64/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 13/30 batch  65/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 13/30 batch  66/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 13/30 batch  67/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch  68/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 13/30 batch  69/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch  70/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 13/30 batch  71/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 13/30 batch  72/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 13/30 batch  73/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 13/30 batch  74/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 13/30 batch  75/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch  76/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 13/30 batch  77/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 13/30 batch  78/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 13/30 batch  79/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 13/30 batch  80/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 13/30 batch  81/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 13/30 batch  82/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 13/30 batch  83/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch  84/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch  85/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 13/30 batch  86/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 13/30 batch  87/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 13/30 batch  88/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 13/30 batch  89/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch  90/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 13/30 batch  91/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch  92/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch  93/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 13/30 batch  94/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch  95/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 13/30 batch  96/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 13/30 batch  97/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 13/30 batch  98/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 13/30 batch  99/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 13/30 batch 100/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 13/30 batch 101/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 13/30 batch 102/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 13/30 batch 103/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch 104/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch 105/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 13/30 batch 106/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch 107/375  Train Loss: 0.098, Acc: 0.977\n",
      "epoch: 13/30 batch 108/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 13/30 batch 109/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 13/30 batch 110/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 13/30 batch 111/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 13/30 batch 112/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 113/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch 114/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 13/30 batch 115/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 13/30 batch 116/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch 117/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 13/30 batch 118/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch 119/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 13/30 batch 120/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 13/30 batch 121/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch 122/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 13/30 batch 123/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 13/30 batch 124/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 13/30 batch 125/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 13/30 batch 126/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch 127/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 13/30 batch 128/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 13/30 batch 129/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch 130/375  Train Loss: 0.008, Acc: 0.992\n",
      "epoch: 13/30 batch 131/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 13/30 batch 132/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 13/30 batch 133/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 13/30 batch 134/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch 135/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 13/30 batch 136/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 13/30 batch 137/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch 138/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch 139/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch 140/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 13/30 batch 141/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 13/30 batch 142/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 143/375  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 13/30 batch 144/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 13/30 batch 145/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 146/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 13/30 batch 147/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 13/30 batch 148/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 13/30 batch 149/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 13/30 batch 150/375  Train Loss: 0.073, Acc: 0.977\n",
      "epoch: 13/30 batch 151/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 13/30 batch 152/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 13/30 batch 153/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 13/30 batch 154/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch 155/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 13/30 batch 156/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 13/30 batch 157/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 13/30 batch 158/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 159/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 13/30 batch 160/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 13/30 batch 161/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 13/30 batch 162/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch 163/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch 164/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 165/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 13/30 batch 166/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 13/30 batch 167/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch 168/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch 169/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 13/30 batch 170/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch 171/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 13/30 batch 172/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 13/30 batch 173/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch 174/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch 175/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 176/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch 177/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 13/30 batch 178/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 13/30 batch 179/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 180/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 13/30 batch 181/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 13/30 batch 182/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 183/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch 184/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 13/30 batch 185/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 13/30 batch 186/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 13/30 batch 187/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 13/30 batch 188/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 13/30 batch 189/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch 190/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 13/30 batch 191/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 13/30 batch 192/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 13/30 batch 193/375  Train Loss: 0.083, Acc: 0.977\n",
      "epoch: 13/30 batch 194/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch 195/375  Train Loss: 0.070, Acc: 0.977\n",
      "epoch: 13/30 batch 196/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 13/30 batch 197/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch 198/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 13/30 batch 199/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch 200/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 13/30 batch 201/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch 202/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch 203/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 13/30 batch 204/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 13/30 batch 205/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 13/30 batch 206/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 13/30 batch 207/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 13/30 batch 208/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 13/30 batch 209/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 13/30 batch 210/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch 211/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 212/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 13/30 batch 213/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 13/30 batch 214/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 13/30 batch 215/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 13/30 batch 216/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 13/30 batch 217/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 13/30 batch 218/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 13/30 batch 219/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch 220/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch 221/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch 222/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 13/30 batch 223/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 13/30 batch 224/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 13/30 batch 225/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch 226/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 13/30 batch 227/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 13/30 batch 228/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 13/30 batch 229/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 13/30 batch 230/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 13/30 batch 231/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 13/30 batch 232/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 13/30 batch 233/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 13/30 batch 234/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 13/30 batch 235/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 13/30 batch 236/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 13/30 batch 237/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch 238/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch 239/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 13/30 batch 240/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 13/30 batch 241/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch 242/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch 243/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 13/30 batch 244/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 13/30 batch 245/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 13/30 batch 246/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 13/30 batch 247/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch 248/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 13/30 batch 249/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 13/30 batch 250/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 13/30 batch 251/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 13/30 batch 252/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch 253/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 13/30 batch 254/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch: 13/30 batch 255/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 13/30 batch 256/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 13/30 batch 257/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 13/30 batch 258/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 13/30 batch 259/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 13/30 batch 260/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 13/30 batch 261/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch 262/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 13/30 batch 263/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch 264/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch 265/375  Train Loss: 0.053, Acc: 0.969\n",
      "epoch: 13/30 batch 266/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 13/30 batch 267/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 13/30 batch 268/375  Train Loss: 0.086, Acc: 0.977\n",
      "epoch: 13/30 batch 269/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch 270/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 13/30 batch 271/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 13/30 batch 272/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 13/30 batch 273/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 13/30 batch 274/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 13/30 batch 275/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 13/30 batch 276/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 13/30 batch 277/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 13/30 batch 278/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 13/30 batch 279/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 13/30 batch 280/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 13/30 batch 281/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch 282/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 13/30 batch 283/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 13/30 batch 284/375  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 13/30 batch 285/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 13/30 batch 286/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 13/30 batch 287/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 13/30 batch 288/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 13/30 batch 289/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 13/30 batch 290/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 13/30 batch 291/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch 292/375  Train Loss: 0.111, Acc: 0.992\n",
      "epoch: 13/30 batch 293/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 13/30 batch 294/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 13/30 batch 295/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 13/30 batch 296/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 13/30 batch 297/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 13/30 batch 298/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 13/30 batch 299/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 13/30 batch 300/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 13/30 batch 301/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 13/30 batch 302/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 13/30 batch 303/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 13/30 batch 304/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 13/30 batch 305/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 13/30 batch 306/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 13/30 batch 307/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 13/30 batch 308/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 13/30 batch 309/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 13/30 batch 310/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 13/30 batch 311/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 13/30 batch 312/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 13/30 batch 313/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 13/30 batch 314/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 13/30 batch 315/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 13/30 batch 316/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 13/30 batch 317/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 13/30 batch 318/375  Train Loss: 0.033, Acc: 0.977\n",
      "epoch: 13/30 batch 319/375  Train Loss: 0.090, Acc: 0.977\n",
      "epoch: 13/30 batch 320/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 13/30 batch 321/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 13/30 batch 322/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 13/30 batch 323/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 13/30 batch 324/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 13/30 batch 325/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 13/30 batch 326/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 13/30 batch 327/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 13/30 batch 328/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 13/30 batch 329/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 13/30 batch 330/375  Train Loss: 0.063, Acc: 0.977\n",
      "epoch: 13/30 batch 331/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 13/30 batch 332/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 13/30 batch 333/375  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 13/30 batch 334/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 13/30 batch 335/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 13/30 batch 336/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 13/30 batch 337/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch 338/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 13/30 batch 339/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 13/30 batch 340/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 13/30 batch 341/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 13/30 batch 342/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 13/30 batch 343/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 13/30 batch 344/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 13/30 batch 345/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 13/30 batch 346/375  Train Loss: 0.065, Acc: 0.977\n",
      "epoch: 13/30 batch 347/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 13/30 batch 348/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 13/30 batch 349/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 13/30 batch 350/375  Train Loss: 0.038, Acc: 0.977\n",
      "epoch: 13/30 batch 351/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch 352/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 13/30 batch 353/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 13/30 batch 354/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch 355/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 13/30 batch 356/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 13/30 batch 357/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 13/30 batch 358/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 13/30 batch 359/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 13/30 batch 360/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 13/30 batch 361/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 13/30 batch 362/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch 363/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 13/30 batch 364/375  Train Loss: 0.081, Acc: 0.992\n",
      "epoch: 13/30 batch 365/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 13/30 batch 366/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch 367/375  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 13/30 batch 368/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 13/30 batch 369/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 13/30 batch 370/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 13/30 batch 371/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 13/30 batch 372/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 13/30 batch 373/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 13/30 batch 374/375  Train Loss: 0.030, Acc: 0.992\n",
      "Train Loss: 0.026710, Acc: 0.992\n",
      "Val Loss: 0.033617, Acc: 0.989\n",
      "epoch: 14/30 batch   0/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 14/30 batch   1/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 14/30 batch   2/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 14/30 batch   3/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch   4/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch   5/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 14/30 batch   6/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 14/30 batch   7/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 14/30 batch   8/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 14/30 batch   9/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 14/30 batch  10/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 14/30 batch  11/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 14/30 batch  12/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 14/30 batch  13/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 14/30 batch  14/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 14/30 batch  15/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 14/30 batch  16/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 14/30 batch  17/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 14/30 batch  18/375  Train Loss: 0.078, Acc: 0.961\n",
      "epoch: 14/30 batch  19/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 14/30 batch  20/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch  21/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 14/30 batch  22/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch  23/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 14/30 batch  24/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 14/30 batch  25/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch  26/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 14/30 batch  27/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 14/30 batch  28/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 14/30 batch  29/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 14/30 batch  30/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 14/30 batch  31/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 14/30 batch  32/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch  33/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 14/30 batch  34/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 14/30 batch  35/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 14/30 batch  36/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 14/30 batch  37/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 14/30 batch  38/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 14/30 batch  39/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 14/30 batch  40/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch  41/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 14/30 batch  42/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 14/30 batch  43/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 14/30 batch  44/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 14/30 batch  45/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 14/30 batch  46/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 14/30 batch  47/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 14/30 batch  48/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 14/30 batch  49/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 14/30 batch  50/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 14/30 batch  51/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 14/30 batch  52/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch  53/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 14/30 batch  54/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 14/30 batch  55/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 14/30 batch  56/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 14/30 batch  57/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 14/30 batch  58/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 14/30 batch  59/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 14/30 batch  60/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch  61/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch  62/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch  63/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 14/30 batch  64/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 14/30 batch  65/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch  66/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch  67/375  Train Loss: 0.017, Acc: 0.984\n",
      "epoch: 14/30 batch  68/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 14/30 batch  69/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 14/30 batch  70/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 14/30 batch  71/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 14/30 batch  72/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 14/30 batch  73/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 14/30 batch  74/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 14/30 batch  75/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 14/30 batch  76/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 14/30 batch  77/375  Train Loss: 0.066, Acc: 0.977\n",
      "epoch: 14/30 batch  78/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 14/30 batch  79/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 14/30 batch  80/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch  81/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 14/30 batch  82/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 14/30 batch  83/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 14/30 batch  84/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 14/30 batch  85/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 14/30 batch  86/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 14/30 batch  87/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 14/30 batch  88/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 14/30 batch  89/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 14/30 batch  90/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 14/30 batch  91/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 14/30 batch  92/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 14/30 batch  93/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 14/30 batch  94/375  Train Loss: 0.092, Acc: 0.992\n",
      "epoch: 14/30 batch  95/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 14/30 batch  96/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 14/30 batch  97/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 14/30 batch  98/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch  99/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 14/30 batch 100/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 14/30 batch 101/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 14/30 batch 102/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch 103/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 14/30 batch 104/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 14/30 batch 105/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 14/30 batch 106/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 14/30 batch 107/375  Train Loss: 0.028, Acc: 0.977\n",
      "epoch: 14/30 batch 108/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 14/30 batch 109/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 110/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 14/30 batch 111/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 14/30 batch 112/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch 113/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 14/30 batch 114/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch 115/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch 116/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch 117/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 14/30 batch 118/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch 119/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 14/30 batch 120/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 14/30 batch 121/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 14/30 batch 122/375  Train Loss: 0.031, Acc: 0.977\n",
      "epoch: 14/30 batch 123/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 14/30 batch 124/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 14/30 batch 125/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 14/30 batch 126/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 14/30 batch 127/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 14/30 batch 128/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 14/30 batch 129/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 14/30 batch 130/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 14/30 batch 131/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch 132/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 14/30 batch 133/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 14/30 batch 134/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 14/30 batch 135/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 14/30 batch 136/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 14/30 batch 137/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 14/30 batch 138/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 14/30 batch 139/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch 140/375  Train Loss: 0.033, Acc: 0.969\n",
      "epoch: 14/30 batch 141/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 14/30 batch 142/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 14/30 batch 143/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch 144/375  Train Loss: 0.035, Acc: 0.977\n",
      "epoch: 14/30 batch 145/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 14/30 batch 146/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 14/30 batch 147/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 14/30 batch 148/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 149/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 14/30 batch 150/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 14/30 batch 151/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 14/30 batch 152/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 14/30 batch 153/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 14/30 batch 154/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 155/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 14/30 batch 156/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 14/30 batch 157/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 14/30 batch 158/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 14/30 batch 159/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 14/30 batch 160/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 14/30 batch 161/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 14/30 batch 162/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 163/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 164/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 14/30 batch 165/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 14/30 batch 166/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 14/30 batch 167/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 14/30 batch 168/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 14/30 batch 169/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 14/30 batch 170/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 14/30 batch 171/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 14/30 batch 172/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 14/30 batch 173/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 14/30 batch 174/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 175/375  Train Loss: 0.076, Acc: 0.977\n",
      "epoch: 14/30 batch 176/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch 177/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 14/30 batch 178/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 14/30 batch 179/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 180/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 181/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 14/30 batch 182/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 14/30 batch 183/375  Train Loss: 0.063, Acc: 0.969\n",
      "epoch: 14/30 batch 184/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 14/30 batch 185/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 14/30 batch 186/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 14/30 batch 187/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 14/30 batch 188/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 14/30 batch 189/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 14/30 batch 190/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 14/30 batch 191/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 14/30 batch 192/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 14/30 batch 193/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 14/30 batch 194/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 14/30 batch 195/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 14/30 batch 196/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 14/30 batch 197/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 14/30 batch 198/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 14/30 batch 199/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 14/30 batch 200/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch: 14/30 batch 201/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 14/30 batch 202/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 14/30 batch 203/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 14/30 batch 204/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 14/30 batch 205/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 14/30 batch 206/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 14/30 batch 207/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 14/30 batch 208/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 14/30 batch 209/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 210/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 211/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 14/30 batch 212/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 14/30 batch 213/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 14/30 batch 214/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 14/30 batch 215/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 14/30 batch 216/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 14/30 batch 217/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 218/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 14/30 batch 219/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch 220/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 14/30 batch 221/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 14/30 batch 222/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 14/30 batch 223/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 14/30 batch 224/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 14/30 batch 225/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 14/30 batch 226/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 14/30 batch 227/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 14/30 batch 228/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 14/30 batch 229/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 14/30 batch 230/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 14/30 batch 231/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 14/30 batch 232/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 14/30 batch 233/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch 234/375  Train Loss: 0.036, Acc: 0.977\n",
      "epoch: 14/30 batch 235/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 14/30 batch 236/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 14/30 batch 237/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch 238/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 14/30 batch 239/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch 240/375  Train Loss: 0.150, Acc: 0.969\n",
      "epoch: 14/30 batch 241/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 14/30 batch 242/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 243/375  Train Loss: 0.066, Acc: 0.969\n",
      "epoch: 14/30 batch 244/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 14/30 batch 245/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 14/30 batch 246/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 14/30 batch 247/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 14/30 batch 248/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 14/30 batch 249/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 250/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 14/30 batch 251/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 14/30 batch 252/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 14/30 batch 253/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 14/30 batch 254/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 255/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 14/30 batch 256/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 14/30 batch 257/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 258/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 14/30 batch 259/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 14/30 batch 260/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch 261/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 14/30 batch 262/375  Train Loss: 0.091, Acc: 0.984\n",
      "epoch: 14/30 batch 263/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 14/30 batch 264/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 14/30 batch 265/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 14/30 batch 266/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch 267/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 14/30 batch 268/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 14/30 batch 269/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 14/30 batch 270/375  Train Loss: 0.090, Acc: 0.969\n",
      "epoch: 14/30 batch 271/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 14/30 batch 272/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 14/30 batch 273/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 274/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 14/30 batch 275/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 14/30 batch 276/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 277/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 14/30 batch 278/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 14/30 batch 279/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 14/30 batch 280/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 14/30 batch 281/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 14/30 batch 282/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch 283/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 14/30 batch 284/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 14/30 batch 285/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 14/30 batch 286/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 14/30 batch 287/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch 288/375  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 14/30 batch 289/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 14/30 batch 290/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 14/30 batch 291/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 14/30 batch 292/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch 293/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 294/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 14/30 batch 295/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 14/30 batch 296/375  Train Loss: 0.099, Acc: 0.969\n",
      "epoch: 14/30 batch 297/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 14/30 batch 298/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 14/30 batch 299/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 14/30 batch 300/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 14/30 batch 301/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 14/30 batch 302/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 14/30 batch 303/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 14/30 batch 304/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 14/30 batch 305/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 14/30 batch 306/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 14/30 batch 307/375  Train Loss: 0.075, Acc: 0.969\n",
      "epoch: 14/30 batch 308/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 14/30 batch 309/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 14/30 batch 310/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 14/30 batch 311/375  Train Loss: 0.028, Acc: 1.000\n",
      "epoch: 14/30 batch 312/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 14/30 batch 313/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 14/30 batch 314/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 14/30 batch 315/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 14/30 batch 316/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 317/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 14/30 batch 318/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 14/30 batch 319/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 14/30 batch 320/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 14/30 batch 321/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 14/30 batch 322/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 14/30 batch 323/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 14/30 batch 324/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 14/30 batch 325/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 14/30 batch 326/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 14/30 batch 327/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 14/30 batch 328/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 14/30 batch 329/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 14/30 batch 330/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 331/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 332/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch 333/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 14/30 batch 334/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 14/30 batch 335/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 336/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 14/30 batch 337/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 14/30 batch 338/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 14/30 batch 339/375  Train Loss: 0.093, Acc: 0.977\n",
      "epoch: 14/30 batch 340/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 14/30 batch 341/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 14/30 batch 342/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 14/30 batch 343/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 14/30 batch 344/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 14/30 batch 345/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch 346/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 14/30 batch 347/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 14/30 batch 348/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 14/30 batch 349/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 14/30 batch 350/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 14/30 batch 351/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 352/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 14/30 batch 353/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 14/30 batch 354/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 14/30 batch 355/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 14/30 batch 356/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 14/30 batch 357/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 14/30 batch 358/375  Train Loss: 0.070, Acc: 0.992\n",
      "epoch: 14/30 batch 359/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 14/30 batch 360/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 14/30 batch 361/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 14/30 batch 362/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 14/30 batch 363/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 14/30 batch 364/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 14/30 batch 365/375  Train Loss: 0.064, Acc: 0.992\n",
      "epoch: 14/30 batch 366/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 14/30 batch 367/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 14/30 batch 368/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 14/30 batch 369/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 14/30 batch 370/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 14/30 batch 371/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 14/30 batch 372/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 14/30 batch 373/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 14/30 batch 374/375  Train Loss: 0.006, Acc: 1.000\n",
      "Train Loss: 0.026502, Acc: 0.992\n",
      "Val Loss: 0.033233, Acc: 0.990\n",
      "epoch: 15/30 batch   0/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 15/30 batch   1/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch   2/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 15/30 batch   3/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 15/30 batch   4/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch   5/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 15/30 batch   6/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 15/30 batch   7/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 15/30 batch   8/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch   9/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 15/30 batch  10/375  Train Loss: 0.030, Acc: 0.977\n",
      "epoch: 15/30 batch  11/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 15/30 batch  12/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 15/30 batch  13/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch  14/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 15/30 batch  15/375  Train Loss: 0.038, Acc: 0.977\n",
      "epoch: 15/30 batch  16/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch  17/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 15/30 batch  18/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 15/30 batch  19/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch  20/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch  21/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 15/30 batch  22/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 15/30 batch  23/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch  24/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch  25/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch  26/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 15/30 batch  27/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch  28/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 15/30 batch  29/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 15/30 batch  30/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 15/30 batch  31/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch  32/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 15/30 batch  33/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch  34/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 15/30 batch  35/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 15/30 batch  36/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 15/30 batch  37/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 15/30 batch  38/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch  39/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 15/30 batch  40/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 15/30 batch  41/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch  42/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 15/30 batch  43/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 15/30 batch  44/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 15/30 batch  45/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 15/30 batch  46/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch  47/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 15/30 batch  48/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 15/30 batch  49/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 15/30 batch  50/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 15/30 batch  51/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch  52/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 15/30 batch  53/375  Train Loss: 0.083, Acc: 0.969\n",
      "epoch: 15/30 batch  54/375  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 15/30 batch  55/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 15/30 batch  56/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 15/30 batch  57/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 15/30 batch  58/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 15/30 batch  59/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch  60/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch  61/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 15/30 batch  62/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch  63/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 15/30 batch  64/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 15/30 batch  65/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch  66/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 15/30 batch  67/375  Train Loss: 0.037, Acc: 0.977\n",
      "epoch: 15/30 batch  68/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch  69/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 15/30 batch  70/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 15/30 batch  71/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 15/30 batch  72/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch  73/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 15/30 batch  74/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch  75/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch  76/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch  77/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 15/30 batch  78/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch  79/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch  80/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 15/30 batch  81/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch  82/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 15/30 batch  83/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 15/30 batch  84/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 15/30 batch  85/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 15/30 batch  86/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 15/30 batch  87/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 15/30 batch  88/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 15/30 batch  89/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 15/30 batch  90/375  Train Loss: 0.150, Acc: 0.969\n",
      "epoch: 15/30 batch  91/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 15/30 batch  92/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 15/30 batch  93/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch  94/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 15/30 batch  95/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 15/30 batch  96/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 15/30 batch  97/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 15/30 batch  98/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 15/30 batch  99/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 15/30 batch 100/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 15/30 batch 101/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 15/30 batch 102/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 15/30 batch 103/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch 104/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 15/30 batch 105/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 15/30 batch 106/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 15/30 batch 107/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch 108/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 15/30 batch 109/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 15/30 batch 110/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 15/30 batch 111/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 15/30 batch 112/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch 113/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 15/30 batch 114/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 115/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 116/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 117/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 15/30 batch 118/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch 119/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch 120/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 15/30 batch 121/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 15/30 batch 122/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 15/30 batch 123/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 15/30 batch 124/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 15/30 batch 125/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch 126/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 127/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch 128/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 15/30 batch 129/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 15/30 batch 130/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch 131/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 15/30 batch 132/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch 133/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 15/30 batch 134/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 15/30 batch 135/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 15/30 batch 136/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 15/30 batch 137/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 15/30 batch 138/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 15/30 batch 139/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 15/30 batch 140/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 141/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 15/30 batch 142/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 15/30 batch 143/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch 144/375  Train Loss: 0.041, Acc: 0.969\n",
      "epoch: 15/30 batch 145/375  Train Loss: 0.061, Acc: 0.977\n",
      "epoch: 15/30 batch 146/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 15/30 batch 147/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 15/30 batch 148/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 149/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 150/375  Train Loss: 0.034, Acc: 0.977\n",
      "epoch: 15/30 batch 151/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 15/30 batch 152/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 15/30 batch 153/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 15/30 batch 154/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch 155/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 15/30 batch 156/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 15/30 batch 157/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 15/30 batch 158/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 15/30 batch 159/375  Train Loss: 0.102, Acc: 0.977\n",
      "epoch: 15/30 batch 160/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 15/30 batch 161/375  Train Loss: 0.037, Acc: 0.977\n",
      "epoch: 15/30 batch 162/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch 163/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 15/30 batch 164/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 15/30 batch 165/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 15/30 batch 166/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 15/30 batch 167/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 15/30 batch 168/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 15/30 batch 169/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 15/30 batch 170/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 15/30 batch 171/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 15/30 batch 172/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch 173/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 15/30 batch 174/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 175/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch 176/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 15/30 batch 177/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 15/30 batch 178/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch 179/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch 180/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 15/30 batch 181/375  Train Loss: 0.107, Acc: 0.992\n",
      "epoch: 15/30 batch 182/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 183/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 15/30 batch 184/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 15/30 batch 185/375  Train Loss: 0.043, Acc: 0.969\n",
      "epoch: 15/30 batch 186/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch 187/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 15/30 batch 188/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 15/30 batch 189/375  Train Loss: 0.029, Acc: 1.000\n",
      "epoch: 15/30 batch 190/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch 191/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 15/30 batch 192/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 193/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 15/30 batch 194/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 15/30 batch 195/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 15/30 batch 196/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 15/30 batch 197/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 15/30 batch 198/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 15/30 batch 199/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 15/30 batch 200/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 15/30 batch 201/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 15/30 batch 202/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 15/30 batch 203/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 204/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 205/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 206/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 15/30 batch 207/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch 208/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 15/30 batch 209/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch 210/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 15/30 batch 211/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 15/30 batch 212/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 15/30 batch 213/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 15/30 batch 214/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 15/30 batch 215/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch 216/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 15/30 batch 217/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 15/30 batch 218/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch 219/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 15/30 batch 220/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 15/30 batch 221/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 15/30 batch 222/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch 223/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 15/30 batch 224/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 15/30 batch 225/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch 226/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 15/30 batch 227/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 15/30 batch 228/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 15/30 batch 229/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 15/30 batch 230/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 15/30 batch 231/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch 232/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 15/30 batch 233/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 15/30 batch 234/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 15/30 batch 235/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 15/30 batch 236/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 15/30 batch 237/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 15/30 batch 238/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 15/30 batch 239/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 15/30 batch 240/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 15/30 batch 241/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 15/30 batch 242/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 15/30 batch 243/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch 244/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 15/30 batch 245/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 15/30 batch 246/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 15/30 batch 247/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch 248/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 15/30 batch 249/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 15/30 batch 250/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch 251/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 15/30 batch 252/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 15/30 batch 253/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch 254/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 15/30 batch 255/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 15/30 batch 256/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 15/30 batch 257/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 15/30 batch 258/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 15/30 batch 259/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 15/30 batch 260/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 15/30 batch 261/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch 262/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 15/30 batch 263/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 15/30 batch 264/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 15/30 batch 265/375  Train Loss: 0.059, Acc: 0.992\n",
      "epoch: 15/30 batch 266/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch 267/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 15/30 batch 268/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 15/30 batch 269/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 15/30 batch 270/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 15/30 batch 271/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 15/30 batch 272/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 15/30 batch 273/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch 274/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 15/30 batch 275/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 15/30 batch 276/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 15/30 batch 277/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 15/30 batch 278/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 15/30 batch 279/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 15/30 batch 280/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 15/30 batch 281/375  Train Loss: 0.088, Acc: 0.969\n",
      "epoch: 15/30 batch 282/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 15/30 batch 283/375  Train Loss: 0.079, Acc: 0.969\n",
      "epoch: 15/30 batch 284/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 15/30 batch 285/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 286/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 15/30 batch 287/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 288/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 15/30 batch 289/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 15/30 batch 290/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 15/30 batch 291/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch 292/375  Train Loss: 0.031, Acc: 0.977\n",
      "epoch: 15/30 batch 293/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 15/30 batch 294/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 15/30 batch 295/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 15/30 batch 296/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 15/30 batch 297/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 15/30 batch 298/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 15/30 batch 299/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 15/30 batch 300/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 15/30 batch 301/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch 302/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 15/30 batch 303/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 15/30 batch 304/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 15/30 batch 305/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch 306/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 15/30 batch 307/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 15/30 batch 308/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 15/30 batch 309/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch 310/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 15/30 batch 311/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 15/30 batch 312/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 15/30 batch 313/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 15/30 batch 314/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch 315/375  Train Loss: 0.071, Acc: 0.977\n",
      "epoch: 15/30 batch 316/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 15/30 batch 317/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 15/30 batch 318/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 15/30 batch 319/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 15/30 batch 320/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 321/375  Train Loss: 0.061, Acc: 0.992\n",
      "epoch: 15/30 batch 322/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 15/30 batch 323/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 15/30 batch 324/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 15/30 batch 325/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 15/30 batch 326/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 15/30 batch 327/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch 328/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 15/30 batch 329/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 15/30 batch 330/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 15/30 batch 331/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch 332/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 15/30 batch 333/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 15/30 batch 334/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch 335/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 15/30 batch 336/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 337/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 15/30 batch 338/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 15/30 batch 339/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch 340/375  Train Loss: 0.103, Acc: 0.969\n",
      "epoch: 15/30 batch 341/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 15/30 batch 342/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 15/30 batch 343/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch 344/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 15/30 batch 345/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 15/30 batch 346/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 15/30 batch 347/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 15/30 batch 348/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 15/30 batch 349/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 15/30 batch 350/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 15/30 batch 351/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 15/30 batch 352/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 15/30 batch 353/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch 354/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 15/30 batch 355/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 15/30 batch 356/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch 357/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 15/30 batch 358/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 15/30 batch 359/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 15/30 batch 360/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 15/30 batch 361/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 15/30 batch 362/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 15/30 batch 363/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 15/30 batch 364/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 15/30 batch 365/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 15/30 batch 366/375  Train Loss: 0.062, Acc: 0.969\n",
      "epoch: 15/30 batch 367/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 368/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 369/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 15/30 batch 370/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 15/30 batch 371/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 15/30 batch 372/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 15/30 batch 373/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 15/30 batch 374/375  Train Loss: 0.006, Acc: 1.000\n",
      "Train Loss: 0.025866, Acc: 0.993\n",
      "Val Loss: 0.033775, Acc: 0.990\n",
      "epoch: 16/30 batch   0/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 16/30 batch   1/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch   2/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 16/30 batch   3/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 16/30 batch   4/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch   5/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 16/30 batch   6/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 16/30 batch   7/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 16/30 batch   8/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 16/30 batch   9/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch  10/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 16/30 batch  11/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch  12/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 16/30 batch  13/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 16/30 batch  14/375  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 16/30 batch  15/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch  16/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch  17/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 16/30 batch  18/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch  19/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 16/30 batch  20/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 16/30 batch  21/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch  22/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 16/30 batch  23/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 16/30 batch  24/375  Train Loss: 0.103, Acc: 0.992\n",
      "epoch: 16/30 batch  25/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 16/30 batch  26/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 16/30 batch  27/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 16/30 batch  28/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 16/30 batch  29/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch  30/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 16/30 batch  31/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch  32/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 16/30 batch  33/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch  34/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch  35/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 16/30 batch  36/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch  37/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 16/30 batch  38/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 16/30 batch  39/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 16/30 batch  40/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch  41/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch  42/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch  43/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 16/30 batch  44/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 16/30 batch  45/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 16/30 batch  46/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 16/30 batch  47/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 16/30 batch  48/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 16/30 batch  49/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 16/30 batch  50/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch  51/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 16/30 batch  52/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 16/30 batch  53/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch  54/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch  55/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch  56/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 16/30 batch  57/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch  58/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch: 16/30 batch  59/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 16/30 batch  60/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 16/30 batch  61/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 16/30 batch  62/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 16/30 batch  63/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch  64/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 16/30 batch  65/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch  66/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 16/30 batch  67/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 16/30 batch  68/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch  69/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 16/30 batch  70/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 16/30 batch  71/375  Train Loss: 0.058, Acc: 0.961\n",
      "epoch: 16/30 batch  72/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch  73/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 16/30 batch  74/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 16/30 batch  75/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 16/30 batch  76/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 16/30 batch  77/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 16/30 batch  78/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 16/30 batch  79/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 16/30 batch  80/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 16/30 batch  81/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 16/30 batch  82/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 16/30 batch  83/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch  84/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch  85/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 16/30 batch  86/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 16/30 batch  87/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 16/30 batch  88/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 16/30 batch  89/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch  90/375  Train Loss: 0.040, Acc: 0.969\n",
      "epoch: 16/30 batch  91/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch  92/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch  93/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 16/30 batch  94/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 16/30 batch  95/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 16/30 batch  96/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 16/30 batch  97/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 16/30 batch  98/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch  99/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 16/30 batch 100/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 16/30 batch 101/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 16/30 batch 102/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 16/30 batch 103/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 16/30 batch 104/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 16/30 batch 105/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch 106/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch 107/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 16/30 batch 108/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 16/30 batch 109/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 16/30 batch 110/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch 111/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 16/30 batch 112/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 16/30 batch 113/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 16/30 batch 114/375  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 16/30 batch 115/375  Train Loss: 0.089, Acc: 0.984\n",
      "epoch: 16/30 batch 116/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 16/30 batch 117/375  Train Loss: 0.129, Acc: 0.969\n",
      "epoch: 16/30 batch 118/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 119/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 16/30 batch 120/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch 121/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 122/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 16/30 batch 123/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 16/30 batch 124/375  Train Loss: 0.035, Acc: 0.977\n",
      "epoch: 16/30 batch 125/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 16/30 batch 126/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 16/30 batch 127/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch 128/375  Train Loss: 0.093, Acc: 0.977\n",
      "epoch: 16/30 batch 129/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 16/30 batch 130/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 16/30 batch 131/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 16/30 batch 132/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 16/30 batch 133/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 134/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 16/30 batch 135/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 136/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 16/30 batch 137/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 16/30 batch 138/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch 139/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 16/30 batch 140/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 16/30 batch 141/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch 142/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch 143/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 16/30 batch 144/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 16/30 batch 145/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 16/30 batch 146/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 16/30 batch 147/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 148/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch 149/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 16/30 batch 150/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 16/30 batch 151/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 16/30 batch 152/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 16/30 batch 153/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 16/30 batch 154/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 16/30 batch 155/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 16/30 batch 156/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 16/30 batch 157/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 16/30 batch 158/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 159/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 16/30 batch 160/375  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 16/30 batch 161/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 16/30 batch 162/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 16/30 batch 163/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 16/30 batch 164/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 16/30 batch 165/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 16/30 batch 166/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 16/30 batch 167/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 16/30 batch 168/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 16/30 batch 169/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 170/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 16/30 batch 171/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 172/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 16/30 batch 173/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch 174/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 16/30 batch 175/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 16/30 batch 176/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 16/30 batch 177/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 178/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 16/30 batch 179/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 16/30 batch 180/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 16/30 batch 181/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 16/30 batch 182/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 16/30 batch 183/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 16/30 batch 184/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 16/30 batch 185/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 16/30 batch 186/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 16/30 batch 187/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 16/30 batch 188/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 16/30 batch 189/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 16/30 batch 190/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 16/30 batch 191/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 16/30 batch 192/375  Train Loss: 0.083, Acc: 0.984\n",
      "epoch: 16/30 batch 193/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 16/30 batch 194/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 16/30 batch 195/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 16/30 batch 196/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch 197/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 198/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 16/30 batch 199/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 16/30 batch 200/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 16/30 batch 201/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 16/30 batch 202/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 203/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 16/30 batch 204/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 16/30 batch 205/375  Train Loss: 0.049, Acc: 0.969\n",
      "epoch: 16/30 batch 206/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 16/30 batch 207/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 16/30 batch 208/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 16/30 batch 209/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 16/30 batch 210/375  Train Loss: 0.079, Acc: 0.984\n",
      "epoch: 16/30 batch 211/375  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 16/30 batch 212/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 16/30 batch 213/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch 214/375  Train Loss: 0.034, Acc: 0.977\n",
      "epoch: 16/30 batch 215/375  Train Loss: 0.106, Acc: 0.969\n",
      "epoch: 16/30 batch 216/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 16/30 batch 217/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 16/30 batch 218/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 16/30 batch 219/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 220/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch 221/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch 222/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 16/30 batch 223/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch 224/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch 225/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 226/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 16/30 batch 227/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 16/30 batch 228/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 16/30 batch 229/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 16/30 batch 230/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 16/30 batch 231/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch 232/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 16/30 batch 233/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 16/30 batch 234/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 16/30 batch 235/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 16/30 batch 236/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 16/30 batch 237/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 16/30 batch 238/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 16/30 batch 239/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 16/30 batch 240/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 241/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch 242/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 16/30 batch 243/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 16/30 batch 244/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 16/30 batch 245/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 16/30 batch 246/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch 247/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 16/30 batch 248/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 16/30 batch 249/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 250/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch 251/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch 252/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 16/30 batch 253/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 16/30 batch 254/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 16/30 batch 255/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 16/30 batch 256/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 16/30 batch 257/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch 258/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 16/30 batch 259/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 16/30 batch 260/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 261/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 16/30 batch 262/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 16/30 batch 263/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch 264/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 16/30 batch 265/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 266/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch 267/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 16/30 batch 268/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 16/30 batch 269/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 16/30 batch 270/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch 271/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 272/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 16/30 batch 273/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 16/30 batch 274/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 16/30 batch 275/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 16/30 batch 276/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 277/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 16/30 batch 278/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 16/30 batch 279/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 16/30 batch 280/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 16/30 batch 281/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 16/30 batch 282/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 16/30 batch 283/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 16/30 batch 284/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 16/30 batch 285/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 16/30 batch 286/375  Train Loss: 0.138, Acc: 0.969\n",
      "epoch: 16/30 batch 287/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 16/30 batch 288/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 16/30 batch 289/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 16/30 batch 290/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 16/30 batch 291/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch 292/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 293/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 16/30 batch 294/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 295/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 16/30 batch 296/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch 297/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 16/30 batch 298/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 16/30 batch 299/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 300/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 16/30 batch 301/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 16/30 batch 302/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch 303/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 16/30 batch 304/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch 305/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 16/30 batch 306/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 16/30 batch 307/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 16/30 batch 308/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch 309/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 16/30 batch 310/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 311/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 16/30 batch 312/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 313/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 16/30 batch 314/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 16/30 batch 315/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 16/30 batch 316/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 317/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 16/30 batch 318/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 16/30 batch 319/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 320/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 16/30 batch 321/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 16/30 batch 322/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 16/30 batch 323/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 16/30 batch 324/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 325/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch 326/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 16/30 batch 327/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch 328/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 16/30 batch 329/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 16/30 batch 330/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch 331/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 16/30 batch 332/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 16/30 batch 333/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 16/30 batch 334/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 16/30 batch 335/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch 336/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 16/30 batch 337/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 16/30 batch 338/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 339/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 16/30 batch 340/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 16/30 batch 341/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch 342/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 16/30 batch 343/375  Train Loss: 0.114, Acc: 0.977\n",
      "epoch: 16/30 batch 344/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 16/30 batch 345/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 346/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 16/30 batch 347/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 16/30 batch 348/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 16/30 batch 349/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 16/30 batch 350/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 16/30 batch 351/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 352/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 353/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 16/30 batch 354/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 16/30 batch 355/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 16/30 batch 356/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 16/30 batch 357/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch 358/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 16/30 batch 359/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 360/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 16/30 batch 361/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 16/30 batch 362/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 16/30 batch 363/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 16/30 batch 364/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 365/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 16/30 batch 366/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 16/30 batch 367/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 16/30 batch 368/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 16/30 batch 369/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 16/30 batch 370/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 16/30 batch 371/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 16/30 batch 372/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 16/30 batch 373/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 16/30 batch 374/375  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.025578, Acc: 0.992\n",
      "Val Loss: 0.034240, Acc: 0.989\n",
      "epoch: 17/30 batch   0/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 17/30 batch   1/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 17/30 batch   2/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 17/30 batch   3/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 17/30 batch   4/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 17/30 batch   5/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 17/30 batch   6/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 17/30 batch   7/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 17/30 batch   8/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch   9/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 17/30 batch  10/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch  11/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 17/30 batch  12/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 17/30 batch  13/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 17/30 batch  14/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 17/30 batch  15/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 17/30 batch  16/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch  17/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 17/30 batch  18/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch  19/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 17/30 batch  20/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch  21/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 17/30 batch  22/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 17/30 batch  23/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch  24/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 17/30 batch  25/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 17/30 batch  26/375  Train Loss: 0.061, Acc: 0.961\n",
      "epoch: 17/30 batch  27/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 17/30 batch  28/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch  29/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 17/30 batch  30/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 17/30 batch  31/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch  32/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 17/30 batch  33/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 17/30 batch  34/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 17/30 batch  35/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 17/30 batch  36/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 17/30 batch  37/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 17/30 batch  38/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 17/30 batch  39/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 17/30 batch  40/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 17/30 batch  41/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 17/30 batch  42/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 17/30 batch  43/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 17/30 batch  44/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 17/30 batch  45/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 17/30 batch  46/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 17/30 batch  47/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 17/30 batch  48/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 17/30 batch  49/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 17/30 batch  50/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 17/30 batch  51/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 17/30 batch  52/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 17/30 batch  53/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 17/30 batch  54/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 17/30 batch  55/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch  56/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 17/30 batch  57/375  Train Loss: 0.119, Acc: 0.984\n",
      "epoch: 17/30 batch  58/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 17/30 batch  59/375  Train Loss: 0.093, Acc: 0.977\n",
      "epoch: 17/30 batch  60/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 17/30 batch  61/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 17/30 batch  62/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 17/30 batch  63/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 17/30 batch  64/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 17/30 batch  65/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 17/30 batch  66/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch  67/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 17/30 batch  68/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 17/30 batch  69/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch  70/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch  71/375  Train Loss: 0.054, Acc: 0.977\n",
      "epoch: 17/30 batch  72/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch  73/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 17/30 batch  74/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 17/30 batch  75/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 17/30 batch  76/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 17/30 batch  77/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 17/30 batch  78/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 17/30 batch  79/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 17/30 batch  80/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 17/30 batch  81/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 17/30 batch  82/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 17/30 batch  83/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 17/30 batch  84/375  Train Loss: 0.072, Acc: 0.984\n",
      "epoch: 17/30 batch  85/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 17/30 batch  86/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch  87/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 17/30 batch  88/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch  89/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 17/30 batch  90/375  Train Loss: 0.058, Acc: 0.992\n",
      "epoch: 17/30 batch  91/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 17/30 batch  92/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 17/30 batch  93/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 17/30 batch  94/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 17/30 batch  95/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 17/30 batch  96/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 17/30 batch  97/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 17/30 batch  98/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 17/30 batch  99/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 17/30 batch 100/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 17/30 batch 101/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 17/30 batch 102/375  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 17/30 batch 103/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 17/30 batch 104/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 17/30 batch 105/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 17/30 batch 106/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 17/30 batch 107/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 17/30 batch 108/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 17/30 batch 109/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 17/30 batch 110/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 111/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 17/30 batch 112/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch 113/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 114/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 17/30 batch 115/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 116/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 17/30 batch 117/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 118/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 17/30 batch 119/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 17/30 batch 120/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 17/30 batch 121/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 17/30 batch 122/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 17/30 batch 123/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 17/30 batch 124/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 17/30 batch 125/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 17/30 batch 126/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 17/30 batch 127/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 17/30 batch 128/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 17/30 batch 129/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 17/30 batch 130/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 131/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 132/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 17/30 batch 133/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 17/30 batch 134/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 17/30 batch 135/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 17/30 batch 136/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 17/30 batch 137/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 17/30 batch 138/375  Train Loss: 0.058, Acc: 0.969\n",
      "epoch: 17/30 batch 139/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 140/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 17/30 batch 141/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 142/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 17/30 batch 143/375  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 17/30 batch 144/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 17/30 batch 145/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 17/30 batch 146/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 17/30 batch 147/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 17/30 batch 148/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 17/30 batch 149/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 17/30 batch 150/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 17/30 batch 151/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 17/30 batch 152/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 17/30 batch 153/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 17/30 batch 154/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 17/30 batch 155/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 17/30 batch 156/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 17/30 batch 157/375  Train Loss: 0.059, Acc: 0.969\n",
      "epoch: 17/30 batch 158/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 17/30 batch 159/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 17/30 batch 160/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 17/30 batch 161/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 17/30 batch 162/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 17/30 batch 163/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 17/30 batch 164/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 17/30 batch 165/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 17/30 batch 166/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 17/30 batch 167/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 17/30 batch 168/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 17/30 batch 169/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch 170/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 17/30 batch 171/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 17/30 batch 172/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 17/30 batch 173/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch 174/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 17/30 batch 175/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 17/30 batch 176/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 17/30 batch 177/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 17/30 batch 178/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 179/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 17/30 batch 180/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 17/30 batch 181/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 182/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 17/30 batch 183/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 17/30 batch 184/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 17/30 batch 185/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 17/30 batch 186/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 17/30 batch 187/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 17/30 batch 188/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 17/30 batch 189/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 17/30 batch 190/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 17/30 batch 191/375  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 17/30 batch 192/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 17/30 batch 193/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 194/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 195/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 17/30 batch 196/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 17/30 batch 197/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch 198/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 17/30 batch 199/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 17/30 batch 200/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 17/30 batch 201/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 17/30 batch 202/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 17/30 batch 203/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 17/30 batch 204/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 205/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 17/30 batch 206/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 17/30 batch 207/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 17/30 batch 208/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 17/30 batch 209/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 17/30 batch 210/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 17/30 batch 211/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 212/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 17/30 batch 213/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 17/30 batch 214/375  Train Loss: 0.034, Acc: 0.977\n",
      "epoch: 17/30 batch 215/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 17/30 batch 216/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 17/30 batch 217/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 17/30 batch 218/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 17/30 batch 219/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 17/30 batch 220/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 17/30 batch 221/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 17/30 batch 222/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 17/30 batch 223/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 17/30 batch 224/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 17/30 batch 225/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch 226/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 17/30 batch 227/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 17/30 batch 228/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 17/30 batch 229/375  Train Loss: 0.082, Acc: 0.977\n",
      "epoch: 17/30 batch 230/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 231/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 17/30 batch 232/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 17/30 batch 233/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 17/30 batch 234/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 17/30 batch 235/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 17/30 batch 236/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 17/30 batch 237/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 17/30 batch 238/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 17/30 batch 239/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 17/30 batch 240/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch 241/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 17/30 batch 242/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 17/30 batch 243/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 17/30 batch 244/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 17/30 batch 245/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 17/30 batch 246/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 17/30 batch 247/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 17/30 batch 248/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 17/30 batch 249/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 17/30 batch 250/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 251/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 17/30 batch 252/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch 253/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 17/30 batch 254/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 17/30 batch 255/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 17/30 batch 256/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 17/30 batch 257/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 17/30 batch 258/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 259/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 17/30 batch 260/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 17/30 batch 261/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 17/30 batch 262/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 17/30 batch 263/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 17/30 batch 264/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 17/30 batch 265/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 17/30 batch 266/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch 267/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 268/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 17/30 batch 269/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 17/30 batch 270/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 17/30 batch 271/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 17/30 batch 272/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 17/30 batch 273/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 17/30 batch 274/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 17/30 batch 275/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch 276/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch 277/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 17/30 batch 278/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 17/30 batch 279/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 17/30 batch 280/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 17/30 batch 281/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 17/30 batch 282/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 17/30 batch 283/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 17/30 batch 284/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 17/30 batch 285/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 17/30 batch 286/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 17/30 batch 287/375  Train Loss: 0.018, Acc: 0.984\n",
      "epoch: 17/30 batch 288/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 17/30 batch 289/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 17/30 batch 290/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 17/30 batch 291/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 17/30 batch 292/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 17/30 batch 293/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 17/30 batch 294/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 17/30 batch 295/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 17/30 batch 296/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 17/30 batch 297/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 17/30 batch 298/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 299/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 17/30 batch 300/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 17/30 batch 301/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 17/30 batch 302/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 17/30 batch 303/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 17/30 batch 304/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 17/30 batch 305/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 17/30 batch 306/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 17/30 batch 307/375  Train Loss: 0.094, Acc: 0.977\n",
      "epoch: 17/30 batch 308/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 17/30 batch 309/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 17/30 batch 310/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 311/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 17/30 batch 312/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch 313/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 17/30 batch 314/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 17/30 batch 315/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 17/30 batch 316/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 17/30 batch 317/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 17/30 batch 318/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 17/30 batch 319/375  Train Loss: 0.033, Acc: 0.977\n",
      "epoch: 17/30 batch 320/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 17/30 batch 321/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 17/30 batch 322/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 17/30 batch 323/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 17/30 batch 324/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 17/30 batch 325/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 17/30 batch 326/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 17/30 batch 327/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 328/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 17/30 batch 329/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 17/30 batch 330/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 17/30 batch 331/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 17/30 batch 332/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 17/30 batch 333/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 17/30 batch 334/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 17/30 batch 335/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 17/30 batch 336/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 337/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 17/30 batch 338/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 17/30 batch 339/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 17/30 batch 340/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 17/30 batch 341/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 17/30 batch 342/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 17/30 batch 343/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 17/30 batch 344/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 17/30 batch 345/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 17/30 batch 346/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 17/30 batch 347/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 17/30 batch 348/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 17/30 batch 349/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 17/30 batch 350/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 17/30 batch 351/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 17/30 batch 352/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 17/30 batch 353/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 17/30 batch 354/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 17/30 batch 355/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 17/30 batch 356/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 17/30 batch 357/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 17/30 batch 358/375  Train Loss: 0.018, Acc: 0.984\n",
      "epoch: 17/30 batch 359/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 17/30 batch 360/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 17/30 batch 361/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 17/30 batch 362/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 363/375  Train Loss: 0.072, Acc: 0.969\n",
      "epoch: 17/30 batch 364/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 17/30 batch 365/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 17/30 batch 366/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 17/30 batch 367/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 17/30 batch 368/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 17/30 batch 369/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 17/30 batch 370/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 17/30 batch 371/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 17/30 batch 372/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 17/30 batch 373/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 17/30 batch 374/375  Train Loss: 0.030, Acc: 0.992\n",
      "Train Loss: 0.024443, Acc: 0.993\n",
      "Val Loss: 0.031864, Acc: 0.989\n",
      "epoch: 18/30 batch   0/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 18/30 batch   1/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch   2/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 18/30 batch   3/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 18/30 batch   4/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 18/30 batch   5/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 18/30 batch   6/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch   7/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 18/30 batch   8/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 18/30 batch   9/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 18/30 batch  10/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch  11/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 18/30 batch  12/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 18/30 batch  13/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 18/30 batch  14/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 18/30 batch  15/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch  16/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch  17/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 18/30 batch  18/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 18/30 batch  19/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch  20/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch  21/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch  22/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 18/30 batch  23/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch  24/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 18/30 batch  25/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 18/30 batch  26/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 18/30 batch  27/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 18/30 batch  28/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 18/30 batch  29/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 18/30 batch  30/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 18/30 batch  31/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 18/30 batch  32/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 18/30 batch  33/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 18/30 batch  34/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 18/30 batch  35/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 18/30 batch  36/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 18/30 batch  37/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch  38/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 18/30 batch  39/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 18/30 batch  40/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch  41/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch  42/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 18/30 batch  43/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 18/30 batch  44/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch  45/375  Train Loss: 0.127, Acc: 0.984\n",
      "epoch: 18/30 batch  46/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch  47/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch  48/375  Train Loss: 0.059, Acc: 0.969\n",
      "epoch: 18/30 batch  49/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 18/30 batch  50/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 18/30 batch  51/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 18/30 batch  52/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 18/30 batch  53/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch  54/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 18/30 batch  55/375  Train Loss: 0.051, Acc: 0.977\n",
      "epoch: 18/30 batch  56/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch  57/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 18/30 batch  58/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 18/30 batch  59/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 18/30 batch  60/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 18/30 batch  61/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 18/30 batch  62/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 18/30 batch  63/375  Train Loss: 0.037, Acc: 0.977\n",
      "epoch: 18/30 batch  64/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 18/30 batch  65/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 18/30 batch  66/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 18/30 batch  67/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 18/30 batch  68/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 18/30 batch  69/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 18/30 batch  70/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 18/30 batch  71/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 18/30 batch  72/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 18/30 batch  73/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 18/30 batch  74/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 18/30 batch  75/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 18/30 batch  76/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 18/30 batch  77/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 18/30 batch  78/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 18/30 batch  79/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 18/30 batch  80/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch  81/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 18/30 batch  82/375  Train Loss: 0.111, Acc: 0.984\n",
      "epoch: 18/30 batch  83/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 18/30 batch  84/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch  85/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 18/30 batch  86/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 18/30 batch  87/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 18/30 batch  88/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 18/30 batch  89/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch  90/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 18/30 batch  91/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch  92/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 18/30 batch  93/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch  94/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 18/30 batch  95/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 18/30 batch  96/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 18/30 batch  97/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch  98/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 18/30 batch  99/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 18/30 batch 100/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 18/30 batch 101/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 18/30 batch 102/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 18/30 batch 103/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 18/30 batch 104/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 18/30 batch 105/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 18/30 batch 106/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 18/30 batch 107/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 108/375  Train Loss: 0.068, Acc: 0.984\n",
      "epoch: 18/30 batch 109/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 18/30 batch 110/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 18/30 batch 111/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch 112/375  Train Loss: 0.036, Acc: 0.977\n",
      "epoch: 18/30 batch 113/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch 114/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 18/30 batch 115/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 18/30 batch 116/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 18/30 batch 117/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 18/30 batch 118/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 18/30 batch 119/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 18/30 batch 120/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 18/30 batch 121/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch 122/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 18/30 batch 123/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 124/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 18/30 batch 125/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 126/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch 127/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 18/30 batch 128/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 18/30 batch 129/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 18/30 batch 130/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 18/30 batch 131/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 18/30 batch 132/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 133/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch 134/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch 135/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 18/30 batch 136/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 18/30 batch 137/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 138/375  Train Loss: 0.036, Acc: 0.977\n",
      "epoch: 18/30 batch 139/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 18/30 batch 140/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 141/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 18/30 batch 142/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch 143/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 18/30 batch 144/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 18/30 batch 145/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 18/30 batch 146/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 18/30 batch 147/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch 148/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 18/30 batch 149/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch 150/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 18/30 batch 151/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch 152/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 18/30 batch 153/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch 154/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch 155/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 18/30 batch 156/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 18/30 batch 157/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch 158/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 18/30 batch 159/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 18/30 batch 160/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 18/30 batch 161/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 18/30 batch 162/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 163/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 164/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch 165/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 18/30 batch 166/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 167/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 168/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 18/30 batch 169/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch 170/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 18/30 batch 171/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 18/30 batch 172/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 18/30 batch 173/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 18/30 batch 174/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 18/30 batch 175/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 18/30 batch 176/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 18/30 batch 177/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 18/30 batch 178/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 18/30 batch 179/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch 180/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 18/30 batch 181/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 18/30 batch 182/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 18/30 batch 183/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 18/30 batch 184/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 18/30 batch 185/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 18/30 batch 186/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 18/30 batch 187/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch 188/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 189/375  Train Loss: 0.106, Acc: 0.977\n",
      "epoch: 18/30 batch 190/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 18/30 batch 191/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 18/30 batch 192/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 18/30 batch 193/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 18/30 batch 194/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 18/30 batch 195/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 18/30 batch 196/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 197/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 18/30 batch 198/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 18/30 batch 199/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch 200/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 18/30 batch 201/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 18/30 batch 202/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 18/30 batch 203/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 204/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch 205/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 18/30 batch 206/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 18/30 batch 207/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 18/30 batch 208/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 18/30 batch 209/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch 210/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 18/30 batch 211/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 18/30 batch 212/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 18/30 batch 213/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 18/30 batch 214/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 18/30 batch 215/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 18/30 batch 216/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch 217/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 18/30 batch 218/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 18/30 batch 219/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch 220/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 221/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch 222/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 18/30 batch 223/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 18/30 batch 224/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 18/30 batch 225/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 18/30 batch 226/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 227/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 18/30 batch 228/375  Train Loss: 0.037, Acc: 0.977\n",
      "epoch: 18/30 batch 229/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 18/30 batch 230/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 18/30 batch 231/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 18/30 batch 232/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 18/30 batch 233/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 18/30 batch 234/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 18/30 batch 235/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch 236/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 18/30 batch 237/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch 238/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 18/30 batch 239/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 240/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch 241/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 18/30 batch 242/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 18/30 batch 243/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 18/30 batch 244/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 18/30 batch 245/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 246/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 18/30 batch 247/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 248/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 18/30 batch 249/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 18/30 batch 250/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 18/30 batch 251/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch 252/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 18/30 batch 253/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch 254/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 18/30 batch 255/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 18/30 batch 256/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch 257/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 18/30 batch 258/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 18/30 batch 259/375  Train Loss: 0.059, Acc: 0.969\n",
      "epoch: 18/30 batch 260/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch 261/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 18/30 batch 262/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 18/30 batch 263/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 264/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 265/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 18/30 batch 266/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 18/30 batch 267/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 268/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 18/30 batch 269/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 18/30 batch 270/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 18/30 batch 271/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 272/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch 273/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 274/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 18/30 batch 275/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch 276/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 18/30 batch 277/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch 278/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 18/30 batch 279/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 280/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 281/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 18/30 batch 282/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 18/30 batch 283/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 18/30 batch 284/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 18/30 batch 285/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 18/30 batch 286/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 18/30 batch 287/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 18/30 batch 288/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 289/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 18/30 batch 290/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 291/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 18/30 batch 292/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 18/30 batch 293/375  Train Loss: 0.107, Acc: 0.977\n",
      "epoch: 18/30 batch 294/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch 295/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 18/30 batch 296/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 18/30 batch 297/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch 298/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 18/30 batch 299/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 18/30 batch 300/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 18/30 batch 301/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 302/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 18/30 batch 303/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 18/30 batch 304/375  Train Loss: 0.062, Acc: 0.977\n",
      "epoch: 18/30 batch 305/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch 306/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 18/30 batch 307/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 18/30 batch 308/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 18/30 batch 309/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 18/30 batch 310/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch 311/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 18/30 batch 312/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 18/30 batch 313/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 18/30 batch 314/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 18/30 batch 315/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 18/30 batch 316/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 18/30 batch 317/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch: 18/30 batch 318/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 319/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 18/30 batch 320/375  Train Loss: 0.038, Acc: 0.977\n",
      "epoch: 18/30 batch 321/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 18/30 batch 322/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 18/30 batch 323/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 18/30 batch 324/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch 325/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 18/30 batch 326/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 18/30 batch 327/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch 328/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 18/30 batch 329/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 330/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 18/30 batch 331/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 18/30 batch 332/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 18/30 batch 333/375  Train Loss: 0.033, Acc: 0.977\n",
      "epoch: 18/30 batch 334/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 18/30 batch 335/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 336/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 18/30 batch 337/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 338/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 18/30 batch 339/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch 340/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 18/30 batch 341/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 18/30 batch 342/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 18/30 batch 343/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 18/30 batch 344/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 18/30 batch 345/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 18/30 batch 346/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 18/30 batch 347/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 18/30 batch 348/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 18/30 batch 349/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch 350/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 18/30 batch 351/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 18/30 batch 352/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 18/30 batch 353/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 18/30 batch 354/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 18/30 batch 355/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 18/30 batch 356/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch 357/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 18/30 batch 358/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 18/30 batch 359/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 18/30 batch 360/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 18/30 batch 361/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 18/30 batch 362/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 18/30 batch 363/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 18/30 batch 364/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 18/30 batch 365/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 18/30 batch 366/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 18/30 batch 367/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 18/30 batch 368/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 18/30 batch 369/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 18/30 batch 370/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 18/30 batch 371/375  Train Loss: 0.041, Acc: 0.977\n",
      "epoch: 18/30 batch 372/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 18/30 batch 373/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 18/30 batch 374/375  Train Loss: 0.049, Acc: 0.992\n",
      "Train Loss: 0.023890, Acc: 0.993\n",
      "Val Loss: 0.030694, Acc: 0.990\n",
      "epoch: 19/30 batch   0/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 19/30 batch   1/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch   2/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch   3/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 19/30 batch   4/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 19/30 batch   5/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 19/30 batch   6/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 19/30 batch   7/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 19/30 batch   8/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 19/30 batch   9/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 19/30 batch  10/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 19/30 batch  11/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 19/30 batch  12/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 19/30 batch  13/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch  14/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch  15/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 19/30 batch  16/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 19/30 batch  17/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch  18/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 19/30 batch  19/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch  20/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 19/30 batch  21/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 19/30 batch  22/375  Train Loss: 0.065, Acc: 0.969\n",
      "epoch: 19/30 batch  23/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 19/30 batch  24/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch  25/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch  26/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 19/30 batch  27/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 19/30 batch  28/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 19/30 batch  29/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 19/30 batch  30/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 19/30 batch  31/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch  32/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 19/30 batch  33/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 19/30 batch  34/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch  35/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch  36/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 19/30 batch  37/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 19/30 batch  38/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 19/30 batch  39/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 19/30 batch  40/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 19/30 batch  41/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 19/30 batch  42/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 19/30 batch  43/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 19/30 batch  44/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 19/30 batch  45/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 19/30 batch  46/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 19/30 batch  47/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch  48/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 19/30 batch  49/375  Train Loss: 0.065, Acc: 0.984\n",
      "epoch: 19/30 batch  50/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 19/30 batch  51/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 19/30 batch  52/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 19/30 batch  53/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch  54/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 19/30 batch  55/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 19/30 batch  56/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 19/30 batch  57/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 19/30 batch  58/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 19/30 batch  59/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch  60/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 19/30 batch  61/375  Train Loss: 0.042, Acc: 0.977\n",
      "epoch: 19/30 batch  62/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 19/30 batch  63/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 19/30 batch  64/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 19/30 batch  65/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 19/30 batch  66/375  Train Loss: 0.077, Acc: 0.984\n",
      "epoch: 19/30 batch  67/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 19/30 batch  68/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch  69/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 19/30 batch  70/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 19/30 batch  71/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 19/30 batch  72/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 19/30 batch  73/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch  74/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 19/30 batch  75/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch  76/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch  77/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 19/30 batch  78/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 19/30 batch  79/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 19/30 batch  80/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 19/30 batch  81/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 19/30 batch  82/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 19/30 batch  83/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 19/30 batch  84/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch  85/375  Train Loss: 0.081, Acc: 0.969\n",
      "epoch: 19/30 batch  86/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 19/30 batch  87/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 19/30 batch  88/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 19/30 batch  89/375  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 19/30 batch  90/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 19/30 batch  91/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 19/30 batch  92/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch  93/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch  94/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 19/30 batch  95/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch  96/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 19/30 batch  97/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch  98/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 19/30 batch  99/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 19/30 batch 100/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 19/30 batch 101/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 19/30 batch 102/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch 103/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 19/30 batch 104/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch 105/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 19/30 batch 106/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 19/30 batch 107/375  Train Loss: 0.079, Acc: 0.992\n",
      "epoch: 19/30 batch 108/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch 109/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 19/30 batch 110/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 19/30 batch 111/375  Train Loss: 0.034, Acc: 0.977\n",
      "epoch: 19/30 batch 112/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch 113/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 114/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 115/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 19/30 batch 116/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 19/30 batch 117/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 19/30 batch 118/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 19/30 batch 119/375  Train Loss: 0.008, Acc: 0.992\n",
      "epoch: 19/30 batch 120/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 19/30 batch 121/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 19/30 batch 122/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 19/30 batch 123/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch 124/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 19/30 batch 125/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 19/30 batch 126/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 19/30 batch 127/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 19/30 batch 128/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 19/30 batch 129/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch 130/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 19/30 batch 131/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 19/30 batch 132/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 19/30 batch 133/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 19/30 batch 134/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 19/30 batch 135/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 19/30 batch 136/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 19/30 batch 137/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 19/30 batch 138/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch 139/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 19/30 batch 140/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 19/30 batch 141/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 19/30 batch 142/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 19/30 batch 143/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch 144/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 19/30 batch 145/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 19/30 batch 146/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 19/30 batch 147/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 19/30 batch 148/375  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 19/30 batch 149/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 19/30 batch 150/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 19/30 batch 151/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 19/30 batch 152/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 19/30 batch 153/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 19/30 batch 154/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 155/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 156/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 19/30 batch 157/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch 158/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch 159/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 160/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 19/30 batch 161/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 19/30 batch 162/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 19/30 batch 163/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch 164/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 19/30 batch 165/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 19/30 batch 166/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 167/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch 168/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 19/30 batch 169/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 19/30 batch 170/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 19/30 batch 171/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 19/30 batch 172/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 19/30 batch 173/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 19/30 batch 174/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch 175/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch 176/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 19/30 batch 177/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 19/30 batch 178/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 19/30 batch 179/375  Train Loss: 0.035, Acc: 0.977\n",
      "epoch: 19/30 batch 180/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 19/30 batch 181/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 182/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch 183/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 184/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 19/30 batch 185/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 19/30 batch 186/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 19/30 batch 187/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 19/30 batch 188/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 19/30 batch 189/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 19/30 batch 190/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch 191/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch 192/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch 193/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 19/30 batch 194/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 19/30 batch 195/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 19/30 batch 196/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 19/30 batch 197/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 19/30 batch 198/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 19/30 batch 199/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 19/30 batch 200/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 201/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 19/30 batch 202/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 19/30 batch 203/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 19/30 batch 204/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 19/30 batch 205/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch 206/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 19/30 batch 207/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 19/30 batch 208/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 19/30 batch 209/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 19/30 batch 210/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch 211/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 19/30 batch 212/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 19/30 batch 213/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 19/30 batch 214/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 215/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 19/30 batch 216/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 19/30 batch 217/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 19/30 batch 218/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 19/30 batch 219/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 19/30 batch 220/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 19/30 batch 221/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 19/30 batch 222/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 19/30 batch 223/375  Train Loss: 0.018, Acc: 0.984\n",
      "epoch: 19/30 batch 224/375  Train Loss: 0.134, Acc: 0.984\n",
      "epoch: 19/30 batch 225/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 19/30 batch 226/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 19/30 batch 227/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 19/30 batch 228/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 19/30 batch 229/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 19/30 batch 230/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 19/30 batch 231/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 19/30 batch 232/375  Train Loss: 0.049, Acc: 0.969\n",
      "epoch: 19/30 batch 233/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 19/30 batch 234/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 19/30 batch 235/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 19/30 batch 236/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 19/30 batch 237/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 238/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 19/30 batch 239/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 19/30 batch 240/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 19/30 batch 241/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 19/30 batch 242/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 19/30 batch 243/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 19/30 batch 244/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 19/30 batch 245/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 19/30 batch 246/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 19/30 batch 247/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 19/30 batch 248/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 19/30 batch 249/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 19/30 batch 250/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 19/30 batch 251/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 19/30 batch 252/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 19/30 batch 253/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 19/30 batch 254/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 19/30 batch 255/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 19/30 batch 256/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 19/30 batch 257/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 19/30 batch 258/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 19/30 batch 259/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 19/30 batch 260/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 19/30 batch 261/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch 262/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 19/30 batch 263/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch 264/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 19/30 batch 265/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 19/30 batch 266/375  Train Loss: 0.089, Acc: 0.977\n",
      "epoch: 19/30 batch 267/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 19/30 batch 268/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 19/30 batch 269/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 19/30 batch 270/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 271/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch 272/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 19/30 batch 273/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 19/30 batch 274/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 19/30 batch 275/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 19/30 batch 276/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 277/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 19/30 batch 278/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 19/30 batch 279/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch 280/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 19/30 batch 281/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 19/30 batch 282/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 19/30 batch 283/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 19/30 batch 284/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 19/30 batch 285/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 19/30 batch 286/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch 287/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 19/30 batch 288/375  Train Loss: 0.036, Acc: 0.977\n",
      "epoch: 19/30 batch 289/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 19/30 batch 290/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 19/30 batch 291/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch 292/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 19/30 batch 293/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 19/30 batch 294/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 19/30 batch 295/375  Train Loss: 0.068, Acc: 0.977\n",
      "epoch: 19/30 batch 296/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 19/30 batch 297/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 19/30 batch 298/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 19/30 batch 299/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 19/30 batch 300/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 19/30 batch 301/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 19/30 batch 302/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 19/30 batch 303/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 19/30 batch 304/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 305/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 19/30 batch 306/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 19/30 batch 307/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 19/30 batch 308/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 19/30 batch 309/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 19/30 batch 310/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 19/30 batch 311/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 19/30 batch 312/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 19/30 batch 313/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 19/30 batch 314/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 19/30 batch 315/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch 316/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 19/30 batch 317/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 19/30 batch 318/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 19/30 batch 319/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 19/30 batch 320/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 19/30 batch 321/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 19/30 batch 322/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 19/30 batch 323/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 324/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 19/30 batch 325/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 19/30 batch 326/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch 327/375  Train Loss: 0.027, Acc: 1.000\n",
      "epoch: 19/30 batch 328/375  Train Loss: 0.017, Acc: 0.984\n",
      "epoch: 19/30 batch 329/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 19/30 batch 330/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 19/30 batch 331/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 19/30 batch 332/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 19/30 batch 333/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 19/30 batch 334/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 19/30 batch 335/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 19/30 batch 336/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 19/30 batch 337/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch 338/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 19/30 batch 339/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 19/30 batch 340/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 19/30 batch 341/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 19/30 batch 342/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 19/30 batch 343/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 19/30 batch 344/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 19/30 batch 345/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 19/30 batch 346/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 19/30 batch 347/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 19/30 batch 348/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 19/30 batch 349/375  Train Loss: 0.093, Acc: 0.969\n",
      "epoch: 19/30 batch 350/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 19/30 batch 351/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 19/30 batch 352/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 19/30 batch 353/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 19/30 batch 354/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 19/30 batch 355/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch 356/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 19/30 batch 357/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 19/30 batch 358/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 19/30 batch 359/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 19/30 batch 360/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 361/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 19/30 batch 362/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 19/30 batch 363/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 19/30 batch 364/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 19/30 batch 365/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 19/30 batch 366/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 367/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 19/30 batch 368/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 19/30 batch 369/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 19/30 batch 370/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 19/30 batch 371/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 19/30 batch 372/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 19/30 batch 373/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 19/30 batch 374/375  Train Loss: 0.015, Acc: 0.992\n",
      "Train Loss: 0.023897, Acc: 0.993\n",
      "Val Loss: 0.032162, Acc: 0.989\n",
      "epoch: 20/30 batch   0/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch   1/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 20/30 batch   2/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch   3/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 20/30 batch   4/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 20/30 batch   5/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch   6/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch   7/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch   8/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 20/30 batch   9/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch  10/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch  11/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch  12/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 20/30 batch  13/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 20/30 batch  14/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 20/30 batch  15/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 20/30 batch  16/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch  17/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 20/30 batch  18/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 20/30 batch  19/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch  20/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch  21/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 20/30 batch  22/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch  23/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch  24/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 20/30 batch  25/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 20/30 batch  26/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 20/30 batch  27/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 20/30 batch  28/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch  29/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 20/30 batch  30/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch  31/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch  32/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch  33/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 20/30 batch  34/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 20/30 batch  35/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch  36/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch  37/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch  38/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch  39/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 20/30 batch  40/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch  41/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch  42/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 20/30 batch  43/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 20/30 batch  44/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 20/30 batch  45/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch  46/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 20/30 batch  47/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 20/30 batch  48/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch  49/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 20/30 batch  50/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 20/30 batch  51/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch  52/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 20/30 batch  53/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 20/30 batch  54/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 20/30 batch  55/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch  56/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 20/30 batch  57/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 20/30 batch  58/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 20/30 batch  59/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 20/30 batch  60/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch  61/375  Train Loss: 0.097, Acc: 0.984\n",
      "epoch: 20/30 batch  62/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch  63/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 20/30 batch  64/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 20/30 batch  65/375  Train Loss: 0.045, Acc: 0.969\n",
      "epoch: 20/30 batch  66/375  Train Loss: 0.080, Acc: 0.992\n",
      "epoch: 20/30 batch  67/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch  68/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch  69/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 20/30 batch  70/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 20/30 batch  71/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 20/30 batch  72/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 20/30 batch  73/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 20/30 batch  74/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch  75/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch  76/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 20/30 batch  77/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 20/30 batch  78/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 20/30 batch  79/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch  80/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 20/30 batch  81/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch  82/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 20/30 batch  83/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 20/30 batch  84/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 20/30 batch  85/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 20/30 batch  86/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch  87/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 20/30 batch  88/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch  89/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch  90/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 20/30 batch  91/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch  92/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch  93/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 20/30 batch  94/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 20/30 batch  95/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch  96/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch  97/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 20/30 batch  98/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 20/30 batch  99/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 100/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 20/30 batch 101/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 20/30 batch 102/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch 103/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 104/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 20/30 batch 105/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 20/30 batch 106/375  Train Loss: 0.032, Acc: 0.977\n",
      "epoch: 20/30 batch 107/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 20/30 batch 108/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 20/30 batch 109/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 110/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 20/30 batch 111/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 20/30 batch 112/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 20/30 batch 113/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 114/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 115/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 20/30 batch 116/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 20/30 batch 117/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 118/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch 119/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 20/30 batch 120/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 20/30 batch 121/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 122/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 20/30 batch 123/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 124/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 125/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 126/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 20/30 batch 127/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 20/30 batch 128/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 129/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 20/30 batch 130/375  Train Loss: 0.033, Acc: 0.977\n",
      "epoch: 20/30 batch 131/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 132/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 20/30 batch 133/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 20/30 batch 134/375  Train Loss: 0.057, Acc: 0.992\n",
      "epoch: 20/30 batch 135/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 136/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 20/30 batch 137/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 20/30 batch 138/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 139/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 20/30 batch 140/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 141/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 20/30 batch 142/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 143/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 20/30 batch 144/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 20/30 batch 145/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 20/30 batch 146/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 20/30 batch 147/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch 148/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 20/30 batch 149/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 150/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch 151/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 20/30 batch 152/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 153/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 20/30 batch 154/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 20/30 batch 155/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 20/30 batch 156/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 157/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch 158/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 20/30 batch 159/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 160/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 161/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 20/30 batch 162/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 163/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 20/30 batch 164/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 165/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 166/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 20/30 batch 167/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 20/30 batch 168/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 20/30 batch 169/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 170/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 20/30 batch 171/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 172/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 20/30 batch 173/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 174/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 175/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 176/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 20/30 batch 177/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 20/30 batch 178/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 20/30 batch 179/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 20/30 batch 180/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 20/30 batch 181/375  Train Loss: 0.056, Acc: 0.992\n",
      "epoch: 20/30 batch 182/375  Train Loss: 0.069, Acc: 0.977\n",
      "epoch: 20/30 batch 183/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 184/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch 185/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 20/30 batch 186/375  Train Loss: 0.065, Acc: 0.969\n",
      "epoch: 20/30 batch 187/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 20/30 batch 188/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch 189/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 20/30 batch 190/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 20/30 batch 191/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 20/30 batch 192/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 193/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 20/30 batch 194/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 20/30 batch 195/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 20/30 batch 196/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 197/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 198/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 20/30 batch 199/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 20/30 batch 200/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 20/30 batch 201/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 20/30 batch 202/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 20/30 batch 203/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 20/30 batch 204/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 20/30 batch 205/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 20/30 batch 206/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 20/30 batch 207/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 20/30 batch 208/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 20/30 batch 209/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 20/30 batch 210/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch 211/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 212/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 213/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 20/30 batch 214/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 215/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 20/30 batch 216/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 20/30 batch 217/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 218/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 219/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 20/30 batch 220/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 221/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 222/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 20/30 batch 223/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 20/30 batch 224/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 225/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 226/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 20/30 batch 227/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 20/30 batch 228/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 20/30 batch 229/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 230/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 20/30 batch 231/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 232/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 233/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 234/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 235/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 20/30 batch 236/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 237/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 238/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 239/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 20/30 batch 240/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 20/30 batch 241/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 20/30 batch 242/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 20/30 batch 243/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 20/30 batch 244/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 245/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 20/30 batch 246/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 247/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 248/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 20/30 batch 249/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 20/30 batch 250/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 251/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 252/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 253/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 254/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch 255/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 20/30 batch 256/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 257/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 258/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 20/30 batch 259/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 260/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch 261/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 262/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 20/30 batch 263/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 264/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 265/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 266/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 20/30 batch 267/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 268/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 269/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 20/30 batch 270/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 271/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 20/30 batch 272/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 20/30 batch 273/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 274/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 275/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 20/30 batch 276/375  Train Loss: 0.082, Acc: 0.984\n",
      "epoch: 20/30 batch 277/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 278/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 20/30 batch 279/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 280/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 20/30 batch 281/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 20/30 batch 282/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 20/30 batch 283/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 284/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 20/30 batch 285/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 20/30 batch 286/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 287/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 20/30 batch 288/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 289/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 20/30 batch 290/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 20/30 batch 291/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 20/30 batch 292/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 20/30 batch 293/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 294/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 295/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 296/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 20/30 batch 297/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 20/30 batch 298/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch 299/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 300/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 301/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 20/30 batch 302/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 20/30 batch 303/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 304/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 305/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 20/30 batch 306/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 20/30 batch 307/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 308/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 309/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 20/30 batch 310/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 20/30 batch 311/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 312/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 20/30 batch 313/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 314/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 20/30 batch 315/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 20/30 batch 316/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 20/30 batch 317/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 20/30 batch 318/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 20/30 batch 319/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 20/30 batch 320/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 321/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 20/30 batch 322/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 20/30 batch 323/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 20/30 batch 324/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 20/30 batch 325/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 20/30 batch 326/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 327/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 328/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 20/30 batch 329/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 20/30 batch 330/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 20/30 batch 331/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 20/30 batch 332/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 333/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 20/30 batch 334/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 335/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 20/30 batch 336/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 20/30 batch 337/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 20/30 batch 338/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 20/30 batch 339/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 340/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 20/30 batch 341/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 20/30 batch 342/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 343/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 20/30 batch 344/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 20/30 batch 345/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 20/30 batch 346/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 347/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 348/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 20/30 batch 349/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 350/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 20/30 batch 351/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 20/30 batch 352/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 20/30 batch 353/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch 354/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 20/30 batch 355/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 20/30 batch 356/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 20/30 batch 357/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 20/30 batch 358/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 20/30 batch 359/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 20/30 batch 360/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 20/30 batch 361/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 20/30 batch 362/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 363/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 20/30 batch 364/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 20/30 batch 365/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 20/30 batch 366/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 20/30 batch 367/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 20/30 batch 368/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 20/30 batch 369/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 370/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 20/30 batch 371/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 20/30 batch 372/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 20/30 batch 373/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 20/30 batch 374/375  Train Loss: 0.014, Acc: 1.000\n",
      "Train Loss: 0.018396, Acc: 0.995\n",
      "Val Loss: 0.029311, Acc: 0.990\n",
      "epoch: 21/30 batch   0/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 21/30 batch   1/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 21/30 batch   2/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch   3/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 21/30 batch   4/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 21/30 batch   5/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 21/30 batch   6/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 21/30 batch   7/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 21/30 batch   8/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch   9/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch  10/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch  11/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch  12/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 21/30 batch  13/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch  14/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch  15/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch  16/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 21/30 batch  17/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 21/30 batch  18/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch  19/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 21/30 batch  20/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch  21/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch  22/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 21/30 batch  23/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch  24/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch  25/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 21/30 batch  26/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch  27/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 21/30 batch  28/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch  29/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch  30/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 21/30 batch  31/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch  32/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 21/30 batch  33/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch  34/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch  35/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 21/30 batch  36/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 21/30 batch  37/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 21/30 batch  38/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch  39/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 21/30 batch  40/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 21/30 batch  41/375  Train Loss: 0.054, Acc: 0.984\n",
      "epoch: 21/30 batch  42/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 21/30 batch  43/375  Train Loss: 0.093, Acc: 0.984\n",
      "epoch: 21/30 batch  44/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch  45/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 21/30 batch  46/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 21/30 batch  47/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch  48/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 21/30 batch  49/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 21/30 batch  50/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch  51/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch  52/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 21/30 batch  53/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 21/30 batch  54/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch  55/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch  56/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 21/30 batch  57/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch  58/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch  59/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch  60/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch  61/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 21/30 batch  62/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch  63/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 21/30 batch  64/375  Train Loss: 0.035, Acc: 0.977\n",
      "epoch: 21/30 batch  65/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 21/30 batch  66/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 21/30 batch  67/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch  68/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 21/30 batch  69/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 21/30 batch  70/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 21/30 batch  71/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 21/30 batch  72/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch  73/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 21/30 batch  74/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch  75/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 21/30 batch  76/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 21/30 batch  77/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch  78/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 21/30 batch  79/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 21/30 batch  80/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch  81/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 21/30 batch  82/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 21/30 batch  83/375  Train Loss: 0.065, Acc: 0.961\n",
      "epoch: 21/30 batch  84/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch  85/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 21/30 batch  86/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch  87/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch  88/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 21/30 batch  89/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch  90/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch  91/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 21/30 batch  92/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 21/30 batch  93/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 21/30 batch  94/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch  95/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 21/30 batch  96/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch  97/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 21/30 batch  98/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch  99/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 100/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch 101/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 102/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 21/30 batch 103/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 104/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch 105/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 106/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 21/30 batch 107/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 108/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 109/375  Train Loss: 0.102, Acc: 0.992\n",
      "epoch: 21/30 batch 110/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 111/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 21/30 batch 112/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 113/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch 114/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 115/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 21/30 batch 116/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 21/30 batch 117/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 118/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 119/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 21/30 batch 120/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 21/30 batch 121/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 21/30 batch 122/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 21/30 batch 123/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 21/30 batch 124/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 125/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 126/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 21/30 batch 127/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 21/30 batch 128/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 21/30 batch 129/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 21/30 batch 130/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 21/30 batch 131/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 21/30 batch 132/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 133/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 21/30 batch 134/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 21/30 batch 135/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 21/30 batch 136/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 137/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 138/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 139/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch 140/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 21/30 batch 141/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 142/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 143/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch 144/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 145/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch 146/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 21/30 batch 147/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 148/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 149/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 21/30 batch 150/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 151/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 21/30 batch 152/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 21/30 batch 153/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch 154/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 21/30 batch 155/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 156/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 157/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 21/30 batch 158/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 159/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 21/30 batch 160/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 161/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 162/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 21/30 batch 163/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 21/30 batch 164/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 21/30 batch 165/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 21/30 batch 166/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 167/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 168/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 169/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 21/30 batch 170/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch 171/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 172/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 21/30 batch 173/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 21/30 batch 174/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch 175/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 21/30 batch 176/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 21/30 batch 177/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 178/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 21/30 batch 179/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 21/30 batch 180/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 21/30 batch 181/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 182/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 21/30 batch 183/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 21/30 batch 184/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 21/30 batch 185/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 21/30 batch 186/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch 187/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch 188/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch 189/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 190/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch 191/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 192/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 21/30 batch 193/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 21/30 batch 194/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch 195/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 21/30 batch 196/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch 197/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 198/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 21/30 batch 199/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch 200/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 201/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch 202/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 21/30 batch 203/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 21/30 batch 204/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 21/30 batch 205/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 206/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 21/30 batch 207/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 208/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 21/30 batch 209/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 21/30 batch 210/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 21/30 batch 211/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 212/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 213/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 214/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 215/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 21/30 batch 216/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 21/30 batch 217/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch 218/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 21/30 batch 219/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 21/30 batch 220/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 221/375  Train Loss: 0.051, Acc: 0.992\n",
      "epoch: 21/30 batch 222/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 21/30 batch 223/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 21/30 batch 224/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 21/30 batch 225/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch 226/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 21/30 batch 227/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch 228/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 21/30 batch 229/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 230/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 231/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 21/30 batch 232/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 21/30 batch 233/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 21/30 batch 234/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 21/30 batch 235/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 236/375  Train Loss: 0.055, Acc: 0.992\n",
      "epoch: 21/30 batch 237/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 238/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 239/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 21/30 batch 240/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 21/30 batch 241/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 21/30 batch 242/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 21/30 batch 243/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch 244/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 21/30 batch 245/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 246/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 21/30 batch 247/375  Train Loss: 0.048, Acc: 0.977\n",
      "epoch: 21/30 batch 248/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 249/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 250/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 21/30 batch 251/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 21/30 batch 252/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 253/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 254/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 21/30 batch 255/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 21/30 batch 256/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 21/30 batch 257/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch 258/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 21/30 batch 259/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 21/30 batch 260/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 21/30 batch 261/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 21/30 batch 262/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 263/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 21/30 batch 264/375  Train Loss: 0.017, Acc: 0.984\n",
      "epoch: 21/30 batch 265/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch 266/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 267/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch 268/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 269/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 21/30 batch 270/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 271/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 21/30 batch 272/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 273/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 274/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 21/30 batch 275/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 21/30 batch 276/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 21/30 batch 277/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 21/30 batch 278/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch 279/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 280/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch 281/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch 282/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch 283/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 21/30 batch 284/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 285/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 21/30 batch 286/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 21/30 batch 287/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 21/30 batch 288/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 289/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch 290/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 21/30 batch 291/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 21/30 batch 292/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 21/30 batch 293/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 21/30 batch 294/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 295/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch 296/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 21/30 batch 297/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 21/30 batch 298/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 21/30 batch 299/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 21/30 batch 300/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 21/30 batch 301/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 302/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 21/30 batch 303/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 21/30 batch 304/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 21/30 batch 305/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch 306/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 21/30 batch 307/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 308/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 309/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 21/30 batch 310/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 21/30 batch 311/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 21/30 batch 312/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 21/30 batch 313/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 21/30 batch 314/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 21/30 batch 315/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 21/30 batch 316/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 21/30 batch 317/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 21/30 batch 318/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 21/30 batch 319/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 21/30 batch 320/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 21/30 batch 321/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 21/30 batch 322/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch 323/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 21/30 batch 324/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 325/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 21/30 batch 326/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 21/30 batch 327/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 21/30 batch 328/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 21/30 batch 329/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 21/30 batch 330/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 331/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 21/30 batch 332/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch 333/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 21/30 batch 334/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 21/30 batch 335/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 336/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 21/30 batch 337/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 21/30 batch 338/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 21/30 batch 339/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 21/30 batch 340/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 341/375  Train Loss: 0.035, Acc: 0.977\n",
      "epoch: 21/30 batch 342/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 21/30 batch 343/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 21/30 batch 344/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch 345/375  Train Loss: 0.069, Acc: 0.984\n",
      "epoch: 21/30 batch 346/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 347/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 348/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 349/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 21/30 batch 350/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch 351/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 352/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 21/30 batch 353/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 21/30 batch 354/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 355/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 21/30 batch 356/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 21/30 batch 357/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 21/30 batch 358/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 21/30 batch 359/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 360/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 21/30 batch 361/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 362/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 21/30 batch 363/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 21/30 batch 364/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 21/30 batch 365/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 21/30 batch 366/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 21/30 batch 367/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 21/30 batch 368/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 21/30 batch 369/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 21/30 batch 370/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 21/30 batch 371/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 21/30 batch 372/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 21/30 batch 373/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 21/30 batch 374/375  Train Loss: 0.008, Acc: 0.992\n",
      "Train Loss: 0.017693, Acc: 0.995\n",
      "Val Loss: 0.028844, Acc: 0.990\n",
      "epoch: 22/30 batch   0/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch   1/375  Train Loss: 0.056, Acc: 0.977\n",
      "epoch: 22/30 batch   2/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch   3/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 22/30 batch   4/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 22/30 batch   5/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch   6/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 22/30 batch   7/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch   8/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 22/30 batch   9/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch  10/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch  11/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch  12/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch  13/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch  14/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch  15/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 22/30 batch  16/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch  17/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch  18/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 22/30 batch  19/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 22/30 batch  20/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 22/30 batch  21/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 22/30 batch  22/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 22/30 batch  23/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch  24/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch  25/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch  26/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch  27/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch  28/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch  29/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 22/30 batch  30/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch  31/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 22/30 batch  32/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch  33/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch  34/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 22/30 batch  35/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 22/30 batch  36/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch  37/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch  38/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 22/30 batch  39/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 22/30 batch  40/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 22/30 batch  41/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch  42/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch  43/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch  44/375  Train Loss: 0.047, Acc: 0.977\n",
      "epoch: 22/30 batch  45/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 22/30 batch  46/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch  47/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch  48/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 22/30 batch  49/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 22/30 batch  50/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 22/30 batch  51/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 22/30 batch  52/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 22/30 batch  53/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 22/30 batch  54/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 22/30 batch  55/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch  56/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch  57/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 22/30 batch  58/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 22/30 batch  59/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 22/30 batch  60/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch  61/375  Train Loss: 0.060, Acc: 0.969\n",
      "epoch: 22/30 batch  62/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch  63/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch  64/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch  65/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 22/30 batch  66/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch  67/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 22/30 batch  68/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch  69/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch  70/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 22/30 batch  71/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 22/30 batch  72/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 22/30 batch  73/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch  74/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch  75/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch  76/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 22/30 batch  77/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 22/30 batch  78/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch  79/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 22/30 batch  80/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 22/30 batch  81/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 22/30 batch  82/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 22/30 batch  83/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 22/30 batch  84/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 22/30 batch  85/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 22/30 batch  86/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch  87/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch  88/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch  89/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 22/30 batch  90/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch  91/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch  92/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch  93/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch  94/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 22/30 batch  95/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 22/30 batch  96/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch  97/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch  98/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch  99/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 22/30 batch 100/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 101/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 22/30 batch 102/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 22/30 batch 103/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 22/30 batch 104/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 22/30 batch 105/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch 106/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 107/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch 108/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch 109/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 22/30 batch 110/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 22/30 batch 111/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 22/30 batch 112/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 113/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 22/30 batch 114/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 22/30 batch 115/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 116/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 22/30 batch 117/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 118/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 119/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch 120/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 121/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 122/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 22/30 batch 123/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 124/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 22/30 batch 125/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch 126/375  Train Loss: 0.034, Acc: 0.977\n",
      "epoch: 22/30 batch 127/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 128/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 22/30 batch 129/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 22/30 batch 130/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 22/30 batch 131/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 22/30 batch 132/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 133/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 22/30 batch 134/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 135/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch 136/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 22/30 batch 137/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch 138/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 22/30 batch 139/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 140/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 22/30 batch 141/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 142/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 22/30 batch 143/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 144/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 22/30 batch 145/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 146/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 147/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 22/30 batch 148/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 149/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 22/30 batch 150/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 22/30 batch 151/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch 152/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch 153/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 154/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 155/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 22/30 batch 156/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 22/30 batch 157/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 22/30 batch 158/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 159/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 22/30 batch 160/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 161/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch 162/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 22/30 batch 163/375  Train Loss: 0.117, Acc: 0.961\n",
      "epoch: 22/30 batch 164/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 22/30 batch 165/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 22/30 batch 166/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 22/30 batch 167/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 22/30 batch 168/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 169/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 170/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 22/30 batch 171/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch 172/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 173/375  Train Loss: 0.059, Acc: 0.977\n",
      "epoch: 22/30 batch 174/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 22/30 batch 175/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 176/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 22/30 batch 177/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch 178/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 179/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 180/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch 181/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch 182/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 22/30 batch 183/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 184/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 185/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 186/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 22/30 batch 187/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 22/30 batch 188/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 22/30 batch 189/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 190/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 191/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 22/30 batch 192/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 193/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 194/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 22/30 batch 195/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 196/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch 197/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 198/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 199/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 200/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 201/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 202/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch 203/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 22/30 batch 204/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 205/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch 206/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 22/30 batch 207/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 22/30 batch 208/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 209/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 22/30 batch 210/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 22/30 batch 211/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 212/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 213/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 214/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 215/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 216/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 217/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 218/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 219/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch 220/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 221/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 222/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 223/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 224/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch 225/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 22/30 batch 226/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 22/30 batch 227/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 228/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 229/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 230/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 231/375  Train Loss: 0.119, Acc: 0.977\n",
      "epoch: 22/30 batch 232/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 233/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 22/30 batch 234/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch 235/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 236/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 237/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 238/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 239/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 22/30 batch 240/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 22/30 batch 241/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 22/30 batch 242/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch 243/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 22/30 batch 244/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 22/30 batch 245/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 22/30 batch 246/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 22/30 batch 247/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 248/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 22/30 batch 249/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 22/30 batch 250/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 251/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch 252/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 253/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 22/30 batch 254/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 22/30 batch 255/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 256/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 257/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 22/30 batch 258/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 22/30 batch 259/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 260/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch 261/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 22/30 batch 262/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 263/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 264/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 22/30 batch 265/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch 266/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch 267/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 268/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 269/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 22/30 batch 270/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 22/30 batch 271/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 22/30 batch 272/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 22/30 batch 273/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 22/30 batch 274/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 275/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 276/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 22/30 batch 277/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 278/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 279/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch 280/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 281/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 22/30 batch 282/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch 283/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 22/30 batch 284/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 285/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 22/30 batch 286/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 287/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 288/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 289/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 22/30 batch 290/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 22/30 batch 291/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 22/30 batch 292/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 22/30 batch 293/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 22/30 batch 294/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 22/30 batch 295/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch 296/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 22/30 batch 297/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 22/30 batch 298/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 299/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch 300/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 301/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 22/30 batch 302/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 303/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 22/30 batch 304/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 305/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 306/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 22/30 batch 307/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 308/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch 309/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 310/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 22/30 batch 311/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 312/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 22/30 batch 313/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 22/30 batch 314/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 22/30 batch 315/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 316/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 317/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch 318/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 22/30 batch 319/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 22/30 batch 320/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 321/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 22/30 batch 322/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 323/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 22/30 batch 324/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 325/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 22/30 batch 326/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 22/30 batch 327/375  Train Loss: 0.060, Acc: 0.977\n",
      "epoch: 22/30 batch 328/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 22/30 batch 329/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 22/30 batch 330/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch 331/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch 332/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch 333/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 22/30 batch 334/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 22/30 batch 335/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 22/30 batch 336/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 337/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 338/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 339/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 22/30 batch 340/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 22/30 batch 341/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 22/30 batch 342/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 22/30 batch 343/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 22/30 batch 344/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch 345/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 22/30 batch 346/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 347/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 22/30 batch 348/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 349/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 22/30 batch 350/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch 351/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 22/30 batch 352/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 22/30 batch 353/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 354/375  Train Loss: 0.032, Acc: 0.977\n",
      "epoch: 22/30 batch 355/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 22/30 batch 356/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 22/30 batch 357/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 22/30 batch 358/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 22/30 batch 359/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch 360/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 22/30 batch 361/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 22/30 batch 362/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 22/30 batch 363/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 22/30 batch 364/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 22/30 batch 365/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 366/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 22/30 batch 367/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 22/30 batch 368/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 22/30 batch 369/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 22/30 batch 370/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 22/30 batch 371/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 22/30 batch 372/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 22/30 batch 373/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 22/30 batch 374/375  Train Loss: 0.009, Acc: 1.000\n",
      "Train Loss: 0.017445, Acc: 0.995\n",
      "Val Loss: 0.029555, Acc: 0.990\n",
      "epoch: 23/30 batch   0/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 23/30 batch   1/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 23/30 batch   2/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch   3/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 23/30 batch   4/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch   5/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 23/30 batch   6/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 23/30 batch   7/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch   8/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch   9/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch  10/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 23/30 batch  11/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 23/30 batch  12/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 23/30 batch  13/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 23/30 batch  14/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 23/30 batch  15/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 23/30 batch  16/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 23/30 batch  17/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch  18/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch  19/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch  20/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch  21/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch  22/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 23/30 batch  23/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 23/30 batch  24/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 23/30 batch  25/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 23/30 batch  26/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 23/30 batch  27/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 23/30 batch  28/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 23/30 batch  29/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch  30/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 23/30 batch  31/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch  32/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 23/30 batch  33/375  Train Loss: 0.074, Acc: 0.977\n",
      "epoch: 23/30 batch  34/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 23/30 batch  35/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch  36/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 23/30 batch  37/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch  38/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch  39/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 23/30 batch  40/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch  41/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 23/30 batch  42/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch  43/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch  44/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch  45/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 23/30 batch  46/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch  47/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch  48/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 23/30 batch  49/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch  50/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 23/30 batch  51/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch  52/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch  53/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch  54/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 23/30 batch  55/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch  56/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 23/30 batch  57/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch  58/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch  59/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch  60/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 23/30 batch  61/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 23/30 batch  62/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 23/30 batch  63/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 23/30 batch  64/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch  65/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch  66/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 23/30 batch  67/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch  68/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 23/30 batch  69/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch  70/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 23/30 batch  71/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 23/30 batch  72/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 23/30 batch  73/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 23/30 batch  74/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch  75/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch  76/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch  77/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 23/30 batch  78/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch  79/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch  80/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch  81/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 23/30 batch  82/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch  83/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 23/30 batch  84/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 23/30 batch  85/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch  86/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch  87/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 23/30 batch  88/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch  89/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch  90/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch  91/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 23/30 batch  92/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 23/30 batch  93/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch  94/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 23/30 batch  95/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 23/30 batch  96/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 23/30 batch  97/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch  98/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch  99/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 100/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 101/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 23/30 batch 102/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 23/30 batch 103/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 104/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 23/30 batch 105/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 23/30 batch 106/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch 107/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 108/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 23/30 batch 109/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 23/30 batch 110/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 111/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 23/30 batch 112/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 113/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 114/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 23/30 batch 115/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 23/30 batch 116/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 117/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 118/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 119/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 120/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 23/30 batch 121/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 23/30 batch 122/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 123/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 124/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 125/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 126/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 127/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 23/30 batch 128/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 23/30 batch 129/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 23/30 batch 130/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 131/375  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 23/30 batch 132/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 133/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 23/30 batch 134/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 135/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 136/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 137/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 23/30 batch 138/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 23/30 batch 139/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 23/30 batch 140/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 141/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 23/30 batch 142/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 143/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 23/30 batch 144/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 23/30 batch 145/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 146/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch 147/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 23/30 batch 148/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 23/30 batch 149/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 150/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch 151/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 23/30 batch 152/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 23/30 batch 153/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 154/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 155/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 23/30 batch 156/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 23/30 batch 157/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 23/30 batch 158/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 23/30 batch 159/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 23/30 batch 160/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 161/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 23/30 batch 162/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 23/30 batch 163/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch 164/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 23/30 batch 165/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 166/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 167/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 23/30 batch 168/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 23/30 batch 169/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 23/30 batch 170/375  Train Loss: 0.056, Acc: 0.969\n",
      "epoch: 23/30 batch 171/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 23/30 batch 172/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 23/30 batch 173/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 23/30 batch 174/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 175/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 23/30 batch 176/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 177/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 23/30 batch 178/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 179/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 180/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 181/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 23/30 batch 182/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 23/30 batch 183/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 184/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 23/30 batch 185/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 186/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 23/30 batch 187/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 23/30 batch 188/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 23/30 batch 189/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 190/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 191/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch 192/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 193/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 194/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 195/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 196/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 197/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 198/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 199/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 200/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 23/30 batch 201/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 202/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 23/30 batch 203/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 204/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 23/30 batch 205/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 206/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch 207/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 23/30 batch 208/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 23/30 batch 209/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 210/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 211/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 23/30 batch 212/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 23/30 batch 213/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 214/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 215/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 23/30 batch 216/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 23/30 batch 217/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 23/30 batch 218/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 219/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 220/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 23/30 batch 221/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 23/30 batch 222/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 23/30 batch 223/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 224/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 225/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 226/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 227/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 228/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 229/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 23/30 batch 230/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 23/30 batch 231/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 23/30 batch 232/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 23/30 batch 233/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 23/30 batch 234/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 235/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 236/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch 237/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 23/30 batch 238/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 239/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 23/30 batch 240/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 241/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 242/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 243/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 23/30 batch 244/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 23/30 batch 245/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 23/30 batch 246/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 247/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 248/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 23/30 batch 249/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch 250/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 23/30 batch 251/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 23/30 batch 252/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 23/30 batch 253/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 23/30 batch 254/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 255/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 23/30 batch 256/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 257/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 258/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 23/30 batch 259/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 260/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 23/30 batch 261/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 262/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 23/30 batch 263/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 23/30 batch 264/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 23/30 batch 265/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 23/30 batch 266/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 23/30 batch 267/375  Train Loss: 0.050, Acc: 0.984\n",
      "epoch: 23/30 batch 268/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 23/30 batch 269/375  Train Loss: 0.120, Acc: 0.984\n",
      "epoch: 23/30 batch 270/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 271/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 272/375  Train Loss: 0.102, Acc: 0.977\n",
      "epoch: 23/30 batch 273/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 23/30 batch 274/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 23/30 batch 275/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 23/30 batch 276/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 23/30 batch 277/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 23/30 batch 278/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch 279/375  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 23/30 batch 280/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 23/30 batch 281/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 23/30 batch 282/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 23/30 batch 283/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 23/30 batch 284/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 23/30 batch 285/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 286/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 287/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 288/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 23/30 batch 289/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 290/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 23/30 batch 291/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch 292/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 23/30 batch 293/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 294/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 295/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 296/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 297/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 23/30 batch 298/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 299/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 23/30 batch 300/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 301/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 23/30 batch 302/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 303/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 23/30 batch 304/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 23/30 batch 305/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 306/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 307/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch 308/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 23/30 batch 309/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 23/30 batch 310/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 311/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 23/30 batch 312/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch 313/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 23/30 batch 314/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 315/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 23/30 batch 316/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 317/375  Train Loss: 0.064, Acc: 0.977\n",
      "epoch: 23/30 batch 318/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 23/30 batch 319/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 23/30 batch 320/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 321/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 23/30 batch 322/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 23/30 batch 323/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 324/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 325/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 23/30 batch 326/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 23/30 batch 327/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 328/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 23/30 batch 329/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 23/30 batch 330/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 23/30 batch 331/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 332/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 23/30 batch 333/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 334/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 335/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 23/30 batch 336/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 23/30 batch 337/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 23/30 batch 338/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 23/30 batch 339/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 23/30 batch 340/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 23/30 batch 341/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 23/30 batch 342/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 23/30 batch 343/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 344/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 345/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 23/30 batch 346/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 23/30 batch 347/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 23/30 batch 348/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 23/30 batch 349/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 23/30 batch 350/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 351/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 23/30 batch 352/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 23/30 batch 353/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 23/30 batch 354/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 23/30 batch 355/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 356/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 357/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 23/30 batch 358/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 359/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 23/30 batch 360/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 23/30 batch 361/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 23/30 batch 362/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 23/30 batch 363/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 23/30 batch 364/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 365/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 23/30 batch 366/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 367/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 23/30 batch 368/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 23/30 batch 369/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 23/30 batch 370/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 23/30 batch 371/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 23/30 batch 372/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 23/30 batch 373/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 23/30 batch 374/375  Train Loss: 0.015, Acc: 1.000\n",
      "Train Loss: 0.017327, Acc: 0.995\n",
      "Val Loss: 0.028848, Acc: 0.990\n",
      "epoch: 24/30 batch   0/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch   1/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch   2/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 24/30 batch   3/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 24/30 batch   4/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 24/30 batch   5/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch   6/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 24/30 batch   7/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch   8/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch   9/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 24/30 batch  10/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 24/30 batch  11/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch  12/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 24/30 batch  13/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch  14/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 24/30 batch  15/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch  16/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch  17/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 24/30 batch  18/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 24/30 batch  19/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 24/30 batch  20/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch  21/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch  22/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 24/30 batch  23/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch  24/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 24/30 batch  25/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch  26/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch  27/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 24/30 batch  28/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 24/30 batch  29/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 24/30 batch  30/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 24/30 batch  31/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 24/30 batch  32/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 24/30 batch  33/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 24/30 batch  34/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 24/30 batch  35/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch  36/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 24/30 batch  37/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 24/30 batch  38/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 24/30 batch  39/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch  40/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch  41/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 24/30 batch  42/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 24/30 batch  43/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 24/30 batch  44/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 24/30 batch  45/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 24/30 batch  46/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 24/30 batch  47/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch  48/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch  49/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 24/30 batch  50/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch  51/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 24/30 batch  52/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 24/30 batch  53/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 24/30 batch  54/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 24/30 batch  55/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch  56/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch  57/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch  58/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 24/30 batch  59/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch  60/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 24/30 batch  61/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch  62/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 24/30 batch  63/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 24/30 batch  64/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch  65/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 24/30 batch  66/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 24/30 batch  67/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 24/30 batch  68/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch  69/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 24/30 batch  70/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 24/30 batch  71/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 24/30 batch  72/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch  73/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 24/30 batch  74/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 24/30 batch  75/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch  76/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 24/30 batch  77/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch  78/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch  79/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch  80/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 24/30 batch  81/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 24/30 batch  82/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch  83/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch  84/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 24/30 batch  85/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 24/30 batch  86/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch  87/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch  88/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 24/30 batch  89/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 24/30 batch  90/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 24/30 batch  91/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 24/30 batch  92/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 24/30 batch  93/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch  94/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch  95/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 24/30 batch  96/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 24/30 batch  97/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch  98/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 24/30 batch  99/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 100/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 24/30 batch 101/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 24/30 batch 102/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 24/30 batch 103/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 24/30 batch 104/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 105/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 24/30 batch 106/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch 107/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 108/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 109/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 24/30 batch 110/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 111/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 112/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch 113/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 24/30 batch 114/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch 115/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 116/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 117/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 24/30 batch 118/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 24/30 batch 119/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 24/30 batch 120/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 24/30 batch 121/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 24/30 batch 122/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 24/30 batch 123/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 24/30 batch 124/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 24/30 batch 125/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 24/30 batch 126/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 24/30 batch 127/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 24/30 batch 128/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 129/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 24/30 batch 130/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 131/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 132/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch 133/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 24/30 batch 134/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 24/30 batch 135/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch 136/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch 137/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 24/30 batch 138/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 139/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 24/30 batch 140/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 141/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch 142/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch 143/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 24/30 batch 144/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 24/30 batch 145/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 146/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 147/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 24/30 batch 148/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch 149/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 24/30 batch 150/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 24/30 batch 151/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 152/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 24/30 batch 153/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 154/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 24/30 batch 155/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 24/30 batch 156/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 24/30 batch 157/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 158/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 24/30 batch 159/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 160/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 24/30 batch 161/375  Train Loss: 0.075, Acc: 0.992\n",
      "epoch: 24/30 batch 162/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 163/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 24/30 batch 164/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 24/30 batch 165/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch 166/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 167/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 168/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 24/30 batch 169/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 24/30 batch 170/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 24/30 batch 171/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 24/30 batch 172/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 24/30 batch 173/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 24/30 batch 174/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 24/30 batch 175/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 176/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 24/30 batch 177/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 24/30 batch 178/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 24/30 batch 179/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 180/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch 181/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 182/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 24/30 batch 183/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 24/30 batch 184/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 24/30 batch 185/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch 186/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 24/30 batch 187/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 188/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 189/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 24/30 batch 190/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 24/30 batch 191/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 192/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 24/30 batch 193/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 194/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 195/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 24/30 batch 196/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch 197/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 24/30 batch 198/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 24/30 batch 199/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 24/30 batch 200/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 24/30 batch 201/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 24/30 batch 202/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 203/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 24/30 batch 204/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 205/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch 206/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 207/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 24/30 batch 208/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 209/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 24/30 batch 210/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 211/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 212/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 24/30 batch 213/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 24/30 batch 214/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 24/30 batch 215/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 24/30 batch 216/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 24/30 batch 217/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 218/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 219/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 24/30 batch 220/375  Train Loss: 0.055, Acc: 0.961\n",
      "epoch: 24/30 batch 221/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 24/30 batch 222/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 24/30 batch 223/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 24/30 batch 224/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 24/30 batch 225/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 226/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 24/30 batch 227/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 228/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 229/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 24/30 batch 230/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 24/30 batch 231/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 24/30 batch 232/375  Train Loss: 0.053, Acc: 0.992\n",
      "epoch: 24/30 batch 233/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 24/30 batch 234/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 24/30 batch 235/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 236/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 24/30 batch 237/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 238/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 239/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 24/30 batch 240/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 24/30 batch 241/375  Train Loss: 0.036, Acc: 0.977\n",
      "epoch: 24/30 batch 242/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 243/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 24/30 batch 244/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch 245/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 24/30 batch 246/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 247/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 24/30 batch 248/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 24/30 batch 249/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 250/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 24/30 batch 251/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 24/30 batch 252/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 24/30 batch 253/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 254/375  Train Loss: 0.024, Acc: 1.000\n",
      "epoch: 24/30 batch 255/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch 256/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch 257/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 24/30 batch 258/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 24/30 batch 259/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 24/30 batch 260/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 24/30 batch 261/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 24/30 batch 262/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 263/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 264/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch 265/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 266/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 24/30 batch 267/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 268/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 269/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 24/30 batch 270/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 24/30 batch 271/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 272/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 273/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 24/30 batch 274/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 24/30 batch 275/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 24/30 batch 276/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 24/30 batch 277/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 24/30 batch 278/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 24/30 batch 279/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 24/30 batch 280/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 281/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 282/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 24/30 batch 283/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch 284/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 24/30 batch 285/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 24/30 batch 286/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 24/30 batch 287/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 24/30 batch 288/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch 289/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 290/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 24/30 batch 291/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 24/30 batch 292/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 293/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 294/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 295/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch 296/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 297/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch 298/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 299/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 24/30 batch 300/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 24/30 batch 301/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 24/30 batch 302/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 24/30 batch 303/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 304/375  Train Loss: 0.016, Acc: 0.984\n",
      "epoch: 24/30 batch 305/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 24/30 batch 306/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 24/30 batch 307/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch 308/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 309/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 24/30 batch 310/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 24/30 batch 311/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 312/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 24/30 batch 313/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 24/30 batch 314/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 24/30 batch 315/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch 316/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 24/30 batch 317/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 24/30 batch 318/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 24/30 batch 319/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 24/30 batch 320/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch 321/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch 322/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch 323/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 24/30 batch 324/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch 325/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch 326/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 24/30 batch 327/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 24/30 batch 328/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 24/30 batch 329/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch 330/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 331/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 332/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 333/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 24/30 batch 334/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 24/30 batch 335/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 24/30 batch 336/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 24/30 batch 337/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 24/30 batch 338/375  Train Loss: 0.118, Acc: 0.984\n",
      "epoch: 24/30 batch 339/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 340/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 24/30 batch 341/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 24/30 batch 342/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 24/30 batch 343/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 344/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 345/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 24/30 batch 346/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 24/30 batch 347/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 348/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 24/30 batch 349/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch 350/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 24/30 batch 351/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 352/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 24/30 batch 353/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 354/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 24/30 batch 355/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 24/30 batch 356/375  Train Loss: 0.040, Acc: 0.977\n",
      "epoch: 24/30 batch 357/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 358/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 24/30 batch 359/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 24/30 batch 360/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 361/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 24/30 batch 362/375  Train Loss: 0.079, Acc: 0.977\n",
      "epoch: 24/30 batch 363/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 24/30 batch 364/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 365/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 24/30 batch 366/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 24/30 batch 367/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 24/30 batch 368/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 24/30 batch 369/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 370/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 24/30 batch 371/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 24/30 batch 372/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 24/30 batch 373/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 24/30 batch 374/375  Train Loss: 0.022, Acc: 0.992\n",
      "Train Loss: 0.017223, Acc: 0.995\n",
      "Val Loss: 0.028442, Acc: 0.990\n",
      "epoch: 25/30 batch   0/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 25/30 batch   1/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 25/30 batch   2/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch   3/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch   4/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 25/30 batch   5/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 25/30 batch   6/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 25/30 batch   7/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch   8/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch   9/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch  10/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch  11/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch  12/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 25/30 batch  13/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 25/30 batch  14/375  Train Loss: 0.008, Acc: 0.992\n",
      "epoch: 25/30 batch  15/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 25/30 batch  16/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch  17/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 25/30 batch  18/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch  19/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch  20/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 25/30 batch  21/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch  22/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch  23/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch  24/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 25/30 batch  25/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 25/30 batch  26/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch  27/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch  28/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch  29/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch  30/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch  31/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 25/30 batch  32/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 25/30 batch  33/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 25/30 batch  34/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 25/30 batch  35/375  Train Loss: 0.038, Acc: 0.977\n",
      "epoch: 25/30 batch  36/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch  37/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 25/30 batch  38/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 25/30 batch  39/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 25/30 batch  40/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch  41/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch  42/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch  43/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 25/30 batch  44/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch  45/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch  46/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 25/30 batch  47/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 25/30 batch  48/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch  49/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch  50/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 25/30 batch  51/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 25/30 batch  52/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 25/30 batch  53/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 25/30 batch  54/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch  55/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch  56/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch  57/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 25/30 batch  58/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch  59/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 25/30 batch  60/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch  61/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch  62/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 25/30 batch  63/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch  64/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 25/30 batch  65/375  Train Loss: 0.046, Acc: 0.984\n",
      "epoch: 25/30 batch  66/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 25/30 batch  67/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 25/30 batch  68/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 25/30 batch  69/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch  70/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 25/30 batch  71/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch  72/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 25/30 batch  73/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 25/30 batch  74/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 25/30 batch  75/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch  76/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 25/30 batch  77/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch  78/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch  79/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 25/30 batch  80/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch  81/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch  82/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch  83/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 25/30 batch  84/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 25/30 batch  85/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch  86/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 25/30 batch  87/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 25/30 batch  88/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch  89/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch  90/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch  91/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 25/30 batch  92/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch  93/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch  94/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 25/30 batch  95/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch  96/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch  97/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 25/30 batch  98/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch  99/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 25/30 batch 100/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 25/30 batch 101/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 25/30 batch 102/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 25/30 batch 103/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 104/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 105/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 25/30 batch 106/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 25/30 batch 107/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch 108/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 25/30 batch 109/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 110/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 111/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 112/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 25/30 batch 113/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 25/30 batch 114/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 115/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 116/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 25/30 batch 117/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch 118/375  Train Loss: 0.037, Acc: 0.977\n",
      "epoch: 25/30 batch 119/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 120/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch 121/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 25/30 batch 122/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 25/30 batch 123/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 124/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 25/30 batch 125/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 126/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 25/30 batch 127/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 128/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch 129/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 25/30 batch 130/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 25/30 batch 131/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 25/30 batch 132/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 25/30 batch 133/375  Train Loss: 0.026, Acc: 0.977\n",
      "epoch: 25/30 batch 134/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 25/30 batch 135/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 136/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 25/30 batch 137/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 138/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 25/30 batch 139/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 140/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 141/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 142/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 143/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch 144/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 145/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 25/30 batch 146/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 25/30 batch 147/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 25/30 batch 148/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 25/30 batch 149/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 25/30 batch 150/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 25/30 batch 151/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch 152/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 25/30 batch 153/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 25/30 batch 154/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 155/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 156/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 25/30 batch 157/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 25/30 batch 158/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 159/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 160/375  Train Loss: 0.043, Acc: 0.977\n",
      "epoch: 25/30 batch 161/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch 162/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 25/30 batch 163/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 25/30 batch 164/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 25/30 batch 165/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 25/30 batch 166/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 167/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 25/30 batch 168/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 169/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 25/30 batch 170/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 171/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 172/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 25/30 batch 173/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 25/30 batch 174/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 25/30 batch 175/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 176/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 25/30 batch 177/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 25/30 batch 178/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 25/30 batch 179/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch 180/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 25/30 batch 181/375  Train Loss: 0.057, Acc: 0.977\n",
      "epoch: 25/30 batch 182/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 183/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 25/30 batch 184/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 25/30 batch 185/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 25/30 batch 186/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 25/30 batch 187/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 188/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 25/30 batch 189/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 25/30 batch 190/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 25/30 batch 191/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 192/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch 193/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 194/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 195/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 196/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 25/30 batch 197/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 198/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 25/30 batch 199/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 200/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 25/30 batch 201/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 25/30 batch 202/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 25/30 batch 203/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 25/30 batch 204/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 25/30 batch 205/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 25/30 batch 206/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 25/30 batch 207/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 208/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 209/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 25/30 batch 210/375  Train Loss: 0.029, Acc: 0.977\n",
      "epoch: 25/30 batch 211/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch 212/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 25/30 batch 213/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 25/30 batch 214/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch: 25/30 batch 215/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 216/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 217/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 218/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch 219/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 220/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 25/30 batch 221/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 222/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 25/30 batch 223/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 224/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 25/30 batch 225/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 25/30 batch 226/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 25/30 batch 227/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 25/30 batch 228/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 25/30 batch 229/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 25/30 batch 230/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 231/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 232/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 25/30 batch 233/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 25/30 batch 234/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch 235/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 25/30 batch 236/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 25/30 batch 237/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 238/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 25/30 batch 239/375  Train Loss: 0.105, Acc: 0.992\n",
      "epoch: 25/30 batch 240/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 241/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 242/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 243/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 244/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 25/30 batch 245/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 25/30 batch 246/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch 247/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch 248/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch 249/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 250/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 25/30 batch 251/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 25/30 batch 252/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch 253/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 25/30 batch 254/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 255/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 256/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 25/30 batch 257/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 25/30 batch 258/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 25/30 batch 259/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 25/30 batch 260/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 25/30 batch 261/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch 262/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 263/375  Train Loss: 0.085, Acc: 0.992\n",
      "epoch: 25/30 batch 264/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 265/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 266/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 25/30 batch 267/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 268/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 269/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 270/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 25/30 batch 271/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 272/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch 273/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 274/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 25/30 batch 275/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 276/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 25/30 batch 277/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 25/30 batch 278/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 279/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 25/30 batch 280/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 25/30 batch 281/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 25/30 batch 282/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 283/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 284/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 25/30 batch 285/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 25/30 batch 286/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 287/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 25/30 batch 288/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 289/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 25/30 batch 290/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 291/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 25/30 batch 292/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 25/30 batch 293/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 25/30 batch 294/375  Train Loss: 0.008, Acc: 0.992\n",
      "epoch: 25/30 batch 295/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 296/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 297/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 25/30 batch 298/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 299/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 25/30 batch 300/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 301/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 25/30 batch 302/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 25/30 batch 303/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 25/30 batch 304/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 305/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 306/375  Train Loss: 0.066, Acc: 0.992\n",
      "epoch: 25/30 batch 307/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch 308/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 309/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 310/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 25/30 batch 311/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 25/30 batch 312/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 25/30 batch 313/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch 314/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 25/30 batch 315/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 316/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 25/30 batch 317/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 25/30 batch 318/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 25/30 batch 319/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 320/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 25/30 batch 321/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 25/30 batch 322/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 25/30 batch 323/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 25/30 batch 324/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 325/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 326/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 327/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 25/30 batch 328/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 25/30 batch 329/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 330/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 25/30 batch 331/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 25/30 batch 332/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 333/375  Train Loss: 0.062, Acc: 0.992\n",
      "epoch: 25/30 batch 334/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 25/30 batch 335/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 25/30 batch 336/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 25/30 batch 337/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 25/30 batch 338/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 25/30 batch 339/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 25/30 batch 340/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 341/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 25/30 batch 342/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 343/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 25/30 batch 344/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 25/30 batch 345/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 25/30 batch 346/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 25/30 batch 347/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 25/30 batch 348/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 25/30 batch 349/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch 350/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 25/30 batch 351/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 25/30 batch 352/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 25/30 batch 353/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 25/30 batch 354/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 25/30 batch 355/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 25/30 batch 356/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 25/30 batch 357/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 358/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 25/30 batch 359/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 25/30 batch 360/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 25/30 batch 361/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 25/30 batch 362/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 25/30 batch 363/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 25/30 batch 364/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 25/30 batch 365/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch 366/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 25/30 batch 367/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 25/30 batch 368/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 369/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 25/30 batch 370/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 25/30 batch 371/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 25/30 batch 372/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 25/30 batch 373/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 25/30 batch 374/375  Train Loss: 0.008, Acc: 1.000\n",
      "Train Loss: 0.017107, Acc: 0.995\n",
      "Val Loss: 0.028832, Acc: 0.990\n",
      "epoch: 26/30 batch   0/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch   1/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 26/30 batch   2/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 26/30 batch   3/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch   4/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch   5/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch   6/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 26/30 batch   7/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch   8/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 26/30 batch   9/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch  10/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch  11/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch  12/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 26/30 batch  13/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 26/30 batch  14/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 26/30 batch  15/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch  16/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch  17/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch  18/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch  19/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch  20/375  Train Loss: 0.130, Acc: 0.977\n",
      "epoch: 26/30 batch  21/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch  22/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 26/30 batch  23/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch  24/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 26/30 batch  25/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 26/30 batch  26/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 26/30 batch  27/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 26/30 batch  28/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch  29/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch  30/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch  31/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch  32/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch  33/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch  34/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch  35/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch  36/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch  37/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch  38/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 26/30 batch  39/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 26/30 batch  40/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch  41/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 26/30 batch  42/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 26/30 batch  43/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch  44/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 26/30 batch  45/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 26/30 batch  46/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch  47/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch  48/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 26/30 batch  49/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 26/30 batch  50/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch  51/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 26/30 batch  52/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 26/30 batch  53/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 26/30 batch  54/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch  55/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch  56/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 26/30 batch  57/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 26/30 batch  58/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 26/30 batch  59/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch  60/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 26/30 batch  61/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch  62/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch  63/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch  64/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch  65/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch  66/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch  67/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch  68/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch  69/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 26/30 batch  70/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 26/30 batch  71/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch  72/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch  73/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch  74/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 26/30 batch  75/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch  76/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 26/30 batch  77/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch  78/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch  79/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 26/30 batch  80/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch  81/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 26/30 batch  82/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch  83/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch  84/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch  85/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 26/30 batch  86/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch  87/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch  88/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch  89/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 26/30 batch  90/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 26/30 batch  91/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 26/30 batch  92/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 26/30 batch  93/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 26/30 batch  94/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 26/30 batch  95/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch  96/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch  97/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch  98/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch  99/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 100/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 101/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 102/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 26/30 batch 103/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 26/30 batch 104/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 105/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 106/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 26/30 batch 107/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 108/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 109/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 110/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 26/30 batch 111/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 26/30 batch 112/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 113/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 26/30 batch 114/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 115/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 26/30 batch 116/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch 117/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 118/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 26/30 batch 119/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 120/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 121/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 26/30 batch 122/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 123/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 26/30 batch 124/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 125/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 26/30 batch 126/375  Train Loss: 0.048, Acc: 0.984\n",
      "epoch: 26/30 batch 127/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 128/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 129/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 26/30 batch 130/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 26/30 batch 131/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 26/30 batch 132/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 133/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 134/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 135/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 136/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch 137/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 26/30 batch 138/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 139/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 26/30 batch 140/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 26/30 batch 141/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 26/30 batch 142/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 26/30 batch 143/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch 144/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 26/30 batch 145/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 146/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 26/30 batch 147/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 148/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 149/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 150/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 26/30 batch 151/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 152/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 26/30 batch 153/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 154/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 26/30 batch 155/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 156/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 26/30 batch 157/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 26/30 batch 158/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 159/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 26/30 batch 160/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 161/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 26/30 batch 162/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 26/30 batch 163/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 164/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 165/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 26/30 batch 166/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 26/30 batch 167/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 168/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 26/30 batch 169/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 26/30 batch 170/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 171/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 172/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 26/30 batch 173/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 174/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch 175/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 26/30 batch 176/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 177/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 178/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 26/30 batch 179/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 180/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 26/30 batch 181/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch 182/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 26/30 batch 183/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 26/30 batch 184/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 26/30 batch 185/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 26/30 batch 186/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 187/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 26/30 batch 188/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 189/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 26/30 batch 190/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 26/30 batch 191/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 26/30 batch 192/375  Train Loss: 0.016, Acc: 0.984\n",
      "epoch: 26/30 batch 193/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 26/30 batch 194/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 26/30 batch 195/375  Train Loss: 0.041, Acc: 0.969\n",
      "epoch: 26/30 batch 196/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 26/30 batch 197/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 26/30 batch 198/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch 199/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 26/30 batch 200/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 26/30 batch 201/375  Train Loss: 0.031, Acc: 0.977\n",
      "epoch: 26/30 batch 202/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 26/30 batch 203/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 204/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 26/30 batch 205/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 206/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 207/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 26/30 batch 208/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 26/30 batch 209/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 26/30 batch 210/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 26/30 batch 211/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 26/30 batch 212/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 26/30 batch 213/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 214/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 215/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 26/30 batch 216/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 217/375  Train Loss: 0.046, Acc: 0.977\n",
      "epoch: 26/30 batch 218/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch 219/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 26/30 batch 220/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 221/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 26/30 batch 222/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 223/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 224/375  Train Loss: 0.061, Acc: 0.984\n",
      "epoch: 26/30 batch 225/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 26/30 batch 226/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 227/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 26/30 batch 228/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 26/30 batch 229/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 230/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 231/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 26/30 batch 232/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 26/30 batch 233/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 26/30 batch 234/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 26/30 batch 235/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 26/30 batch 236/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 26/30 batch 237/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 26/30 batch 238/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 26/30 batch 239/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 26/30 batch 240/375  Train Loss: 0.097, Acc: 0.992\n",
      "epoch: 26/30 batch 241/375  Train Loss: 0.044, Acc: 0.977\n",
      "epoch: 26/30 batch 242/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 26/30 batch 243/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 26/30 batch 244/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 245/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 246/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 26/30 batch 247/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 26/30 batch 248/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 249/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 250/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 26/30 batch 251/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 252/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 253/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 254/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 26/30 batch 255/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 26/30 batch 256/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 257/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 26/30 batch 258/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 26/30 batch 259/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 26/30 batch 260/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 26/30 batch 261/375  Train Loss: 0.080, Acc: 0.977\n",
      "epoch: 26/30 batch 262/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 263/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 264/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 26/30 batch 265/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 266/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 26/30 batch 267/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 268/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 26/30 batch 269/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 270/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 26/30 batch 271/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 272/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 26/30 batch 273/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 26/30 batch 274/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 26/30 batch 275/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 26/30 batch 276/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 26/30 batch 277/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 26/30 batch 278/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 26/30 batch 279/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 26/30 batch 280/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch 281/375  Train Loss: 0.074, Acc: 0.984\n",
      "epoch: 26/30 batch 282/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 283/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 26/30 batch 284/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 26/30 batch 285/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 286/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 26/30 batch 287/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 288/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 289/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 290/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 291/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 26/30 batch 292/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 26/30 batch 293/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 26/30 batch 294/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 295/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 26/30 batch 296/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 26/30 batch 297/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch 298/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 26/30 batch 299/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 26/30 batch 300/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 26/30 batch 301/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 302/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 26/30 batch 303/375  Train Loss: 0.018, Acc: 0.984\n",
      "epoch: 26/30 batch 304/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 305/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 26/30 batch 306/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 26/30 batch 307/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 308/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 26/30 batch 309/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 310/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 26/30 batch 311/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 26/30 batch 312/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 313/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 26/30 batch 314/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 26/30 batch 315/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 26/30 batch 316/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 317/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 26/30 batch 318/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 26/30 batch 319/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 26/30 batch 320/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 321/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 26/30 batch 322/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 26/30 batch 323/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch 324/375  Train Loss: 0.055, Acc: 0.977\n",
      "epoch: 26/30 batch 325/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 326/375  Train Loss: 0.082, Acc: 0.984\n",
      "epoch: 26/30 batch 327/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 328/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 329/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 26/30 batch 330/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 26/30 batch 331/375  Train Loss: 0.093, Acc: 0.977\n",
      "epoch: 26/30 batch 332/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 26/30 batch 333/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 334/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch 335/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 26/30 batch 336/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 26/30 batch 337/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 26/30 batch 338/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 26/30 batch 339/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 26/30 batch 340/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 26/30 batch 341/375  Train Loss: 0.042, Acc: 0.992\n",
      "epoch: 26/30 batch 342/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 26/30 batch 343/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 26/30 batch 344/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 26/30 batch 345/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 26/30 batch 346/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 26/30 batch 347/375  Train Loss: 0.072, Acc: 0.977\n",
      "epoch: 26/30 batch 348/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 26/30 batch 349/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 26/30 batch 350/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 26/30 batch 351/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 26/30 batch 352/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 353/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 26/30 batch 354/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 26/30 batch 355/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 356/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 26/30 batch 357/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 26/30 batch 358/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 359/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 26/30 batch 360/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 361/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 26/30 batch 362/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 26/30 batch 363/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 26/30 batch 364/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 26/30 batch 365/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 26/30 batch 366/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 26/30 batch 367/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 26/30 batch 368/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 26/30 batch 369/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 26/30 batch 370/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 26/30 batch 371/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 26/30 batch 372/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 26/30 batch 373/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 26/30 batch 374/375  Train Loss: 0.029, Acc: 0.984\n",
      "Train Loss: 0.017111, Acc: 0.995\n",
      "Val Loss: 0.029036, Acc: 0.990\n",
      "epoch: 27/30 batch   0/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 27/30 batch   1/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch   2/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 27/30 batch   3/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 27/30 batch   4/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 27/30 batch   5/375  Train Loss: 0.105, Acc: 0.984\n",
      "epoch: 27/30 batch   6/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 27/30 batch   7/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch   8/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch   9/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch  10/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 27/30 batch  11/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 27/30 batch  12/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch  13/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 27/30 batch  14/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 27/30 batch  15/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 27/30 batch  16/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 27/30 batch  17/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch  18/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch  19/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch  20/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 27/30 batch  21/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch  22/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 27/30 batch  23/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 27/30 batch  24/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch  25/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 27/30 batch  26/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 27/30 batch  27/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch  28/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 27/30 batch  29/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch  30/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch  31/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 27/30 batch  32/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 27/30 batch  33/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 27/30 batch  34/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 27/30 batch  35/375  Train Loss: 0.073, Acc: 0.984\n",
      "epoch: 27/30 batch  36/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 27/30 batch  37/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch  38/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 27/30 batch  39/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 27/30 batch  40/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 27/30 batch  41/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 27/30 batch  42/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch  43/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch  44/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 27/30 batch  45/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch  46/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 27/30 batch  47/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch  48/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 27/30 batch  49/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch  50/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch  51/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 27/30 batch  52/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 27/30 batch  53/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 27/30 batch  54/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch  55/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 27/30 batch  56/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 27/30 batch  57/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch  58/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch  59/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 27/30 batch  60/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch  61/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 27/30 batch  62/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch  63/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 27/30 batch  64/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 27/30 batch  65/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch  66/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch  67/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch  68/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch  69/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch  70/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch  71/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch  72/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch  73/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch  74/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 27/30 batch  75/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 27/30 batch  76/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 27/30 batch  77/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 27/30 batch  78/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 27/30 batch  79/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 27/30 batch  80/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 27/30 batch  81/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch  82/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch  83/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch  84/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch  85/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 27/30 batch  86/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch  87/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 27/30 batch  88/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 27/30 batch  89/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch  90/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch  91/375  Train Loss: 0.028, Acc: 0.977\n",
      "epoch: 27/30 batch  92/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch  93/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 27/30 batch  94/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch  95/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 27/30 batch  96/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 27/30 batch  97/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch  98/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch  99/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 100/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 27/30 batch 101/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 27/30 batch 102/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 27/30 batch 103/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 104/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 105/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 27/30 batch 106/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 27/30 batch 107/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 108/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch 109/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 27/30 batch 110/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 111/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 112/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 27/30 batch 113/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 27/30 batch 114/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 115/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 116/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch 117/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 118/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 27/30 batch 119/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 27/30 batch 120/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 121/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 27/30 batch 122/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 27/30 batch 123/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 27/30 batch 124/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 125/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 27/30 batch 126/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 27/30 batch 127/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 128/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 27/30 batch 129/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 27/30 batch 130/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 131/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 132/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 27/30 batch 133/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 134/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 27/30 batch 135/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 27/30 batch 136/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 27/30 batch 137/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 138/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 27/30 batch 139/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 27/30 batch 140/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 27/30 batch 141/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 27/30 batch 142/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 27/30 batch 143/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 144/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 27/30 batch 145/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 27/30 batch 146/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 147/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 148/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 149/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 27/30 batch 150/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 27/30 batch 151/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 27/30 batch 152/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 153/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 27/30 batch 154/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch 155/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 27/30 batch 156/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 157/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 27/30 batch 158/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 159/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 27/30 batch 160/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 161/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 162/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 27/30 batch 163/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 27/30 batch 164/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 165/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch 166/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 167/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 27/30 batch 168/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 27/30 batch 169/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 27/30 batch 170/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 27/30 batch 171/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 172/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 27/30 batch 173/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 27/30 batch 174/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 27/30 batch 175/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 176/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 27/30 batch 177/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 27/30 batch 178/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 179/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 27/30 batch 180/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 27/30 batch 181/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 182/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 27/30 batch 183/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 27/30 batch 184/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 185/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 27/30 batch 186/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch 187/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 188/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 27/30 batch 189/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 27/30 batch 190/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 27/30 batch 191/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 27/30 batch 192/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 27/30 batch 193/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 27/30 batch 194/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 27/30 batch 195/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 196/375  Train Loss: 0.039, Acc: 0.977\n",
      "epoch: 27/30 batch 197/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 27/30 batch 198/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 27/30 batch 199/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 27/30 batch 200/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 27/30 batch 201/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 27/30 batch 202/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 27/30 batch 203/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 27/30 batch 204/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 27/30 batch 205/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 27/30 batch 206/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 27/30 batch 207/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 27/30 batch 208/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 27/30 batch 209/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 210/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch 211/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 212/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 213/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 27/30 batch 214/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 27/30 batch 215/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 27/30 batch 216/375  Train Loss: 0.018, Acc: 0.984\n",
      "epoch: 27/30 batch 217/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 27/30 batch 218/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 27/30 batch 219/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 220/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 27/30 batch 221/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 27/30 batch 222/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 27/30 batch 223/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 224/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 27/30 batch 225/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 226/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 227/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 27/30 batch 228/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 27/30 batch 229/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 27/30 batch 230/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 27/30 batch 231/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 27/30 batch 232/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 27/30 batch 233/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 27/30 batch 234/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 235/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 236/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 237/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 27/30 batch 238/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 27/30 batch 239/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 27/30 batch 240/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 27/30 batch 241/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch 242/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 27/30 batch 243/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 27/30 batch 244/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 245/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 27/30 batch 246/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch 247/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch 248/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 27/30 batch 249/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 250/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 27/30 batch 251/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 27/30 batch 252/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 27/30 batch 253/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 254/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 255/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 256/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 257/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 27/30 batch 258/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 27/30 batch 259/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 27/30 batch 260/375  Train Loss: 0.063, Acc: 0.984\n",
      "epoch: 27/30 batch 261/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 27/30 batch 262/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch 263/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 264/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 27/30 batch 265/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 266/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 267/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 27/30 batch 268/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 269/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 27/30 batch 270/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch 271/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 27/30 batch 272/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch 273/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 274/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 27/30 batch 275/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 27/30 batch 276/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 27/30 batch 277/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 278/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 27/30 batch 279/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 27/30 batch 280/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 281/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 282/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 27/30 batch 283/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 27/30 batch 284/375  Train Loss: 0.029, Acc: 0.977\n",
      "epoch: 27/30 batch 285/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 286/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 287/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch 288/375  Train Loss: 0.051, Acc: 0.984\n",
      "epoch: 27/30 batch 289/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch 290/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 27/30 batch 291/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 292/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 27/30 batch 293/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 294/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 27/30 batch 295/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 27/30 batch 296/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 27/30 batch 297/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 27/30 batch 298/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 299/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 27/30 batch 300/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 301/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 302/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 27/30 batch 303/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 27/30 batch 304/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 305/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 27/30 batch 306/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 27/30 batch 307/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 27/30 batch 308/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 309/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 27/30 batch 310/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 27/30 batch 311/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 27/30 batch 312/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 27/30 batch 313/375  Train Loss: 0.033, Acc: 0.977\n",
      "epoch: 27/30 batch 314/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 27/30 batch 315/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 27/30 batch 316/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 27/30 batch 317/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 27/30 batch 318/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 27/30 batch 319/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 27/30 batch 320/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 27/30 batch 321/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 27/30 batch 322/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 27/30 batch 323/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch 324/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 325/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 27/30 batch 326/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 327/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 328/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 329/375  Train Loss: 0.023, Acc: 1.000\n",
      "epoch: 27/30 batch 330/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 27/30 batch 331/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 27/30 batch 332/375  Train Loss: 0.046, Acc: 0.992\n",
      "epoch: 27/30 batch 333/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 27/30 batch 334/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 335/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 336/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 27/30 batch 337/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 27/30 batch 338/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 27/30 batch 339/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 340/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 27/30 batch 341/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 27/30 batch 342/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 27/30 batch 343/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 27/30 batch 344/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 345/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 27/30 batch 346/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 27/30 batch 347/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 27/30 batch 348/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 27/30 batch 349/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 27/30 batch 350/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 27/30 batch 351/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 27/30 batch 352/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 27/30 batch 353/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 27/30 batch 354/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 27/30 batch 355/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 27/30 batch 356/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 27/30 batch 357/375  Train Loss: 0.122, Acc: 0.969\n",
      "epoch: 27/30 batch 358/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 27/30 batch 359/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 27/30 batch 360/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 27/30 batch 361/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 27/30 batch 362/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 27/30 batch 363/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 27/30 batch 364/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 27/30 batch 365/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 27/30 batch 366/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 27/30 batch 367/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 27/30 batch 368/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 27/30 batch 369/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 27/30 batch 370/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 27/30 batch 371/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 27/30 batch 372/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 373/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 27/30 batch 374/375  Train Loss: 0.049, Acc: 0.992\n",
      "Train Loss: 0.017038, Acc: 0.995\n",
      "Val Loss: 0.028743, Acc: 0.990\n",
      "epoch: 28/30 batch   0/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch   1/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 28/30 batch   2/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 28/30 batch   3/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 28/30 batch   4/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 28/30 batch   5/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 28/30 batch   6/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch   7/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 28/30 batch   8/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch   9/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 28/30 batch  10/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 28/30 batch  11/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch  12/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 28/30 batch  13/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 28/30 batch  14/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 28/30 batch  15/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch  16/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 28/30 batch  17/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch  18/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 28/30 batch  19/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch  20/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch  21/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch  22/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch  23/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 28/30 batch  24/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 28/30 batch  25/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch  26/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch  27/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 28/30 batch  28/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 28/30 batch  29/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch  30/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch  31/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 28/30 batch  32/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch  33/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 28/30 batch  34/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 28/30 batch  35/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch  36/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 28/30 batch  37/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch  38/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 28/30 batch  39/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch  40/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 28/30 batch  41/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 28/30 batch  42/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch  43/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 28/30 batch  44/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 28/30 batch  45/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 28/30 batch  46/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch  47/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch  48/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch  49/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 28/30 batch  50/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 28/30 batch  51/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch  52/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch  53/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch  54/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 28/30 batch  55/375  Train Loss: 0.053, Acc: 0.977\n",
      "epoch: 28/30 batch  56/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch  57/375  Train Loss: 0.082, Acc: 0.984\n",
      "epoch: 28/30 batch  58/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch  59/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch  60/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch  61/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch  62/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch  63/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch  64/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch  65/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 28/30 batch  66/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 28/30 batch  67/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch  68/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch  69/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch  70/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch  71/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch  72/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch  73/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 28/30 batch  74/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch  75/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 28/30 batch  76/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 28/30 batch  77/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch  78/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch  79/375  Train Loss: 0.116, Acc: 0.984\n",
      "epoch: 28/30 batch  80/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch  81/375  Train Loss: 0.060, Acc: 0.984\n",
      "epoch: 28/30 batch  82/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch  83/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 28/30 batch  84/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch  85/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch  86/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch  87/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch  88/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch  89/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch  90/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch  91/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 28/30 batch  92/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch  93/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 28/30 batch  94/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch  95/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch  96/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 28/30 batch  97/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch  98/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 28/30 batch  99/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 100/375  Train Loss: 0.088, Acc: 0.984\n",
      "epoch: 28/30 batch 101/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 102/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 28/30 batch 103/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch 104/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 28/30 batch 105/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 28/30 batch 106/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch 107/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 28/30 batch 108/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 109/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 110/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 111/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 112/375  Train Loss: 0.037, Acc: 0.977\n",
      "epoch: 28/30 batch 113/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 28/30 batch 114/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 115/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 28/30 batch 116/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 117/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 118/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 28/30 batch 119/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 28/30 batch 120/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 28/30 batch 121/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 122/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 123/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 28/30 batch 124/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 28/30 batch 125/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 126/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 127/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch 128/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 129/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 130/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 131/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 28/30 batch 132/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 133/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 134/375  Train Loss: 0.036, Acc: 0.977\n",
      "epoch: 28/30 batch 135/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 28/30 batch 136/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 137/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 28/30 batch 138/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 139/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch 140/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 28/30 batch 141/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch 142/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 28/30 batch 143/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch 144/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 145/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 146/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 28/30 batch 147/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 148/375  Train Loss: 0.036, Acc: 0.984\n",
      "epoch: 28/30 batch 149/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 150/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 151/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 152/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 28/30 batch 153/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 154/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 28/30 batch 155/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch 156/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 28/30 batch 157/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 158/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 159/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 28/30 batch 160/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 161/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 162/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 163/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 28/30 batch 164/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 28/30 batch 165/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 166/375  Train Loss: 0.035, Acc: 0.984\n",
      "epoch: 28/30 batch 167/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 168/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 28/30 batch 169/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 170/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch 171/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 172/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 173/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 174/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 28/30 batch 175/375  Train Loss: 0.052, Acc: 0.977\n",
      "epoch: 28/30 batch 176/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 177/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 28/30 batch 178/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 28/30 batch 179/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 28/30 batch 180/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch 181/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch 182/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 28/30 batch 183/375  Train Loss: 0.050, Acc: 0.977\n",
      "epoch: 28/30 batch 184/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 28/30 batch 185/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 28/30 batch 186/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 28/30 batch 187/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 188/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 28/30 batch 189/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 190/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 191/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch 192/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch 193/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 28/30 batch 194/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 195/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 28/30 batch 196/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 28/30 batch 197/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 198/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 199/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 200/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 28/30 batch 201/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 202/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 203/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 204/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 28/30 batch 205/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 206/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 207/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 28/30 batch 208/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 209/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 28/30 batch 210/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 211/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 28/30 batch 212/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 213/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 28/30 batch 214/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 28/30 batch 215/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 216/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 28/30 batch 217/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 28/30 batch 218/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 28/30 batch 219/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 28/30 batch 220/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 221/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 222/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 223/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 224/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 225/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 226/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 28/30 batch 227/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 28/30 batch 228/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 229/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 230/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 28/30 batch 231/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 28/30 batch 232/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 28/30 batch 233/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 28/30 batch 234/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 235/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 236/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 28/30 batch 237/375  Train Loss: 0.045, Acc: 0.992\n",
      "epoch: 28/30 batch 238/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 239/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch 240/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 241/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 28/30 batch 242/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 28/30 batch 243/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch 244/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 28/30 batch 245/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 28/30 batch 246/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 28/30 batch 247/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 248/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 249/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch 250/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 251/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 28/30 batch 252/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 28/30 batch 253/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 28/30 batch 254/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 28/30 batch 255/375  Train Loss: 0.020, Acc: 0.984\n",
      "epoch: 28/30 batch 256/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 257/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 258/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 259/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 260/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 261/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 28/30 batch 262/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 28/30 batch 263/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 264/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch 265/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 266/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 28/30 batch 267/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 28/30 batch 268/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 28/30 batch 269/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 270/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 28/30 batch 271/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 272/375  Train Loss: 0.021, Acc: 1.000\n",
      "epoch: 28/30 batch 273/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 274/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 28/30 batch 275/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 28/30 batch 276/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 277/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 28/30 batch 278/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 279/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 28/30 batch 280/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 28/30 batch 281/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 28/30 batch 282/375  Train Loss: 0.047, Acc: 0.992\n",
      "epoch: 28/30 batch 283/375  Train Loss: 0.045, Acc: 0.977\n",
      "epoch: 28/30 batch 284/375  Train Loss: 0.016, Acc: 0.984\n",
      "epoch: 28/30 batch 285/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 28/30 batch 286/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 287/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 288/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 289/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 290/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 28/30 batch 291/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 292/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 293/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 294/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 295/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 28/30 batch 296/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 297/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 298/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 299/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 300/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 28/30 batch 301/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch 302/375  Train Loss: 0.037, Acc: 0.977\n",
      "epoch: 28/30 batch 303/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 28/30 batch 304/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 28/30 batch 305/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 28/30 batch 306/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 307/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 28/30 batch 308/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 309/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 28/30 batch 310/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 28/30 batch 311/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 312/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch 313/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 314/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 28/30 batch 315/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 316/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 28/30 batch 317/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 318/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 28/30 batch 319/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 320/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 321/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 322/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 323/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 28/30 batch 324/375  Train Loss: 0.050, Acc: 0.992\n",
      "epoch: 28/30 batch 325/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch 326/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 327/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 28/30 batch 328/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 28/30 batch 329/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 28/30 batch 330/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 28/30 batch 331/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 28/30 batch 332/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 28/30 batch 333/375  Train Loss: 0.052, Acc: 0.992\n",
      "epoch: 28/30 batch 334/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 28/30 batch 335/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 28/30 batch 336/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 28/30 batch 337/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 28/30 batch 338/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 28/30 batch 339/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 340/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 28/30 batch 341/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 28/30 batch 342/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 343/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 28/30 batch 344/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 28/30 batch 345/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 346/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 347/375  Train Loss: 0.041, Acc: 0.992\n",
      "epoch: 28/30 batch 348/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 28/30 batch 349/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 28/30 batch 350/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch 351/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 28/30 batch 352/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 353/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 28/30 batch 354/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 28/30 batch 355/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 28/30 batch 356/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch 357/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 28/30 batch 358/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 28/30 batch 359/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 28/30 batch 360/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 28/30 batch 361/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 28/30 batch 362/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 363/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 28/30 batch 364/375  Train Loss: 0.064, Acc: 0.969\n",
      "epoch: 28/30 batch 365/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 28/30 batch 366/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 28/30 batch 367/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 28/30 batch 368/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 28/30 batch 369/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 28/30 batch 370/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 28/30 batch 371/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 28/30 batch 372/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 28/30 batch 373/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 28/30 batch 374/375  Train Loss: 0.008, Acc: 1.000\n",
      "Train Loss: 0.016865, Acc: 0.995\n",
      "Val Loss: 0.028933, Acc: 0.990\n",
      "epoch: 29/30 batch   0/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 29/30 batch   1/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch   2/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 29/30 batch   3/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 29/30 batch   4/375  Train Loss: 0.025, Acc: 1.000\n",
      "epoch: 29/30 batch   5/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch   6/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch   7/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 29/30 batch   8/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch   9/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 29/30 batch  10/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch  11/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 29/30 batch  12/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 29/30 batch  13/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch  14/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 29/30 batch  15/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch  16/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 29/30 batch  17/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch  18/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 29/30 batch  19/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 29/30 batch  20/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch  21/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 29/30 batch  22/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch  23/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch  24/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 29/30 batch  25/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 29/30 batch  26/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch  27/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 29/30 batch  28/375  Train Loss: 0.008, Acc: 0.992\n",
      "epoch: 29/30 batch  29/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 29/30 batch  30/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 29/30 batch  31/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch  32/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch  33/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch  34/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch  35/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 29/30 batch  36/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch  37/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 29/30 batch  38/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 29/30 batch  39/375  Train Loss: 0.075, Acc: 0.992\n",
      "epoch: 29/30 batch  40/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch  41/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch  42/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch  43/375  Train Loss: 0.055, Acc: 0.984\n",
      "epoch: 29/30 batch  44/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 29/30 batch  45/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch  46/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 29/30 batch  47/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 29/30 batch  48/375  Train Loss: 0.037, Acc: 0.977\n",
      "epoch: 29/30 batch  49/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 29/30 batch  50/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch  51/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 29/30 batch  52/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch  53/375  Train Loss: 0.056, Acc: 0.984\n",
      "epoch: 29/30 batch  54/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 29/30 batch  55/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch  56/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 29/30 batch  57/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch  58/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch  59/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch  60/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 29/30 batch  61/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch  62/375  Train Loss: 0.054, Acc: 0.992\n",
      "epoch: 29/30 batch  63/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch  64/375  Train Loss: 0.015, Acc: 0.984\n",
      "epoch: 29/30 batch  65/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 29/30 batch  66/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch  67/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch  68/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch  69/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 29/30 batch  70/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 29/30 batch  71/375  Train Loss: 0.020, Acc: 1.000\n",
      "epoch: 29/30 batch  72/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch  73/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 29/30 batch  74/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch  75/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 29/30 batch  76/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 29/30 batch  77/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 29/30 batch  78/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 29/30 batch  79/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 29/30 batch  80/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch  81/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch  82/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 29/30 batch  83/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 29/30 batch  84/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch  85/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 29/30 batch  86/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 29/30 batch  87/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch  88/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 29/30 batch  89/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 29/30 batch  90/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 29/30 batch  91/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 29/30 batch  92/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 29/30 batch  93/375  Train Loss: 0.019, Acc: 0.984\n",
      "epoch: 29/30 batch  94/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch  95/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 29/30 batch  96/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch  97/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 29/30 batch  98/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch  99/375  Train Loss: 0.063, Acc: 0.992\n",
      "epoch: 29/30 batch 100/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 29/30 batch 101/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 29/30 batch 102/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 29/30 batch 103/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 29/30 batch 104/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 29/30 batch 105/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 106/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 29/30 batch 107/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 29/30 batch 108/375  Train Loss: 0.018, Acc: 0.984\n",
      "epoch: 29/30 batch 109/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 110/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 111/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 29/30 batch 112/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 29/30 batch 113/375  Train Loss: 0.035, Acc: 0.977\n",
      "epoch: 29/30 batch 114/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 115/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 116/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 29/30 batch 117/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 118/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 29/30 batch 119/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 29/30 batch 120/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 121/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 29/30 batch 122/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 123/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 124/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 125/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch 126/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 127/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 128/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 29/30 batch 129/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 29/30 batch 130/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 131/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 29/30 batch 132/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 29/30 batch 133/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 134/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 29/30 batch 135/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 136/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 29/30 batch 137/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 138/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 29/30 batch 139/375  Train Loss: 0.049, Acc: 0.984\n",
      "epoch: 29/30 batch 140/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 141/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 29/30 batch 142/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 143/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 29/30 batch 144/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 145/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 29/30 batch 146/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 147/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 148/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 29/30 batch 149/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 29/30 batch 150/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 29/30 batch 151/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 152/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 153/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 29/30 batch 154/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 29/30 batch 155/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 29/30 batch 156/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 29/30 batch 157/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 158/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch 159/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 29/30 batch 160/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 29/30 batch 161/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 29/30 batch 162/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 29/30 batch 163/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 164/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 29/30 batch 165/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 166/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 29/30 batch 167/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 29/30 batch 168/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 29/30 batch 169/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 29/30 batch 170/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 171/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 172/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 173/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 29/30 batch 174/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 175/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 176/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 177/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 29/30 batch 178/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 179/375  Train Loss: 0.057, Acc: 0.984\n",
      "epoch: 29/30 batch 180/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 29/30 batch 181/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 29/30 batch 182/375  Train Loss: 0.023, Acc: 0.984\n",
      "epoch: 29/30 batch 183/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 184/375  Train Loss: 0.039, Acc: 0.992\n",
      "epoch: 29/30 batch 185/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 29/30 batch 186/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 29/30 batch 187/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 29/30 batch 188/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 189/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch 190/375  Train Loss: 0.070, Acc: 0.984\n",
      "epoch: 29/30 batch 191/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 29/30 batch 192/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 193/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 29/30 batch 194/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 195/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 196/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 29/30 batch 197/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 29/30 batch 198/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 29/30 batch 199/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 200/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 201/375  Train Loss: 0.075, Acc: 0.977\n",
      "epoch: 29/30 batch 202/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 29/30 batch 203/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 29/30 batch 204/375  Train Loss: 0.053, Acc: 0.984\n",
      "epoch: 29/30 batch 205/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch 206/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 29/30 batch 207/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 29/30 batch 208/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 209/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 210/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch 211/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 212/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 213/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 29/30 batch 214/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 29/30 batch 215/375  Train Loss: 0.041, Acc: 0.984\n",
      "epoch: 29/30 batch 216/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 217/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 29/30 batch 218/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 29/30 batch 219/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 220/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 29/30 batch 221/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 222/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 223/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 29/30 batch 224/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 225/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 226/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 29/30 batch 227/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 29/30 batch 228/375  Train Loss: 0.040, Acc: 0.984\n",
      "epoch: 29/30 batch 229/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 29/30 batch 230/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 231/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 29/30 batch 232/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 29/30 batch 233/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 234/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 235/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 29/30 batch 236/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 29/30 batch 237/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 29/30 batch 238/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 239/375  Train Loss: 0.059, Acc: 0.984\n",
      "epoch: 29/30 batch 240/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 29/30 batch 241/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 29/30 batch 242/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 29/30 batch 243/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 244/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 29/30 batch 245/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch 246/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 247/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 29/30 batch 248/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 29/30 batch 249/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 29/30 batch 250/375  Train Loss: 0.026, Acc: 1.000\n",
      "epoch: 29/30 batch 251/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 29/30 batch 252/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 253/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 254/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 255/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 29/30 batch 256/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 257/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 258/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 29/30 batch 259/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 29/30 batch 260/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 29/30 batch 261/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 262/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 263/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 29/30 batch 264/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 29/30 batch 265/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 29/30 batch 266/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 29/30 batch 267/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 29/30 batch 268/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 29/30 batch 269/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 29/30 batch 270/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 271/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 29/30 batch 272/375  Train Loss: 0.038, Acc: 0.992\n",
      "epoch: 29/30 batch 273/375  Train Loss: 0.040, Acc: 0.992\n",
      "epoch: 29/30 batch 274/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 275/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 29/30 batch 276/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch 277/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 29/30 batch 278/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 279/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 29/30 batch 280/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 281/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch 282/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 283/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 29/30 batch 284/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 285/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 286/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 287/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 288/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 29/30 batch 289/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch 290/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 29/30 batch 291/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 292/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 293/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 29/30 batch 294/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 29/30 batch 295/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 296/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 29/30 batch 297/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 29/30 batch 298/375  Train Loss: 0.036, Acc: 0.992\n",
      "epoch: 29/30 batch 299/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 29/30 batch 300/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 301/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 29/30 batch 302/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 29/30 batch 303/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 29/30 batch 304/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 29/30 batch 305/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 29/30 batch 306/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 307/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 29/30 batch 308/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 309/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 310/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 29/30 batch 311/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 29/30 batch 312/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 313/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 29/30 batch 314/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 315/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 316/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 317/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 318/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch 319/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 320/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 321/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch 322/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 29/30 batch 323/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 324/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 325/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 326/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 29/30 batch 327/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 29/30 batch 328/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 29/30 batch 329/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 330/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 331/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch 332/375  Train Loss: 0.034, Acc: 0.992\n",
      "epoch: 29/30 batch 333/375  Train Loss: 0.021, Acc: 0.992\n",
      "epoch: 29/30 batch 334/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 29/30 batch 335/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 336/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 337/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 338/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 29/30 batch 339/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 29/30 batch 340/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch 341/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 29/30 batch 342/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 29/30 batch 343/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 344/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 345/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 29/30 batch 346/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 29/30 batch 347/375  Train Loss: 0.044, Acc: 0.984\n",
      "epoch: 29/30 batch 348/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 29/30 batch 349/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 350/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 29/30 batch 351/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 29/30 batch 352/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 353/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 29/30 batch 354/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 29/30 batch 355/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 356/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 357/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 29/30 batch 358/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 29/30 batch 359/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 360/375  Train Loss: 0.008, Acc: 0.992\n",
      "epoch: 29/30 batch 361/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 29/30 batch 362/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 363/375  Train Loss: 0.022, Acc: 1.000\n",
      "epoch: 29/30 batch 364/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 29/30 batch 365/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 29/30 batch 366/375  Train Loss: 0.035, Acc: 0.992\n",
      "epoch: 29/30 batch 367/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 29/30 batch 368/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 29/30 batch 369/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 29/30 batch 370/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 29/30 batch 371/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 29/30 batch 372/375  Train Loss: 0.138, Acc: 0.984\n",
      "epoch: 29/30 batch 373/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 29/30 batch 374/375  Train Loss: 0.017, Acc: 0.992\n",
      "Train Loss: 0.016869, Acc: 0.995\n",
      "Val Loss: 0.028123, Acc: 0.990\n",
      "epoch: 30/30 batch   0/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch   1/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 30/30 batch   2/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 30/30 batch   3/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 30/30 batch   4/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch   5/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch   6/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch   7/375  Train Loss: 0.009, Acc: 0.992\n",
      "epoch: 30/30 batch   8/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch   9/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch  10/375  Train Loss: 0.048, Acc: 0.992\n",
      "epoch: 30/30 batch  11/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 30/30 batch  12/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch  13/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch  14/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch  15/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 30/30 batch  16/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch  17/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 30/30 batch  18/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 30/30 batch  19/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch  20/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch  21/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 30/30 batch  22/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 30/30 batch  23/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 30/30 batch  24/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch  25/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch  26/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch  27/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch  28/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch  29/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 30/30 batch  30/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 30/30 batch  31/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 30/30 batch  32/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch  33/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 30/30 batch  34/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 30/30 batch  35/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch  36/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch  37/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 30/30 batch  38/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch  39/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch  40/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch  41/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch  42/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch  43/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch  44/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch  45/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 30/30 batch  46/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch  47/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch  48/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch  49/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch  50/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 30/30 batch  51/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 30/30 batch  52/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 30/30 batch  53/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 30/30 batch  54/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 30/30 batch  55/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 30/30 batch  56/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 30/30 batch  57/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch  58/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch  59/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 30/30 batch  60/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch  61/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch  62/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch  63/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 30/30 batch  64/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 30/30 batch  65/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 30/30 batch  66/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch  67/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 30/30 batch  68/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch  69/375  Train Loss: 0.044, Acc: 0.992\n",
      "epoch: 30/30 batch  70/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch  71/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch  72/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 30/30 batch  73/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch  74/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 30/30 batch  75/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch  76/375  Train Loss: 0.104, Acc: 0.992\n",
      "epoch: 30/30 batch  77/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch  78/375  Train Loss: 0.027, Acc: 0.977\n",
      "epoch: 30/30 batch  79/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 30/30 batch  80/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch  81/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 30/30 batch  82/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 30/30 batch  83/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch  84/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 30/30 batch  85/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 30/30 batch  86/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch  87/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 30/30 batch  88/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 30/30 batch  89/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 30/30 batch  90/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch  91/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch  92/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch  93/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch  94/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 30/30 batch  95/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch  96/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 30/30 batch  97/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch  98/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch  99/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 100/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 30/30 batch 101/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 102/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 30/30 batch 103/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 30/30 batch 104/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 30/30 batch 105/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 30/30 batch 106/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 30/30 batch 107/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 108/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 109/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 30/30 batch 110/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 111/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 112/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 113/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 114/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 30/30 batch 115/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 30/30 batch 116/375  Train Loss: 0.021, Acc: 0.984\n",
      "epoch: 30/30 batch 117/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 30/30 batch 118/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 30/30 batch 119/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 120/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch 121/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch 122/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 30/30 batch 123/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 30/30 batch 124/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 30/30 batch 125/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 126/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 30/30 batch 127/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 30/30 batch 128/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 30/30 batch 129/375  Train Loss: 0.030, Acc: 0.984\n",
      "epoch: 30/30 batch 130/375  Train Loss: 0.028, Acc: 0.992\n",
      "epoch: 30/30 batch 131/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 30/30 batch 132/375  Train Loss: 0.051, Acc: 0.969\n",
      "epoch: 30/30 batch 133/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 134/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 30/30 batch 135/375  Train Loss: 0.025, Acc: 0.984\n",
      "epoch: 30/30 batch 136/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 137/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 138/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 139/375  Train Loss: 0.002, Acc: 1.000\n",
      "epoch: 30/30 batch 140/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 141/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 30/30 batch 142/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 30/30 batch 143/375  Train Loss: 0.052, Acc: 0.984\n",
      "epoch: 30/30 batch 144/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 30/30 batch 145/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 146/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 147/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 148/375  Train Loss: 0.049, Acc: 0.992\n",
      "epoch: 30/30 batch 149/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 150/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 151/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 152/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 30/30 batch 153/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 30/30 batch 154/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 30/30 batch 155/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 30/30 batch 156/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 30/30 batch 157/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch 158/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 159/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 30/30 batch 160/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 161/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 162/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 30/30 batch 163/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 164/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 165/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 30/30 batch 166/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch 167/375  Train Loss: 0.067, Acc: 0.977\n",
      "epoch: 30/30 batch 168/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 30/30 batch 169/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 170/375  Train Loss: 0.024, Acc: 0.992\n",
      "epoch: 30/30 batch 171/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 172/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 30/30 batch 173/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 174/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 30/30 batch 175/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch 176/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 177/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 30/30 batch 178/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 30/30 batch 179/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 180/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch 181/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 182/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 183/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 184/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 185/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 30/30 batch 186/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 30/30 batch 187/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 30/30 batch 188/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 189/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 30/30 batch 190/375  Train Loss: 0.062, Acc: 0.984\n",
      "epoch: 30/30 batch 191/375  Train Loss: 0.043, Acc: 0.992\n",
      "epoch: 30/30 batch 192/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 193/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch 194/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 30/30 batch 195/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 196/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 197/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 30/30 batch 198/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 199/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 30/30 batch 200/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 201/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 202/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 30/30 batch 203/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch 204/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 30/30 batch 205/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch 206/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 207/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 208/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 209/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 30/30 batch 210/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch 211/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 30/30 batch 212/375  Train Loss: 0.045, Acc: 0.984\n",
      "epoch: 30/30 batch 213/375  Train Loss: 0.101, Acc: 0.984\n",
      "epoch: 30/30 batch 214/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 215/375  Train Loss: 0.013, Acc: 0.992\n",
      "epoch: 30/30 batch 216/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 217/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 30/30 batch 218/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 219/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 220/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 30/30 batch 221/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch 222/375  Train Loss: 0.010, Acc: 0.992\n",
      "epoch: 30/30 batch 223/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 30/30 batch 224/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 30/30 batch 225/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 226/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 30/30 batch 227/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 30/30 batch 228/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch 229/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 230/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 231/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 232/375  Train Loss: 0.066, Acc: 0.984\n",
      "epoch: 30/30 batch 233/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch 234/375  Train Loss: 0.001, Acc: 1.000\n",
      "epoch: 30/30 batch 235/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 30/30 batch 236/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 30/30 batch 237/375  Train Loss: 0.017, Acc: 1.000\n",
      "epoch: 30/30 batch 238/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 30/30 batch 239/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 240/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 241/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 242/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 243/375  Train Loss: 0.025, Acc: 0.992\n",
      "epoch: 30/30 batch 244/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch 245/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 246/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 247/375  Train Loss: 0.031, Acc: 0.984\n",
      "epoch: 30/30 batch 248/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 249/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 250/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 30/30 batch 251/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 30/30 batch 252/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 30/30 batch 253/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 30/30 batch 254/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 30/30 batch 255/375  Train Loss: 0.038, Acc: 0.984\n",
      "epoch: 30/30 batch 256/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 257/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 30/30 batch 258/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 259/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 260/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 30/30 batch 261/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 262/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 263/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 30/30 batch 264/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 30/30 batch 265/375  Train Loss: 0.022, Acc: 0.992\n",
      "epoch: 30/30 batch 266/375  Train Loss: 0.058, Acc: 0.984\n",
      "epoch: 30/30 batch 267/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 268/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 30/30 batch 269/375  Train Loss: 0.034, Acc: 0.984\n",
      "epoch: 30/30 batch 270/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 271/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 30/30 batch 272/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch 273/375  Train Loss: 0.024, Acc: 0.984\n",
      "epoch: 30/30 batch 274/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 275/375  Train Loss: 0.064, Acc: 0.984\n",
      "epoch: 30/30 batch 276/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch 277/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 30/30 batch 278/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 30/30 batch 279/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 280/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 281/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch 282/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 283/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 30/30 batch 284/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 30/30 batch 285/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 30/30 batch 286/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch 287/375  Train Loss: 0.032, Acc: 0.984\n",
      "epoch: 30/30 batch 288/375  Train Loss: 0.030, Acc: 0.992\n",
      "epoch: 30/30 batch 289/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 30/30 batch 290/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 291/375  Train Loss: 0.058, Acc: 0.977\n",
      "epoch: 30/30 batch 292/375  Train Loss: 0.014, Acc: 1.000\n",
      "epoch: 30/30 batch 293/375  Train Loss: 0.033, Acc: 0.984\n",
      "epoch: 30/30 batch 294/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 295/375  Train Loss: 0.020, Acc: 0.992\n",
      "epoch: 30/30 batch 296/375  Train Loss: 0.047, Acc: 0.984\n",
      "epoch: 30/30 batch 297/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 30/30 batch 298/375  Train Loss: 0.029, Acc: 0.992\n",
      "epoch: 30/30 batch 299/375  Train Loss: 0.026, Acc: 0.992\n",
      "epoch: 30/30 batch 300/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 30/30 batch 301/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch 302/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 30/30 batch 303/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 304/375  Train Loss: 0.039, Acc: 0.984\n",
      "epoch: 30/30 batch 305/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 30/30 batch 306/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 307/375  Train Loss: 0.019, Acc: 0.992\n",
      "epoch: 30/30 batch 308/375  Train Loss: 0.011, Acc: 0.992\n",
      "epoch: 30/30 batch 309/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 30/30 batch 310/375  Train Loss: 0.013, Acc: 1.000\n",
      "epoch: 30/30 batch 311/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 312/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 313/375  Train Loss: 0.042, Acc: 0.984\n",
      "epoch: 30/30 batch 314/375  Train Loss: 0.012, Acc: 0.992\n",
      "epoch: 30/30 batch 315/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 30/30 batch 316/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 317/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 30/30 batch 318/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 319/375  Train Loss: 0.043, Acc: 0.984\n",
      "epoch: 30/30 batch 320/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 321/375  Train Loss: 0.006, Acc: 1.000\n",
      "epoch: 30/30 batch 322/375  Train Loss: 0.009, Acc: 1.000\n",
      "epoch: 30/30 batch 323/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 324/375  Train Loss: 0.029, Acc: 0.984\n",
      "epoch: 30/30 batch 325/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 326/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 30/30 batch 327/375  Train Loss: 0.028, Acc: 0.984\n",
      "epoch: 30/30 batch 328/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 329/375  Train Loss: 0.033, Acc: 0.992\n",
      "epoch: 30/30 batch 330/375  Train Loss: 0.026, Acc: 0.984\n",
      "epoch: 30/30 batch 331/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 30/30 batch 332/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch 333/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 334/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 335/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 336/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 337/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 338/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 30/30 batch 339/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 340/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 30/30 batch 341/375  Train Loss: 0.016, Acc: 0.992\n",
      "epoch: 30/30 batch 342/375  Train Loss: 0.057, Acc: 0.969\n",
      "epoch: 30/30 batch 343/375  Train Loss: 0.015, Acc: 1.000\n",
      "epoch: 30/30 batch 344/375  Train Loss: 0.037, Acc: 0.984\n",
      "epoch: 30/30 batch 345/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 346/375  Train Loss: 0.004, Acc: 1.000\n",
      "epoch: 30/30 batch 347/375  Train Loss: 0.019, Acc: 1.000\n",
      "epoch: 30/30 batch 348/375  Train Loss: 0.018, Acc: 1.000\n",
      "epoch: 30/30 batch 349/375  Train Loss: 0.016, Acc: 1.000\n",
      "epoch: 30/30 batch 350/375  Train Loss: 0.018, Acc: 0.992\n",
      "epoch: 30/30 batch 351/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 352/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 30/30 batch 353/375  Train Loss: 0.027, Acc: 0.984\n",
      "epoch: 30/30 batch 354/375  Train Loss: 0.007, Acc: 1.000\n",
      "epoch: 30/30 batch 355/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 30/30 batch 356/375  Train Loss: 0.023, Acc: 0.992\n",
      "epoch: 30/30 batch 357/375  Train Loss: 0.027, Acc: 0.992\n",
      "epoch: 30/30 batch 358/375  Train Loss: 0.022, Acc: 0.984\n",
      "epoch: 30/30 batch 359/375  Train Loss: 0.032, Acc: 0.992\n",
      "epoch: 30/30 batch 360/375  Train Loss: 0.003, Acc: 1.000\n",
      "epoch: 30/30 batch 361/375  Train Loss: 0.031, Acc: 0.992\n",
      "epoch: 30/30 batch 362/375  Train Loss: 0.037, Acc: 0.992\n",
      "epoch: 30/30 batch 363/375  Train Loss: 0.011, Acc: 1.000\n",
      "epoch: 30/30 batch 364/375  Train Loss: 0.017, Acc: 0.992\n",
      "epoch: 30/30 batch 365/375  Train Loss: 0.012, Acc: 1.000\n",
      "epoch: 30/30 batch 366/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 367/375  Train Loss: 0.008, Acc: 1.000\n",
      "epoch: 30/30 batch 368/375  Train Loss: 0.015, Acc: 0.992\n",
      "epoch: 30/30 batch 369/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 30/30 batch 370/375  Train Loss: 0.005, Acc: 1.000\n",
      "epoch: 30/30 batch 371/375  Train Loss: 0.014, Acc: 0.992\n",
      "epoch: 30/30 batch 372/375  Train Loss: 0.010, Acc: 1.000\n",
      "epoch: 30/30 batch 373/375  Train Loss: 0.049, Acc: 0.977\n",
      "epoch: 30/30 batch 374/375  Train Loss: 0.016, Acc: 0.992\n",
      "Train Loss: 0.016749, Acc: 0.995\n",
      "Val Loss: 0.028832, Acc: 0.990\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "epoch_list = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_list.append(epoch)\n",
    "    # train--------------------------\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for batch, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        train_loss += loss.item()\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        train_correct = (pred == batch_y).sum()\n",
    "        train_acc += train_correct.item()\n",
    "        print('epoch: %2d/%d batch %3d/%d  Train Loss: %.3f, Acc: %.3f'\n",
    "        % (epoch + 1, epochs, batch, math.ceil(len(train_data) / batch_size),\n",
    "            loss.item(), train_correct.item() / len(batch_x)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() # 更新lr\n",
    "    print('Train Loss: %.6f, Acc: %.3f' % (train_loss / (math.ceil(len(train_data)/batch_size)),\n",
    "                                        train_acc / (len(train_data))))\n",
    "    \n",
    "    # evaluation-----------\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    eval_acc = 0.0\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        eval_loss += loss.item()\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        num_correct = (pred == batch_y).sum()\n",
    "        eval_acc += num_correct.item()\n",
    "    print('Val Loss: %.6f, Acc: %.3f' % (eval_loss / (math.ceil(len(val_data)/batch_size)),\n",
    "                                            eval_acc / (len(val_data))))\n",
    "    \n",
    "    # save_model\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        torch.save(model.state_dict(), 'D:/learn/mnist_model/params_' + str(epoch + 1) + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "872ed4eb2f287c376edf0c2db5ea5252a3125e445a0f6da6cf219a7817df8b93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
